{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_O-uqZrxkqP7",
        "outputId": "f9b5bce4-3adb-4b53-e3eb-59f8a2cff117"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.21.6)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1,>=3.8.0->tensorboardX) (1.15.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorboardX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-MWVWCMOmQI",
        "outputId": "668f4ccd-4c59-4913-a98f-4638ba6402c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NP6pxaUHFckq"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hl17gP-ijVZH"
      },
      "outputs": [],
      "source": [
        "folder_path = \"/content/drive/MyDrive/DRAC2022/OCTA\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SI61kF3FmS2d"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-resnest/resnest50-528c19ca.pth -P /content/drive/MyDrive/DRAC2022/OCTA/OCTA-Net-OCTA-Vessel-Segmentation-Network-master/code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Z3xFI2Bj4wd",
        "outputId": "46cfc98d-08ae-4f50-d6ae-eeb04978c3e2"
      },
      "outputs": [],
      "source": [
        "%cd {folder_path}/OCTA-Net-OCTA-Vessel-Segmentation-Network-master/code/OCTA-Net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOH3nieHj79P",
        "outputId": "d18d8412-c133-4461-b235-a9a52e80de9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mGörüntülenen çıkış son 5000 satıra kısaltıldı.\u001b[0m\n",
            "4 / 45, train loss: 0.1503\n",
            "5 / 45, train loss: 0.1414\n",
            "6 / 45, train loss: 0.1003\n",
            "7 / 45, train loss: 0.1053\n",
            "8 / 45, train loss: 0.0909\n",
            "9 / 45, train loss: 0.0999\n",
            "10 / 45, train loss: 0.0716\n",
            "11 / 45, train loss: 0.1108\n",
            "12 / 45, train loss: 0.0560\n",
            "13 / 45, train loss: 0.1279\n",
            "14 / 45, train loss: 0.0872\n",
            "15 / 45, train loss: 0.1397\n",
            "16 / 45, train loss: 0.1180\n",
            "17 / 45, train loss: 0.1112\n",
            "18 / 45, train loss: 0.1591\n",
            "19 / 45, train loss: 0.1146\n",
            "20 / 45, train loss: 0.0834\n",
            "21 / 45, train loss: 0.1025\n",
            "22 / 45, train loss: 0.0805\n",
            "23 / 45, train loss: 0.1204\n",
            "24 / 45, train loss: 0.1205\n",
            "25 / 45, train loss: 0.1534\n",
            "26 / 45, train loss: 0.1134\n",
            "27 / 45, train loss: 0.1296\n",
            "28 / 45, train loss: 0.1620\n",
            "29 / 45, train loss: 0.1243\n",
            "30 / 45, train loss: 0.0912\n",
            "31 / 45, train loss: 0.1464\n",
            "32 / 45, train loss: 0.0667\n",
            "33 / 45, train loss: 0.1180\n",
            "34 / 45, train loss: 0.1425\n",
            "35 / 45, train loss: 0.1225\n",
            "36 / 45, train loss: 0.0662\n",
            "37 / 45, train loss: 0.1023\n",
            "38 / 45, train loss: 0.1158\n",
            "39 / 45, train loss: 0.1252\n",
            "40 / 45, train loss: 0.0737\n",
            "41 / 45, train loss: 0.1048\n",
            "42 / 45, train loss: 0.1629\n",
            "43 / 45, train loss: 0.0606\n",
            "44 / 45, train loss: 0.1781\n",
            "45 / 45, train loss: 0.0815\n",
            "epoch 67 loss: 5.1598\n",
            "current learning rate: 0.000240\n",
            "Epoch 69 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1274\n",
            "2 / 45, train loss: 0.1062\n",
            "3 / 45, train loss: 0.1185\n",
            "4 / 45, train loss: 0.1424\n",
            "5 / 45, train loss: 0.0844\n",
            "6 / 45, train loss: 0.1320\n",
            "7 / 45, train loss: 0.1183\n",
            "8 / 45, train loss: 0.1200\n",
            "9 / 45, train loss: 0.0763\n",
            "10 / 45, train loss: 0.1245\n",
            "11 / 45, train loss: 0.1353\n",
            "12 / 45, train loss: 0.0940\n",
            "13 / 45, train loss: 0.1089\n",
            "14 / 45, train loss: 0.0913\n",
            "15 / 45, train loss: 0.0519\n",
            "16 / 45, train loss: 0.1254\n",
            "17 / 45, train loss: 0.1578\n",
            "18 / 45, train loss: 0.1553\n",
            "19 / 45, train loss: 0.1045\n",
            "20 / 45, train loss: 0.1798\n",
            "21 / 45, train loss: 0.1166\n",
            "22 / 45, train loss: 0.1291\n",
            "23 / 45, train loss: 0.1077\n",
            "24 / 45, train loss: 0.0571\n",
            "25 / 45, train loss: 0.1330\n",
            "26 / 45, train loss: 0.1230\n",
            "27 / 45, train loss: 0.1114\n",
            "28 / 45, train loss: 0.1130\n",
            "29 / 45, train loss: 0.1157\n",
            "30 / 45, train loss: 0.1104\n",
            "31 / 45, train loss: 0.1574\n",
            "32 / 45, train loss: 0.1057\n",
            "33 / 45, train loss: 0.1133\n",
            "34 / 45, train loss: 0.1022\n",
            "35 / 45, train loss: 0.1293\n",
            "36 / 45, train loss: 0.1037\n",
            "37 / 45, train loss: 0.0597\n",
            "38 / 45, train loss: 0.1280\n",
            "39 / 45, train loss: 0.0535\n",
            "40 / 45, train loss: 0.1555\n",
            "41 / 45, train loss: 0.1029\n",
            "42 / 45, train loss: 0.1285\n",
            "43 / 45, train loss: 0.1417\n",
            "44 / 45, train loss: 0.1236\n",
            "45 / 45, train loss: 0.0863\n",
            "epoch 68 loss: 5.1624\n",
            "current learning rate: 0.000239\n",
            "Epoch 70 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1213\n",
            "2 / 45, train loss: 0.0674\n",
            "3 / 45, train loss: 0.1245\n",
            "4 / 45, train loss: 0.1280\n",
            "5 / 45, train loss: 0.0747\n",
            "6 / 45, train loss: 0.1775\n",
            "7 / 45, train loss: 0.1862\n",
            "8 / 45, train loss: 0.0819\n",
            "9 / 45, train loss: 0.1230\n",
            "10 / 45, train loss: 0.1495\n",
            "11 / 45, train loss: 0.1259\n",
            "12 / 45, train loss: 0.0486\n",
            "13 / 45, train loss: 0.0697\n",
            "14 / 45, train loss: 0.1087\n",
            "15 / 45, train loss: 0.1178\n",
            "16 / 45, train loss: 0.1668\n",
            "17 / 45, train loss: 0.1772\n",
            "18 / 45, train loss: 0.1170\n",
            "19 / 45, train loss: 0.0915\n",
            "20 / 45, train loss: 0.0913\n",
            "21 / 45, train loss: 0.1396\n",
            "22 / 45, train loss: 0.1564\n",
            "23 / 45, train loss: 0.1189\n",
            "24 / 45, train loss: 0.1274\n",
            "25 / 45, train loss: 0.1940\n",
            "26 / 45, train loss: 0.1140\n",
            "27 / 45, train loss: 0.0732\n",
            "28 / 45, train loss: 0.1350\n",
            "29 / 45, train loss: 0.1951\n",
            "30 / 45, train loss: 0.0895\n",
            "31 / 45, train loss: 0.0959\n",
            "32 / 45, train loss: 0.0806\n",
            "33 / 45, train loss: 0.0888\n",
            "34 / 45, train loss: 0.0825\n",
            "35 / 45, train loss: 0.0660\n",
            "36 / 45, train loss: 0.0646\n",
            "37 / 45, train loss: 0.1126\n",
            "38 / 45, train loss: 0.1430\n",
            "39 / 45, train loss: 0.0801\n",
            "40 / 45, train loss: 0.0875\n",
            "41 / 45, train loss: 0.1150\n",
            "42 / 45, train loss: 0.1173\n",
            "43 / 45, train loss: 0.1291\n",
            "44 / 45, train loss: 0.0899\n",
            "45 / 45, train loss: 0.1304\n",
            "epoch 69 loss: 5.1749\n",
            "current learning rate: 0.000238\n",
            "Loss - mean: 0.049595155753195286\tstd: 0.02050644706707923\n",
            "AUC - mean: 0.856812525214292\tstd: 0.04535001861426995\n",
            "ACC - mean: 0.9061414545232599\tstd: 0.03415488863634561\n",
            "SEN - mean: 0.4862751085806517\tstd: 0.08646486276381092\n",
            "FDR - mean: 0.6672132078429536\tstd: 0.052845159143401856\n",
            "SPE - mean: 0.9347321790018518\tstd: 0.0247738138914161\n",
            "Kappa - mean: 0.3394244679395575\tstd: 0.050910476109654636\n",
            "G-mean - mean: 0.6709948517838753\tstd: 0.062079133219244645\n",
            "IOU - mean: 0.24203393557873018\tstd: 0.03624554915180349\n",
            "Dice - mean: 0.38828280133844095\tstd: 0.04992851342062654\n",
            "Loss - mean: 0.049552256749434906\tstd: 0.020402813751612372\n",
            "AUC - mean: 0.8558516109083737\tstd: 0.045435251504816254\n",
            "ACC - mean: 0.9077219529585405\tstd: 0.033370569214874836\n",
            "SEN - mean: 0.47645527313529984\tstd: 0.08400830657312014\n",
            "FDR - mean: 0.6642829264277323\tstd: 0.05361970187445321\n",
            "SPE - mean: 0.9370990780031374\tstd: 0.023404079685418588\n",
            "Kappa - mean: 0.3390036335767065\tstd: 0.05068076222010204\n",
            "G-mean - mean: 0.66510657743148\tstd: 0.0611199471019347\n",
            "IOU - mean: 0.24124628530813827\tstd: 0.03629291726636787\n",
            "Dice - mean: 0.38725685599727516\tstd: 0.049974150680165225\n",
            "Loss - mean: 0.04991467932069844\tstd: 0.02043976898361209\n",
            "AUC - mean: 0.8571764277851482\tstd: 0.045606470862098104\n",
            "ACC - mean: 0.9049008109352805\tstd: 0.03418801148235917\n",
            "SEN - mean: 0.4922985254720614\tstd: 0.08625026241668535\n",
            "FDR - mean: 0.6708378214368725\tstd: 0.05252898914007325\n",
            "SPE - mean: 0.9330069486570746\tstd: 0.02498347698166545\n",
            "Kappa - mean: 0.33848618023820864\tstd: 0.05038526572775833\n",
            "G-mean - mean: 0.6746069754815412\tstd: 0.061491644956783796\n",
            "IOU - mean: 0.24167879331158704\tstd: 0.036062101671928255\n",
            "Dice - mean: 0.3878355458108812\tstd: 0.04971095747543194\n",
            "best thin: epoch 60\tauc 0.8591\n",
            "best thick: epoch 60\tauc 0.8576\n",
            "best fusion: epoch 60\tauc 0.8586\n",
            "Epoch 71 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1377\n",
            "2 / 45, train loss: 0.1173\n",
            "3 / 45, train loss: 0.1282\n",
            "4 / 45, train loss: 0.1039\n",
            "5 / 45, train loss: 0.1046\n",
            "6 / 45, train loss: 0.0645\n",
            "7 / 45, train loss: 0.1618\n",
            "8 / 45, train loss: 0.1232\n",
            "9 / 45, train loss: 0.1095\n",
            "10 / 45, train loss: 0.0968\n",
            "11 / 45, train loss: 0.0827\n",
            "12 / 45, train loss: 0.1503\n",
            "13 / 45, train loss: 0.1021\n",
            "14 / 45, train loss: 0.1308\n",
            "15 / 45, train loss: 0.0973\n",
            "16 / 45, train loss: 0.0930\n",
            "17 / 45, train loss: 0.0758\n",
            "18 / 45, train loss: 0.0625\n",
            "19 / 45, train loss: 0.1317\n",
            "20 / 45, train loss: 0.1628\n",
            "21 / 45, train loss: 0.1265\n",
            "22 / 45, train loss: 0.1137\n",
            "23 / 45, train loss: 0.0613\n",
            "24 / 45, train loss: 0.0879\n",
            "25 / 45, train loss: 0.0883\n",
            "26 / 45, train loss: 0.0933\n",
            "27 / 45, train loss: 0.1636\n",
            "28 / 45, train loss: 0.1523\n",
            "29 / 45, train loss: 0.0801\n",
            "30 / 45, train loss: 0.1107\n",
            "31 / 45, train loss: 0.0673\n",
            "32 / 45, train loss: 0.1027\n",
            "33 / 45, train loss: 0.1335\n",
            "34 / 45, train loss: 0.1331\n",
            "35 / 45, train loss: 0.1098\n",
            "36 / 45, train loss: 0.1634\n",
            "37 / 45, train loss: 0.1528\n",
            "38 / 45, train loss: 0.1881\n",
            "39 / 45, train loss: 0.0894\n",
            "40 / 45, train loss: 0.1711\n",
            "41 / 45, train loss: 0.1417\n",
            "42 / 45, train loss: 0.0856\n",
            "43 / 45, train loss: 0.0978\n",
            "44 / 45, train loss: 0.0977\n",
            "45 / 45, train loss: 0.1052\n",
            "epoch 70 loss: 5.1536\n",
            "current learning rate: 0.000237\n",
            "Epoch 72 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1301\n",
            "2 / 45, train loss: 0.1227\n",
            "3 / 45, train loss: 0.1101\n",
            "4 / 45, train loss: 0.1073\n",
            "5 / 45, train loss: 0.1361\n",
            "6 / 45, train loss: 0.1016\n",
            "7 / 45, train loss: 0.0863\n",
            "8 / 45, train loss: 0.1019\n",
            "9 / 45, train loss: 0.1683\n",
            "10 / 45, train loss: 0.1799\n",
            "11 / 45, train loss: 0.0913\n",
            "12 / 45, train loss: 0.1559\n",
            "13 / 45, train loss: 0.1026\n",
            "14 / 45, train loss: 0.1648\n",
            "15 / 45, train loss: 0.0925\n",
            "16 / 45, train loss: 0.1287\n",
            "17 / 45, train loss: 0.1360\n",
            "18 / 45, train loss: 0.0993\n",
            "19 / 45, train loss: 0.1222\n",
            "20 / 45, train loss: 0.0978\n",
            "21 / 45, train loss: 0.1024\n",
            "22 / 45, train loss: 0.0709\n",
            "23 / 45, train loss: 0.1070\n",
            "24 / 45, train loss: 0.0866\n",
            "25 / 45, train loss: 0.1120\n",
            "26 / 45, train loss: 0.0988\n",
            "27 / 45, train loss: 0.1252\n",
            "28 / 45, train loss: 0.1242\n",
            "29 / 45, train loss: 0.0923\n",
            "30 / 45, train loss: 0.1151\n",
            "31 / 45, train loss: 0.1082\n",
            "32 / 45, train loss: 0.1469\n",
            "33 / 45, train loss: 0.0876\n",
            "34 / 45, train loss: 0.1349\n",
            "35 / 45, train loss: 0.0860\n",
            "36 / 45, train loss: 0.1077\n",
            "37 / 45, train loss: 0.0854\n",
            "38 / 45, train loss: 0.1734\n",
            "39 / 45, train loss: 0.1148\n",
            "40 / 45, train loss: 0.0506\n",
            "41 / 45, train loss: 0.1064\n",
            "42 / 45, train loss: 0.0806\n",
            "43 / 45, train loss: 0.0780\n",
            "44 / 45, train loss: 0.1541\n",
            "45 / 45, train loss: 0.1417\n",
            "epoch 71 loss: 5.1260\n",
            "current learning rate: 0.000236\n",
            "Epoch 73 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1013\n",
            "2 / 45, train loss: 0.0431\n",
            "3 / 45, train loss: 0.1359\n",
            "4 / 45, train loss: 0.0752\n",
            "5 / 45, train loss: 0.1063\n",
            "6 / 45, train loss: 0.1847\n",
            "7 / 45, train loss: 0.0961\n",
            "8 / 45, train loss: 0.0765\n",
            "9 / 45, train loss: 0.1611\n",
            "10 / 45, train loss: 0.1135\n",
            "11 / 45, train loss: 0.1517\n",
            "12 / 45, train loss: 0.1176\n",
            "13 / 45, train loss: 0.1509\n",
            "14 / 45, train loss: 0.1028\n",
            "15 / 45, train loss: 0.0746\n",
            "16 / 45, train loss: 0.1291\n",
            "17 / 45, train loss: 0.0956\n",
            "18 / 45, train loss: 0.1141\n",
            "19 / 45, train loss: 0.1559\n",
            "20 / 45, train loss: 0.1362\n",
            "21 / 45, train loss: 0.1149\n",
            "22 / 45, train loss: 0.1363\n",
            "23 / 45, train loss: 0.0994\n",
            "24 / 45, train loss: 0.1180\n",
            "25 / 45, train loss: 0.0701\n",
            "26 / 45, train loss: 0.1609\n",
            "27 / 45, train loss: 0.0914\n",
            "28 / 45, train loss: 0.1513\n",
            "29 / 45, train loss: 0.1454\n",
            "30 / 45, train loss: 0.0812\n",
            "31 / 45, train loss: 0.0504\n",
            "32 / 45, train loss: 0.1193\n",
            "33 / 45, train loss: 0.1454\n",
            "34 / 45, train loss: 0.1046\n",
            "35 / 45, train loss: 0.0995\n",
            "36 / 45, train loss: 0.0764\n",
            "37 / 45, train loss: 0.1338\n",
            "38 / 45, train loss: 0.0864\n",
            "39 / 45, train loss: 0.1207\n",
            "40 / 45, train loss: 0.1051\n",
            "41 / 45, train loss: 0.1743\n",
            "42 / 45, train loss: 0.1570\n",
            "43 / 45, train loss: 0.0790\n",
            "44 / 45, train loss: 0.0726\n",
            "45 / 45, train loss: 0.1352\n",
            "epoch 72 loss: 5.1512\n",
            "current learning rate: 0.000235\n",
            "Epoch 74 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1217\n",
            "2 / 45, train loss: 0.1106\n",
            "3 / 45, train loss: 0.1080\n",
            "4 / 45, train loss: 0.1117\n",
            "5 / 45, train loss: 0.1139\n",
            "6 / 45, train loss: 0.1520\n",
            "7 / 45, train loss: 0.1103\n",
            "8 / 45, train loss: 0.1649\n",
            "9 / 45, train loss: 0.0988\n",
            "10 / 45, train loss: 0.0911\n",
            "11 / 45, train loss: 0.1412\n",
            "12 / 45, train loss: 0.0971\n",
            "13 / 45, train loss: 0.0764\n",
            "14 / 45, train loss: 0.1588\n",
            "15 / 45, train loss: 0.0645\n",
            "16 / 45, train loss: 0.1374\n",
            "17 / 45, train loss: 0.0908\n",
            "18 / 45, train loss: 0.0801\n",
            "19 / 45, train loss: 0.1175\n",
            "20 / 45, train loss: 0.1079\n",
            "21 / 45, train loss: 0.0741\n",
            "22 / 45, train loss: 0.0918\n",
            "23 / 45, train loss: 0.1153\n",
            "24 / 45, train loss: 0.0852\n",
            "25 / 45, train loss: 0.0931\n",
            "26 / 45, train loss: 0.1352\n",
            "27 / 45, train loss: 0.1386\n",
            "28 / 45, train loss: 0.1236\n",
            "29 / 45, train loss: 0.1720\n",
            "30 / 45, train loss: 0.1248\n",
            "31 / 45, train loss: 0.0906\n",
            "32 / 45, train loss: 0.1310\n",
            "33 / 45, train loss: 0.0953\n",
            "34 / 45, train loss: 0.0971\n",
            "35 / 45, train loss: 0.1072\n",
            "36 / 45, train loss: 0.0971\n",
            "37 / 45, train loss: 0.1212\n",
            "38 / 45, train loss: 0.1309\n",
            "39 / 45, train loss: 0.1652\n",
            "40 / 45, train loss: 0.1609\n",
            "41 / 45, train loss: 0.1309\n",
            "42 / 45, train loss: 0.0984\n",
            "43 / 45, train loss: 0.0735\n",
            "44 / 45, train loss: 0.1280\n",
            "45 / 45, train loss: 0.1221\n",
            "epoch 73 loss: 5.1579\n",
            "current learning rate: 0.000234\n",
            "Epoch 75 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.0999\n",
            "2 / 45, train loss: 0.1426\n",
            "3 / 45, train loss: 0.1473\n",
            "4 / 45, train loss: 0.0577\n",
            "5 / 45, train loss: 0.0996\n",
            "6 / 45, train loss: 0.1206\n",
            "7 / 45, train loss: 0.1752\n",
            "8 / 45, train loss: 0.1434\n",
            "9 / 45, train loss: 0.1245\n",
            "10 / 45, train loss: 0.0960\n",
            "11 / 45, train loss: 0.1165\n",
            "12 / 45, train loss: 0.0959\n",
            "13 / 45, train loss: 0.1075\n",
            "14 / 45, train loss: 0.0751\n",
            "15 / 45, train loss: 0.1037\n",
            "16 / 45, train loss: 0.1050\n",
            "17 / 45, train loss: 0.1861\n",
            "18 / 45, train loss: 0.0987\n",
            "19 / 45, train loss: 0.0426\n",
            "20 / 45, train loss: 0.0621\n",
            "21 / 45, train loss: 0.0709\n",
            "22 / 45, train loss: 0.1102\n",
            "23 / 45, train loss: 0.1648\n",
            "24 / 45, train loss: 0.1365\n",
            "25 / 45, train loss: 0.1264\n",
            "26 / 45, train loss: 0.1154\n",
            "27 / 45, train loss: 0.1261\n",
            "28 / 45, train loss: 0.1623\n",
            "29 / 45, train loss: 0.0674\n",
            "30 / 45, train loss: 0.0839\n",
            "31 / 45, train loss: 0.0882\n",
            "32 / 45, train loss: 0.0834\n",
            "33 / 45, train loss: 0.0903\n",
            "34 / 45, train loss: 0.1340\n",
            "35 / 45, train loss: 0.1680\n",
            "36 / 45, train loss: 0.1408\n",
            "37 / 45, train loss: 0.0702\n",
            "38 / 45, train loss: 0.1390\n",
            "39 / 45, train loss: 0.1729\n",
            "40 / 45, train loss: 0.1179\n",
            "41 / 45, train loss: 0.0839\n",
            "42 / 45, train loss: 0.1009\n",
            "43 / 45, train loss: 0.1803\n",
            "44 / 45, train loss: 0.1216\n",
            "45 / 45, train loss: 0.0978\n",
            "epoch 74 loss: 5.1530\n",
            "current learning rate: 0.000233\n",
            "Loss - mean: 0.049003638750450176\tstd: 0.020743508912733605\n",
            "AUC - mean: 0.85644815553726\tstd: 0.04617685806049192\n",
            "ACC - mean: 0.9068626057017933\tstd: 0.03336953532294984\n",
            "SEN - mean: 0.48461347557691903\tstd: 0.08084117661301365\n",
            "FDR - mean: 0.6615954294636297\tstd: 0.05799781542065796\n",
            "SPE - mean: 0.9361046534781785\tstd: 0.024341342906460877\n",
            "Kappa - mean: 0.34203842002995777\tstd: 0.0555153078443177\n",
            "G-mean - mean: 0.6708036775625404\tstd: 0.0583457420282807\n",
            "IOU - mean: 0.24363224215135013\tstd: 0.037815761987925973\n",
            "Dice - mean: 0.39021514249320893\tstd: 0.05244367081155493\n",
            "Loss - mean: 0.04901289266788147\tstd: 0.020708770575218433\n",
            "AUC - mean: 0.8552746152396945\tstd: 0.04610555296790305\n",
            "ACC - mean: 0.9086177132346414\tstd: 0.033062747044411755\n",
            "SEN - mean: 0.4753939215974323\tstd: 0.08024742889385353\n",
            "FDR - mean: 0.6564609685537858\tstd: 0.05837249407966316\n",
            "SPE - mean: 0.9386004170694758\tstd: 0.023732179477366354\n",
            "Kappa - mean: 0.34297221246767673\tstd: 0.056122708273622965\n",
            "G-mean - mean: 0.6652359849824728\tstd: 0.0583016636257445\n",
            "IOU - mean: 0.24381405510717882\tstd: 0.03821628635301169\n",
            "Dice - mean: 0.39041780355639105\tstd: 0.05296007137407711\n",
            "Loss - mean: 0.04899524363943122\tstd: 0.020624751025997593\n",
            "AUC - mean: 0.8564540760290197\tstd: 0.04609942571222608\n",
            "ACC - mean: 0.9056883725253019\tstd: 0.03370526699416331\n",
            "SEN - mean: 0.49071728352744304\tstd: 0.08031430606766049\n",
            "FDR - mean: 0.6644515990197836\tstd: 0.05752192911723026\n",
            "SPE - mean: 0.9344108753934733\tstd: 0.02482998075989928\n",
            "Kappa - mean: 0.34176722457071834\tstd: 0.055762976447464314\n",
            "G-mean - mean: 0.6745033314638098\tstd: 0.05768995771623718\n",
            "IOU - mean: 0.24380423969404094\tstd: 0.03801942313220347\n",
            "Dice - mean: 0.3904178980936281\tstd: 0.052815811790859535\n",
            "best thin: epoch 60\tauc 0.8591\n",
            "best thick: epoch 60\tauc 0.8576\n",
            "best fusion: epoch 60\tauc 0.8586\n",
            "Epoch 76 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.0880\n",
            "2 / 45, train loss: 0.1518\n",
            "3 / 45, train loss: 0.1699\n",
            "4 / 45, train loss: 0.0836\n",
            "5 / 45, train loss: 0.0898\n",
            "6 / 45, train loss: 0.1352\n",
            "7 / 45, train loss: 0.0953\n",
            "8 / 45, train loss: 0.1133\n",
            "9 / 45, train loss: 0.1234\n",
            "10 / 45, train loss: 0.0783\n",
            "11 / 45, train loss: 0.0733\n",
            "12 / 45, train loss: 0.0612\n",
            "13 / 45, train loss: 0.1306\n",
            "14 / 45, train loss: 0.1305\n",
            "15 / 45, train loss: 0.0715\n",
            "16 / 45, train loss: 0.1812\n",
            "17 / 45, train loss: 0.0930\n",
            "18 / 45, train loss: 0.1255\n",
            "19 / 45, train loss: 0.0811\n",
            "20 / 45, train loss: 0.1153\n",
            "21 / 45, train loss: 0.0922\n",
            "22 / 45, train loss: 0.1494\n",
            "23 / 45, train loss: 0.0894\n",
            "24 / 45, train loss: 0.1148\n",
            "25 / 45, train loss: 0.1177\n",
            "26 / 45, train loss: 0.1313\n",
            "27 / 45, train loss: 0.1372\n",
            "28 / 45, train loss: 0.1351\n",
            "29 / 45, train loss: 0.1125\n",
            "30 / 45, train loss: 0.0865\n",
            "31 / 45, train loss: 0.0794\n",
            "32 / 45, train loss: 0.0391\n",
            "33 / 45, train loss: 0.1049\n",
            "34 / 45, train loss: 0.1328\n",
            "35 / 45, train loss: 0.0497\n",
            "36 / 45, train loss: 0.1749\n",
            "37 / 45, train loss: 0.1581\n",
            "38 / 45, train loss: 0.1241\n",
            "39 / 45, train loss: 0.1444\n",
            "40 / 45, train loss: 0.1102\n",
            "41 / 45, train loss: 0.1363\n",
            "42 / 45, train loss: 0.1331\n",
            "43 / 45, train loss: 0.1312\n",
            "44 / 45, train loss: 0.1227\n",
            "45 / 45, train loss: 0.1369\n",
            "epoch 75 loss: 5.1355\n",
            "current learning rate: 0.000232\n",
            "Epoch 77 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.0928\n",
            "2 / 45, train loss: 0.0920\n",
            "3 / 45, train loss: 0.1186\n",
            "4 / 45, train loss: 0.1302\n",
            "5 / 45, train loss: 0.1278\n",
            "6 / 45, train loss: 0.1279\n",
            "7 / 45, train loss: 0.1159\n",
            "8 / 45, train loss: 0.1231\n",
            "9 / 45, train loss: 0.1498\n",
            "10 / 45, train loss: 0.0465\n",
            "11 / 45, train loss: 0.0580\n",
            "12 / 45, train loss: 0.1009\n",
            "13 / 45, train loss: 0.0896\n",
            "14 / 45, train loss: 0.1262\n",
            "15 / 45, train loss: 0.1008\n",
            "16 / 45, train loss: 0.1144\n",
            "17 / 45, train loss: 0.1277\n",
            "18 / 45, train loss: 0.0376\n",
            "19 / 45, train loss: 0.1142\n",
            "20 / 45, train loss: 0.1381\n",
            "21 / 45, train loss: 0.0819\n",
            "22 / 45, train loss: 0.1776\n",
            "23 / 45, train loss: 0.1466\n",
            "24 / 45, train loss: 0.0886\n",
            "25 / 45, train loss: 0.1234\n",
            "26 / 45, train loss: 0.0919\n",
            "27 / 45, train loss: 0.1382\n",
            "28 / 45, train loss: 0.1230\n",
            "29 / 45, train loss: 0.1019\n",
            "30 / 45, train loss: 0.1485\n",
            "31 / 45, train loss: 0.0870\n",
            "32 / 45, train loss: 0.1126\n",
            "33 / 45, train loss: 0.1713\n",
            "34 / 45, train loss: 0.1161\n",
            "35 / 45, train loss: 0.1351\n",
            "36 / 45, train loss: 0.0802\n",
            "37 / 45, train loss: 0.1152\n",
            "38 / 45, train loss: 0.1538\n",
            "39 / 45, train loss: 0.0705\n",
            "40 / 45, train loss: 0.0731\n",
            "41 / 45, train loss: 0.0937\n",
            "42 / 45, train loss: 0.1190\n",
            "43 / 45, train loss: 0.1978\n",
            "44 / 45, train loss: 0.1358\n",
            "45 / 45, train loss: 0.1365\n",
            "epoch 76 loss: 5.1513\n",
            "current learning rate: 0.000232\n",
            "Epoch 78 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.0774\n",
            "2 / 45, train loss: 0.1131\n",
            "3 / 45, train loss: 0.0848\n",
            "4 / 45, train loss: 0.1719\n",
            "5 / 45, train loss: 0.1346\n",
            "6 / 45, train loss: 0.1134\n",
            "7 / 45, train loss: 0.1063\n",
            "8 / 45, train loss: 0.0694\n",
            "9 / 45, train loss: 0.1542\n",
            "10 / 45, train loss: 0.0834\n",
            "11 / 45, train loss: 0.1028\n",
            "12 / 45, train loss: 0.1122\n",
            "13 / 45, train loss: 0.1465\n",
            "14 / 45, train loss: 0.1146\n",
            "15 / 45, train loss: 0.1070\n",
            "16 / 45, train loss: 0.1406\n",
            "17 / 45, train loss: 0.1058\n",
            "18 / 45, train loss: 0.0640\n",
            "19 / 45, train loss: 0.1664\n",
            "20 / 45, train loss: 0.1161\n",
            "21 / 45, train loss: 0.1201\n",
            "22 / 45, train loss: 0.1092\n",
            "23 / 45, train loss: 0.1283\n",
            "24 / 45, train loss: 0.1066\n",
            "25 / 45, train loss: 0.1164\n",
            "26 / 45, train loss: 0.1155\n",
            "27 / 45, train loss: 0.0935\n",
            "28 / 45, train loss: 0.0835\n",
            "29 / 45, train loss: 0.1409\n",
            "30 / 45, train loss: 0.1328\n",
            "31 / 45, train loss: 0.1159\n",
            "32 / 45, train loss: 0.0972\n",
            "33 / 45, train loss: 0.1326\n",
            "34 / 45, train loss: 0.1786\n",
            "35 / 45, train loss: 0.1147\n",
            "36 / 45, train loss: 0.1471\n",
            "37 / 45, train loss: 0.0749\n",
            "38 / 45, train loss: 0.1719\n",
            "39 / 45, train loss: 0.1474\n",
            "40 / 45, train loss: 0.0650\n",
            "41 / 45, train loss: 0.0682\n",
            "42 / 45, train loss: 0.1046\n",
            "43 / 45, train loss: 0.1278\n",
            "44 / 45, train loss: 0.0794\n",
            "45 / 45, train loss: 0.0850\n",
            "epoch 77 loss: 5.1418\n",
            "current learning rate: 0.000231\n",
            "Epoch 79 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1154\n",
            "2 / 45, train loss: 0.1167\n",
            "3 / 45, train loss: 0.1162\n",
            "4 / 45, train loss: 0.1745\n",
            "5 / 45, train loss: 0.1313\n",
            "6 / 45, train loss: 0.1998\n",
            "7 / 45, train loss: 0.0783\n",
            "8 / 45, train loss: 0.1622\n",
            "9 / 45, train loss: 0.1250\n",
            "10 / 45, train loss: 0.0681\n",
            "11 / 45, train loss: 0.1038\n",
            "12 / 45, train loss: 0.1111\n",
            "13 / 45, train loss: 0.1046\n",
            "14 / 45, train loss: 0.1014\n",
            "15 / 45, train loss: 0.1339\n",
            "16 / 45, train loss: 0.1330\n",
            "17 / 45, train loss: 0.0850\n",
            "18 / 45, train loss: 0.1356\n",
            "19 / 45, train loss: 0.0967\n",
            "20 / 45, train loss: 0.1282\n",
            "21 / 45, train loss: 0.1279\n",
            "22 / 45, train loss: 0.1005\n",
            "23 / 45, train loss: 0.0833\n",
            "24 / 45, train loss: 0.1227\n",
            "25 / 45, train loss: 0.0491\n",
            "26 / 45, train loss: 0.0522\n",
            "27 / 45, train loss: 0.1138\n",
            "28 / 45, train loss: 0.1745\n",
            "29 / 45, train loss: 0.1061\n",
            "30 / 45, train loss: 0.1027\n",
            "31 / 45, train loss: 0.2172\n",
            "32 / 45, train loss: 0.0891\n",
            "33 / 45, train loss: 0.1045\n",
            "34 / 45, train loss: 0.1232\n",
            "35 / 45, train loss: 0.0580\n",
            "36 / 45, train loss: 0.1598\n",
            "37 / 45, train loss: 0.0920\n",
            "38 / 45, train loss: 0.1127\n",
            "39 / 45, train loss: 0.0671\n",
            "40 / 45, train loss: 0.1249\n",
            "41 / 45, train loss: 0.0776\n",
            "42 / 45, train loss: 0.0546\n",
            "43 / 45, train loss: 0.1532\n",
            "44 / 45, train loss: 0.1218\n",
            "45 / 45, train loss: 0.1484\n",
            "epoch 78 loss: 5.1578\n",
            "current learning rate: 0.000230\n",
            "Epoch 80 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.0894\n",
            "2 / 45, train loss: 0.0761\n",
            "3 / 45, train loss: 0.1363\n",
            "4 / 45, train loss: 0.1636\n",
            "5 / 45, train loss: 0.1256\n",
            "6 / 45, train loss: 0.1003\n",
            "7 / 45, train loss: 0.0961\n",
            "8 / 45, train loss: 0.1003\n",
            "9 / 45, train loss: 0.1139\n",
            "10 / 45, train loss: 0.0759\n",
            "11 / 45, train loss: 0.0792\n",
            "12 / 45, train loss: 0.0826\n",
            "13 / 45, train loss: 0.0691\n",
            "14 / 45, train loss: 0.1638\n",
            "15 / 45, train loss: 0.1568\n",
            "16 / 45, train loss: 0.1399\n",
            "17 / 45, train loss: 0.1100\n",
            "18 / 45, train loss: 0.1783\n",
            "19 / 45, train loss: 0.1351\n",
            "20 / 45, train loss: 0.0843\n",
            "21 / 45, train loss: 0.1246\n",
            "22 / 45, train loss: 0.1819\n",
            "23 / 45, train loss: 0.1398\n",
            "24 / 45, train loss: 0.1423\n",
            "25 / 45, train loss: 0.1080\n",
            "26 / 45, train loss: 0.0962\n",
            "27 / 45, train loss: 0.1268\n",
            "28 / 45, train loss: 0.0665\n",
            "29 / 45, train loss: 0.1279\n",
            "30 / 45, train loss: 0.1081\n",
            "31 / 45, train loss: 0.1081\n",
            "32 / 45, train loss: 0.1169\n",
            "33 / 45, train loss: 0.1285\n",
            "34 / 45, train loss: 0.0675\n",
            "35 / 45, train loss: 0.1173\n",
            "36 / 45, train loss: 0.1250\n",
            "37 / 45, train loss: 0.1135\n",
            "38 / 45, train loss: 0.1448\n",
            "39 / 45, train loss: 0.0797\n",
            "40 / 45, train loss: 0.0656\n",
            "41 / 45, train loss: 0.1096\n",
            "42 / 45, train loss: 0.1179\n",
            "43 / 45, train loss: 0.1778\n",
            "44 / 45, train loss: 0.0871\n",
            "45 / 45, train loss: 0.0974\n",
            "epoch 79 loss: 5.1556\n",
            "current learning rate: 0.000229\n",
            "Loss - mean: 0.048741591797972265\tstd: 0.020772221186360205\n",
            "AUC - mean: 0.8591997675351508\tstd: 0.04647993496434919\n",
            "ACC - mean: 0.9105418812144886\tstd: 0.032066542680061746\n",
            "SEN - mean: 0.4793636012890292\tstd: 0.08720219295876047\n",
            "FDR - mean: 0.6544139643115154\tstd: 0.05141237559789487\n",
            "SPE - mean: 0.940426062165026\tstd: 0.02166658907432486\n",
            "Kappa - mean: 0.34762335533369293\tstd: 0.04947512625992137\n",
            "G-mean - mean: 0.6683042181006228\tstd: 0.06331676611861871\n",
            "IOU - mean: 0.24675164839029476\tstd: 0.03482940978117902\n",
            "Dice - mean: 0.39451737354004535\tstd: 0.0470857067669554\n",
            "Loss - mean: 0.048844873989847576\tstd: 0.020689511763214236\n",
            "AUC - mean: 0.8557014873197549\tstd: 0.0457365741787683\n",
            "ACC - mean: 0.9113096757368608\tstd: 0.032136130775399736\n",
            "SEN - mean: 0.47160218585989644\tstd: 0.08467749918396275\n",
            "FDR - mean: 0.6523725013450357\tstd: 0.05227959894442084\n",
            "SPE - mean: 0.9416840740137232\tstd: 0.02155564055349091\n",
            "Kappa - mean: 0.3466947095172646\tstd: 0.05065778245386462\n",
            "G-mean - mean: 0.6633736181431983\tstd: 0.06216532575161985\n",
            "IOU - mean: 0.2458456612642892\tstd: 0.03558044625904432\n",
            "Dice - mean: 0.3932891537792555\tstd: 0.048222146463966505\n",
            "Loss - mean: 0.04876039465042678\tstd: 0.020597372419037193\n",
            "AUC - mean: 0.8582818849214419\tstd: 0.04569537297717504\n",
            "ACC - mean: 0.9090546694668856\tstd: 0.032462643049713164\n",
            "SEN - mean: 0.48657337033008896\tstd: 0.08554632321397161\n",
            "FDR - mean: 0.6587534554569694\tstd: 0.05093157975913263\n",
            "SPE - mean: 0.938281895468073\tstd: 0.022333168058916823\n",
            "Kappa - mean: 0.3467749316519512\tstd: 0.04908132011405511\n",
            "G-mean - mean: 0.6727416505427893\tstd: 0.06172449909426322\n",
            "IOU - mean: 0.24659656275574096\tstd: 0.03464214604855844\n",
            "Dice - mean: 0.3943273007814071\tstd: 0.046994317582576446\n",
            "best thin: epoch 80\tauc 0.8592\n",
            "best thick: epoch 60\tauc 0.8576\n",
            "best fusion: epoch 60\tauc 0.8586\n",
            "Epoch 81 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1439\n",
            "2 / 45, train loss: 0.1490\n",
            "3 / 45, train loss: 0.1050\n",
            "4 / 45, train loss: 0.0478\n",
            "5 / 45, train loss: 0.0923\n",
            "6 / 45, train loss: 0.0763\n",
            "7 / 45, train loss: 0.1820\n",
            "8 / 45, train loss: 0.0866\n",
            "9 / 45, train loss: 0.0890\n",
            "10 / 45, train loss: 0.1801\n",
            "11 / 45, train loss: 0.0880\n",
            "12 / 45, train loss: 0.1266\n",
            "13 / 45, train loss: 0.0733\n",
            "14 / 45, train loss: 0.1022\n",
            "15 / 45, train loss: 0.1504\n",
            "16 / 45, train loss: 0.0703\n",
            "17 / 45, train loss: 0.1029\n",
            "18 / 45, train loss: 0.0834\n",
            "19 / 45, train loss: 0.1902\n",
            "20 / 45, train loss: 0.0644\n",
            "21 / 45, train loss: 0.1320\n",
            "22 / 45, train loss: 0.1219\n",
            "23 / 45, train loss: 0.1040\n",
            "24 / 45, train loss: 0.1365\n",
            "25 / 45, train loss: 0.1355\n",
            "26 / 45, train loss: 0.1050\n",
            "27 / 45, train loss: 0.0986\n",
            "28 / 45, train loss: 0.1057\n",
            "29 / 45, train loss: 0.1638\n",
            "30 / 45, train loss: 0.0897\n",
            "31 / 45, train loss: 0.0969\n",
            "32 / 45, train loss: 0.1215\n",
            "33 / 45, train loss: 0.1066\n",
            "34 / 45, train loss: 0.1055\n",
            "35 / 45, train loss: 0.1602\n",
            "36 / 45, train loss: 0.1186\n",
            "37 / 45, train loss: 0.1727\n",
            "38 / 45, train loss: 0.1037\n",
            "39 / 45, train loss: 0.1078\n",
            "40 / 45, train loss: 0.1696\n",
            "41 / 45, train loss: 0.0469\n",
            "42 / 45, train loss: 0.0563\n",
            "43 / 45, train loss: 0.1537\n",
            "44 / 45, train loss: 0.0992\n",
            "45 / 45, train loss: 0.1284\n",
            "epoch 80 loss: 5.1439\n",
            "current learning rate: 0.000228\n",
            "Epoch 82 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1709\n",
            "2 / 45, train loss: 0.1014\n",
            "3 / 45, train loss: 0.1449\n",
            "4 / 45, train loss: 0.1180\n",
            "5 / 45, train loss: 0.1400\n",
            "6 / 45, train loss: 0.0850\n",
            "7 / 45, train loss: 0.0919\n",
            "8 / 45, train loss: 0.0599\n",
            "9 / 45, train loss: 0.0436\n",
            "10 / 45, train loss: 0.1010\n",
            "11 / 45, train loss: 0.0891\n",
            "12 / 45, train loss: 0.1368\n",
            "13 / 45, train loss: 0.1034\n",
            "14 / 45, train loss: 0.1282\n",
            "15 / 45, train loss: 0.1254\n",
            "16 / 45, train loss: 0.1088\n",
            "17 / 45, train loss: 0.2247\n",
            "18 / 45, train loss: 0.0944\n",
            "19 / 45, train loss: 0.1284\n",
            "20 / 45, train loss: 0.0788\n",
            "21 / 45, train loss: 0.1485\n",
            "22 / 45, train loss: 0.0776\n",
            "23 / 45, train loss: 0.1609\n",
            "24 / 45, train loss: 0.1454\n",
            "25 / 45, train loss: 0.1110\n",
            "26 / 45, train loss: 0.1292\n",
            "27 / 45, train loss: 0.1459\n",
            "28 / 45, train loss: 0.1585\n",
            "29 / 45, train loss: 0.1265\n",
            "30 / 45, train loss: 0.0576\n",
            "31 / 45, train loss: 0.1315\n",
            "32 / 45, train loss: 0.1357\n",
            "33 / 45, train loss: 0.1078\n",
            "34 / 45, train loss: 0.1203\n",
            "35 / 45, train loss: 0.1021\n",
            "36 / 45, train loss: 0.0944\n",
            "37 / 45, train loss: 0.0861\n",
            "38 / 45, train loss: 0.0840\n",
            "39 / 45, train loss: 0.1022\n",
            "40 / 45, train loss: 0.1575\n",
            "41 / 45, train loss: 0.1094\n",
            "42 / 45, train loss: 0.0927\n",
            "43 / 45, train loss: 0.1683\n",
            "44 / 45, train loss: 0.0883\n",
            "45 / 45, train loss: 0.0534\n",
            "epoch 81 loss: 5.1692\n",
            "current learning rate: 0.000227\n",
            "Epoch 83 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.0497\n",
            "2 / 45, train loss: 0.1141\n",
            "3 / 45, train loss: 0.1065\n",
            "4 / 45, train loss: 0.1071\n",
            "5 / 45, train loss: 0.1140\n",
            "6 / 45, train loss: 0.0692\n",
            "7 / 45, train loss: 0.1273\n",
            "8 / 45, train loss: 0.0912\n",
            "9 / 45, train loss: 0.1793\n",
            "10 / 45, train loss: 0.1035\n",
            "11 / 45, train loss: 0.1432\n",
            "12 / 45, train loss: 0.1426\n",
            "13 / 45, train loss: 0.0873\n",
            "14 / 45, train loss: 0.1679\n",
            "15 / 45, train loss: 0.1559\n",
            "16 / 45, train loss: 0.1170\n",
            "17 / 45, train loss: 0.1002\n",
            "18 / 45, train loss: 0.1424\n",
            "19 / 45, train loss: 0.1600\n",
            "20 / 45, train loss: 0.0913\n",
            "21 / 45, train loss: 0.1006\n",
            "22 / 45, train loss: 0.0996\n",
            "23 / 45, train loss: 0.0792\n",
            "24 / 45, train loss: 0.1062\n",
            "25 / 45, train loss: 0.0747\n",
            "26 / 45, train loss: 0.0724\n",
            "27 / 45, train loss: 0.1241\n",
            "28 / 45, train loss: 0.0909\n",
            "29 / 45, train loss: 0.1010\n",
            "30 / 45, train loss: 0.2061\n",
            "31 / 45, train loss: 0.1044\n",
            "32 / 45, train loss: 0.1029\n",
            "33 / 45, train loss: 0.1083\n",
            "34 / 45, train loss: 0.0550\n",
            "35 / 45, train loss: 0.0840\n",
            "36 / 45, train loss: 0.1251\n",
            "37 / 45, train loss: 0.1811\n",
            "38 / 45, train loss: 0.1102\n",
            "39 / 45, train loss: 0.0854\n",
            "40 / 45, train loss: 0.1238\n",
            "41 / 45, train loss: 0.1358\n",
            "42 / 45, train loss: 0.1102\n",
            "43 / 45, train loss: 0.1069\n",
            "44 / 45, train loss: 0.1604\n",
            "45 / 45, train loss: 0.1275\n",
            "epoch 82 loss: 5.1458\n",
            "current learning rate: 0.000226\n",
            "Epoch 84 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.0736\n",
            "2 / 45, train loss: 0.1525\n",
            "3 / 45, train loss: 0.0821\n",
            "4 / 45, train loss: 0.1547\n",
            "5 / 45, train loss: 0.1062\n",
            "6 / 45, train loss: 0.0779\n",
            "7 / 45, train loss: 0.1087\n",
            "8 / 45, train loss: 0.1320\n",
            "9 / 45, train loss: 0.0780\n",
            "10 / 45, train loss: 0.0857\n",
            "11 / 45, train loss: 0.1177\n",
            "12 / 45, train loss: 0.0900\n",
            "13 / 45, train loss: 0.1656\n",
            "14 / 45, train loss: 0.0921\n",
            "15 / 45, train loss: 0.0528\n",
            "16 / 45, train loss: 0.1462\n",
            "17 / 45, train loss: 0.0808\n",
            "18 / 45, train loss: 0.1260\n",
            "19 / 45, train loss: 0.1037\n",
            "20 / 45, train loss: 0.1725\n",
            "21 / 45, train loss: 0.1841\n",
            "22 / 45, train loss: 0.1019\n",
            "23 / 45, train loss: 0.0862\n",
            "24 / 45, train loss: 0.1533\n",
            "25 / 45, train loss: 0.0983\n",
            "26 / 45, train loss: 0.1060\n",
            "27 / 45, train loss: 0.1438\n",
            "28 / 45, train loss: 0.0748\n",
            "29 / 45, train loss: 0.1213\n",
            "30 / 45, train loss: 0.0826\n",
            "31 / 45, train loss: 0.1236\n",
            "32 / 45, train loss: 0.1153\n",
            "33 / 45, train loss: 0.1101\n",
            "34 / 45, train loss: 0.1462\n",
            "35 / 45, train loss: 0.1347\n",
            "36 / 45, train loss: 0.0912\n",
            "37 / 45, train loss: 0.1256\n",
            "38 / 45, train loss: 0.1057\n",
            "39 / 45, train loss: 0.1100\n",
            "40 / 45, train loss: 0.0711\n",
            "41 / 45, train loss: 0.1206\n",
            "42 / 45, train loss: 0.0988\n",
            "43 / 45, train loss: 0.1601\n",
            "44 / 45, train loss: 0.1679\n",
            "45 / 45, train loss: 0.1032\n",
            "epoch 83 loss: 5.1352\n",
            "current learning rate: 0.000225\n",
            "Epoch 85 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1413\n",
            "2 / 45, train loss: 0.1385\n",
            "3 / 45, train loss: 0.1673\n",
            "4 / 45, train loss: 0.1025\n",
            "5 / 45, train loss: 0.1669\n",
            "6 / 45, train loss: 0.0962\n",
            "7 / 45, train loss: 0.0961\n",
            "8 / 45, train loss: 0.2040\n",
            "9 / 45, train loss: 0.0916\n",
            "10 / 45, train loss: 0.0844\n",
            "11 / 45, train loss: 0.0943\n",
            "12 / 45, train loss: 0.0878\n",
            "13 / 45, train loss: 0.0914\n",
            "14 / 45, train loss: 0.0520\n",
            "15 / 45, train loss: 0.0827\n",
            "16 / 45, train loss: 0.1132\n",
            "17 / 45, train loss: 0.1672\n",
            "18 / 45, train loss: 0.1492\n",
            "19 / 45, train loss: 0.0534\n",
            "20 / 45, train loss: 0.0757\n",
            "21 / 45, train loss: 0.1512\n",
            "22 / 45, train loss: 0.1410\n",
            "23 / 45, train loss: 0.1219\n",
            "24 / 45, train loss: 0.1067\n",
            "25 / 45, train loss: 0.0990\n",
            "26 / 45, train loss: 0.0637\n",
            "27 / 45, train loss: 0.1482\n",
            "28 / 45, train loss: 0.0602\n",
            "29 / 45, train loss: 0.1295\n",
            "30 / 45, train loss: 0.1161\n",
            "31 / 45, train loss: 0.1052\n",
            "32 / 45, train loss: 0.1521\n",
            "33 / 45, train loss: 0.0823\n",
            "34 / 45, train loss: 0.1003\n",
            "35 / 45, train loss: 0.1240\n",
            "36 / 45, train loss: 0.1391\n",
            "37 / 45, train loss: 0.1626\n",
            "38 / 45, train loss: 0.1048\n",
            "39 / 45, train loss: 0.1287\n",
            "40 / 45, train loss: 0.1208\n",
            "41 / 45, train loss: 0.1118\n",
            "42 / 45, train loss: 0.0920\n",
            "43 / 45, train loss: 0.1029\n",
            "44 / 45, train loss: 0.0988\n",
            "45 / 45, train loss: 0.1306\n",
            "epoch 84 loss: 5.1495\n",
            "current learning rate: 0.000224\n",
            "Loss - mean: 0.04881275191225789\tstd: 0.020827119038164817\n",
            "AUC - mean: 0.8582069976089531\tstd: 0.045529392026260794\n",
            "ACC - mean: 0.9175746224143289\tstd: 0.03221720570388142\n",
            "SEN - mean: 0.436391606328446\tstd: 0.07530329955172295\n",
            "FDR - mean: 0.6284652481445062\tstd: 0.05236666033948213\n",
            "SPE - mean: 0.950365706446915\tstd: 0.0200383446555511\n",
            "Kappa - mean: 0.35177172766772297\tstd: 0.05273156174447462\n",
            "G-mean - mean: 0.6412997504010816\tstd: 0.05741800376256918\n",
            "IOU - mean: 0.24776849961263317\tstd: 0.036864781313079464\n",
            "Dice - mean: 0.3956821488855139\tstd: 0.04934282572787731\n",
            "Loss - mean: 0.04895866196602583\tstd: 0.020645419675064194\n",
            "AUC - mean: 0.8493666899093498\tstd: 0.04304351031609998\n",
            "ACC - mean: 0.91582575711337\tstd: 0.03308713739975339\n",
            "SEN - mean: 0.43604530109913325\tstd: 0.08383846270865007\n",
            "FDR - mean: 0.6353204398159199\tstd: 0.05232785610762418\n",
            "SPE - mean: 0.9481081501295558\tstd: 0.02180852315771158\n",
            "Kappa - mean: 0.34524796712897493\tstd: 0.051113476803520554\n",
            "G-mean - mean: 0.639411172915061\tstd: 0.06336391360255707\n",
            "IOU - mean: 0.243405653406419\tstd: 0.037688839136730094\n",
            "Dice - mean: 0.38997950549948485\tstd: 0.05068885160532247\n",
            "Loss - mean: 0.048768469682809984\tstd: 0.02067224688458694\n",
            "AUC - mean: 0.85822286577164\tstd: 0.04568763112587062\n",
            "ACC - mean: 0.9146374789151278\tstd: 0.03327767821224624\n",
            "SEN - mean: 0.4520697390730817\tstd: 0.07617056891340275\n",
            "FDR - mean: 0.6386712167150378\tstd: 0.0519019712447588\n",
            "SPE - mean: 0.9460533703382694\tstd: 0.02187657961211196\n",
            "Kappa - mean: 0.3506178233100849\tstd: 0.05239490878196811\n",
            "G-mean - mean: 0.6513216052484585\tstd: 0.05694872435585602\n",
            "IOU - mean: 0.24798191769127767\tstd: 0.03663684946731311\n",
            "Dice - mean: 0.3959692981163435\tstd: 0.04921722182872232\n",
            "best thin: epoch 80\tauc 0.8592\n",
            "best thick: epoch 60\tauc 0.8576\n",
            "best fusion: epoch 60\tauc 0.8586\n",
            "Epoch 86 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1528\n",
            "2 / 45, train loss: 0.1823\n",
            "3 / 45, train loss: 0.1168\n",
            "4 / 45, train loss: 0.0924\n",
            "5 / 45, train loss: 0.1024\n",
            "6 / 45, train loss: 0.0895\n",
            "7 / 45, train loss: 0.1493\n",
            "8 / 45, train loss: 0.1321\n",
            "9 / 45, train loss: 0.1063\n",
            "10 / 45, train loss: 0.0952\n",
            "11 / 45, train loss: 0.1469\n",
            "12 / 45, train loss: 0.0505\n",
            "13 / 45, train loss: 0.1090\n",
            "14 / 45, train loss: 0.1428\n",
            "15 / 45, train loss: 0.1377\n",
            "16 / 45, train loss: 0.1338\n",
            "17 / 45, train loss: 0.0691\n",
            "18 / 45, train loss: 0.1222\n",
            "19 / 45, train loss: 0.0662\n",
            "20 / 45, train loss: 0.0622\n",
            "21 / 45, train loss: 0.1131\n",
            "22 / 45, train loss: 0.1147\n",
            "23 / 45, train loss: 0.1065\n",
            "24 / 45, train loss: 0.1607\n",
            "25 / 45, train loss: 0.1291\n",
            "26 / 45, train loss: 0.0589\n",
            "27 / 45, train loss: 0.1026\n",
            "28 / 45, train loss: 0.0980\n",
            "29 / 45, train loss: 0.1581\n",
            "30 / 45, train loss: 0.1724\n",
            "31 / 45, train loss: 0.1041\n",
            "32 / 45, train loss: 0.1585\n",
            "33 / 45, train loss: 0.1117\n",
            "34 / 45, train loss: 0.0982\n",
            "35 / 45, train loss: 0.1169\n",
            "36 / 45, train loss: 0.0729\n",
            "37 / 45, train loss: 0.0770\n",
            "38 / 45, train loss: 0.0583\n",
            "39 / 45, train loss: 0.1432\n",
            "40 / 45, train loss: 0.0836\n",
            "41 / 45, train loss: 0.1441\n",
            "42 / 45, train loss: 0.1252\n",
            "43 / 45, train loss: 0.1171\n",
            "44 / 45, train loss: 0.1147\n",
            "45 / 45, train loss: 0.1466\n",
            "epoch 85 loss: 5.1457\n",
            "current learning rate: 0.000223\n",
            "Epoch 87 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1011\n",
            "2 / 45, train loss: 0.0946\n",
            "3 / 45, train loss: 0.2223\n",
            "4 / 45, train loss: 0.1145\n",
            "5 / 45, train loss: 0.1096\n",
            "6 / 45, train loss: 0.0796\n",
            "7 / 45, train loss: 0.0459\n",
            "8 / 45, train loss: 0.1090\n",
            "9 / 45, train loss: 0.1155\n",
            "10 / 45, train loss: 0.1031\n",
            "11 / 45, train loss: 0.1280\n",
            "12 / 45, train loss: 0.1258\n",
            "13 / 45, train loss: 0.0853\n",
            "14 / 45, train loss: 0.0891\n",
            "15 / 45, train loss: 0.1142\n",
            "16 / 45, train loss: 0.0648\n",
            "17 / 45, train loss: 0.1007\n",
            "18 / 45, train loss: 0.1155\n",
            "19 / 45, train loss: 0.0892\n",
            "20 / 45, train loss: 0.1236\n",
            "21 / 45, train loss: 0.0536\n",
            "22 / 45, train loss: 0.1325\n",
            "23 / 45, train loss: 0.1746\n",
            "24 / 45, train loss: 0.1307\n",
            "25 / 45, train loss: 0.1738\n",
            "26 / 45, train loss: 0.1316\n",
            "27 / 45, train loss: 0.1808\n",
            "28 / 45, train loss: 0.0675\n",
            "29 / 45, train loss: 0.1032\n",
            "30 / 45, train loss: 0.1582\n",
            "31 / 45, train loss: 0.1445\n",
            "32 / 45, train loss: 0.1176\n",
            "33 / 45, train loss: 0.1128\n",
            "34 / 45, train loss: 0.0870\n",
            "35 / 45, train loss: 0.0663\n",
            "36 / 45, train loss: 0.1080\n",
            "37 / 45, train loss: 0.1005\n",
            "38 / 45, train loss: 0.1679\n",
            "39 / 45, train loss: 0.1336\n",
            "40 / 45, train loss: 0.1101\n",
            "41 / 45, train loss: 0.1361\n",
            "42 / 45, train loss: 0.1396\n",
            "43 / 45, train loss: 0.1215\n",
            "44 / 45, train loss: 0.0555\n",
            "45 / 45, train loss: 0.1009\n",
            "epoch 86 loss: 5.1395\n",
            "current learning rate: 0.000222\n",
            "Epoch 88 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1092\n",
            "2 / 45, train loss: 0.1172\n",
            "3 / 45, train loss: 0.1106\n",
            "4 / 45, train loss: 0.1723\n",
            "5 / 45, train loss: 0.1157\n",
            "6 / 45, train loss: 0.1038\n",
            "7 / 45, train loss: 0.0914\n",
            "8 / 45, train loss: 0.0952\n",
            "9 / 45, train loss: 0.1244\n",
            "10 / 45, train loss: 0.1523\n",
            "11 / 45, train loss: 0.1291\n",
            "12 / 45, train loss: 0.0713\n",
            "13 / 45, train loss: 0.0708\n",
            "14 / 45, train loss: 0.0926\n",
            "15 / 45, train loss: 0.0712\n",
            "16 / 45, train loss: 0.1310\n",
            "17 / 45, train loss: 0.0669\n",
            "18 / 45, train loss: 0.1091\n",
            "19 / 45, train loss: 0.1353\n",
            "20 / 45, train loss: 0.1194\n",
            "21 / 45, train loss: 0.0787\n",
            "22 / 45, train loss: 0.0975\n",
            "23 / 45, train loss: 0.1304\n",
            "24 / 45, train loss: 0.1194\n",
            "25 / 45, train loss: 0.1397\n",
            "26 / 45, train loss: 0.0680\n",
            "27 / 45, train loss: 0.1429\n",
            "28 / 45, train loss: 0.0943\n",
            "29 / 45, train loss: 0.1425\n",
            "30 / 45, train loss: 0.0908\n",
            "31 / 45, train loss: 0.1131\n",
            "32 / 45, train loss: 0.1368\n",
            "33 / 45, train loss: 0.1266\n",
            "34 / 45, train loss: 0.1016\n",
            "35 / 45, train loss: 0.1104\n",
            "36 / 45, train loss: 0.1200\n",
            "37 / 45, train loss: 0.1649\n",
            "38 / 45, train loss: 0.0501\n",
            "39 / 45, train loss: 0.1511\n",
            "40 / 45, train loss: 0.1448\n",
            "41 / 45, train loss: 0.0805\n",
            "42 / 45, train loss: 0.1038\n",
            "43 / 45, train loss: 0.1199\n",
            "44 / 45, train loss: 0.1260\n",
            "45 / 45, train loss: 0.1831\n",
            "epoch 87 loss: 5.1259\n",
            "current learning rate: 0.000221\n",
            "Epoch 89 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1412\n",
            "2 / 45, train loss: 0.1442\n",
            "3 / 45, train loss: 0.1244\n",
            "4 / 45, train loss: 0.1356\n",
            "5 / 45, train loss: 0.1154\n",
            "6 / 45, train loss: 0.1204\n",
            "7 / 45, train loss: 0.1033\n",
            "8 / 45, train loss: 0.0729\n",
            "9 / 45, train loss: 0.1283\n",
            "10 / 45, train loss: 0.0574\n",
            "11 / 45, train loss: 0.0925\n",
            "12 / 45, train loss: 0.1244\n",
            "13 / 45, train loss: 0.1298\n",
            "14 / 45, train loss: 0.0855\n",
            "15 / 45, train loss: 0.1090\n",
            "16 / 45, train loss: 0.1274\n",
            "17 / 45, train loss: 0.1039\n",
            "18 / 45, train loss: 0.0672\n",
            "19 / 45, train loss: 0.1032\n",
            "20 / 45, train loss: 0.1540\n",
            "21 / 45, train loss: 0.0821\n",
            "22 / 45, train loss: 0.0848\n",
            "23 / 45, train loss: 0.1417\n",
            "24 / 45, train loss: 0.1159\n",
            "25 / 45, train loss: 0.0672\n",
            "26 / 45, train loss: 0.1114\n",
            "27 / 45, train loss: 0.1161\n",
            "28 / 45, train loss: 0.1273\n",
            "29 / 45, train loss: 0.1267\n",
            "30 / 45, train loss: 0.1029\n",
            "31 / 45, train loss: 0.1110\n",
            "32 / 45, train loss: 0.1200\n",
            "33 / 45, train loss: 0.1294\n",
            "34 / 45, train loss: 0.1146\n",
            "35 / 45, train loss: 0.1246\n",
            "36 / 45, train loss: 0.1755\n",
            "37 / 45, train loss: 0.1144\n",
            "38 / 45, train loss: 0.1086\n",
            "39 / 45, train loss: 0.1097\n",
            "40 / 45, train loss: 0.0965\n",
            "41 / 45, train loss: 0.1292\n",
            "42 / 45, train loss: 0.1043\n",
            "43 / 45, train loss: 0.1359\n",
            "44 / 45, train loss: 0.0926\n",
            "45 / 45, train loss: 0.1557\n",
            "epoch 88 loss: 5.1381\n",
            "current learning rate: 0.000220\n",
            "Epoch 90 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1711\n",
            "2 / 45, train loss: 0.0859\n",
            "3 / 45, train loss: 0.1126\n",
            "4 / 45, train loss: 0.1036\n",
            "5 / 45, train loss: 0.1197\n",
            "6 / 45, train loss: 0.1890\n",
            "7 / 45, train loss: 0.1207\n",
            "8 / 45, train loss: 0.1524\n",
            "9 / 45, train loss: 0.0815\n",
            "10 / 45, train loss: 0.1832\n",
            "11 / 45, train loss: 0.1644\n",
            "12 / 45, train loss: 0.0587\n",
            "13 / 45, train loss: 0.0943\n",
            "14 / 45, train loss: 0.1560\n",
            "15 / 45, train loss: 0.0795\n",
            "16 / 45, train loss: 0.0925\n",
            "17 / 45, train loss: 0.1038\n",
            "18 / 45, train loss: 0.1308\n",
            "19 / 45, train loss: 0.0904\n",
            "20 / 45, train loss: 0.0908\n",
            "21 / 45, train loss: 0.0926\n",
            "22 / 45, train loss: 0.2000\n",
            "23 / 45, train loss: 0.1222\n",
            "24 / 45, train loss: 0.1358\n",
            "25 / 45, train loss: 0.0823\n",
            "26 / 45, train loss: 0.0742\n",
            "27 / 45, train loss: 0.1105\n",
            "28 / 45, train loss: 0.1390\n",
            "29 / 45, train loss: 0.0516\n",
            "30 / 45, train loss: 0.1232\n",
            "31 / 45, train loss: 0.0877\n",
            "32 / 45, train loss: 0.1203\n",
            "33 / 45, train loss: 0.0791\n",
            "34 / 45, train loss: 0.1017\n",
            "35 / 45, train loss: 0.1077\n",
            "36 / 45, train loss: 0.0760\n",
            "37 / 45, train loss: 0.1261\n",
            "38 / 45, train loss: 0.1289\n",
            "39 / 45, train loss: 0.1308\n",
            "40 / 45, train loss: 0.0915\n",
            "41 / 45, train loss: 0.1366\n",
            "42 / 45, train loss: 0.1280\n",
            "43 / 45, train loss: 0.1014\n",
            "44 / 45, train loss: 0.0766\n",
            "45 / 45, train loss: 0.1305\n",
            "epoch 89 loss: 5.1356\n",
            "current learning rate: 0.000219\n",
            "Loss - mean: 0.04850999464873563\tstd: 0.020772797447973834\n",
            "AUC - mean: 0.8595374502251126\tstd: 0.04600856068984604\n",
            "ACC - mean: 0.9144838506525214\tstd: 0.03482437627112461\n",
            "SEN - mean: 0.4526751236234696\tstd: 0.0861249688334226\n",
            "FDR - mean: 0.6359524079925183\tstd: 0.049172884894526446\n",
            "SPE - mean: 0.9455794581225215\tstd: 0.024518808830648595\n",
            "Kappa - mean: 0.35180336463524325\tstd: 0.04991365921461245\n",
            "G-mean - mean: 0.6506846473760443\tstd: 0.06291945104929214\n",
            "IOU - mean: 0.24881309887743086\tstd: 0.034990755052013905\n",
            "Dice - mean: 0.3971745819709049\tstd: 0.04660337306276005\n",
            "Loss - mean: 0.048616702160374684\tstd: 0.02077313483054157\n",
            "AUC - mean: 0.8582892935170111\tstd: 0.04587249378640162\n",
            "ACC - mean: 0.9139726812189276\tstd: 0.035354132342119045\n",
            "SEN - mean: 0.45314142329435064\tstd: 0.08630949435706312\n",
            "FDR - mean: 0.6377882509344854\tstd: 0.047777426486393784\n",
            "SPE - mean: 0.9448374542434697\tstd: 0.0250323434747188\n",
            "Kappa - mean: 0.35105819766159213\tstd: 0.05020113012551634\n",
            "G-mean - mean: 0.6507296734082413\tstd: 0.0629022098395885\n",
            "IOU - mean: 0.24850456053893485\tstd: 0.035275783978649784\n",
            "Dice - mean: 0.39675548679578454\tstd: 0.04704312948647618\n",
            "Loss - mean: 0.04853092337196523\tstd: 0.020704823856510426\n",
            "AUC - mean: 0.8593302769643153\tstd: 0.04592893203489946\n",
            "ACC - mean: 0.9122699390758168\tstd: 0.03556248336331691\n",
            "SEN - mean: 0.46398286949395984\tstd: 0.08753387696494744\n",
            "FDR - mean: 0.6436833311440087\tstd: 0.04755200775979021\n",
            "SPE - mean: 0.9423567882190259\tstd: 0.02569170337418884\n",
            "Kappa - mean: 0.3505806371529108\tstd: 0.04918106521218789\n",
            "G-mean - mean: 0.6576685733394317\tstd: 0.0629416400355157\n",
            "IOU - mean: 0.24865876129808828\tstd: 0.03454717100988169\n",
            "Dice - mean: 0.39700678752295276\tstd: 0.04610648657395425\n",
            "best thin: epoch 90\tauc 0.8595\n",
            "best thick: epoch 90\tauc 0.8583\n",
            "best fusion: epoch 90\tauc 0.8593\n",
            "Epoch 91 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.0921\n",
            "2 / 45, train loss: 0.1492\n",
            "3 / 45, train loss: 0.1551\n",
            "4 / 45, train loss: 0.0907\n",
            "5 / 45, train loss: 0.1392\n",
            "6 / 45, train loss: 0.0888\n",
            "7 / 45, train loss: 0.1254\n",
            "8 / 45, train loss: 0.0459\n",
            "9 / 45, train loss: 0.0911\n",
            "10 / 45, train loss: 0.1072\n",
            "11 / 45, train loss: 0.1091\n",
            "12 / 45, train loss: 0.0922\n",
            "13 / 45, train loss: 0.0766\n",
            "14 / 45, train loss: 0.1252\n",
            "15 / 45, train loss: 0.1237\n",
            "16 / 45, train loss: 0.0605\n",
            "17 / 45, train loss: 0.1092\n",
            "18 / 45, train loss: 0.0989\n",
            "19 / 45, train loss: 0.1060\n",
            "20 / 45, train loss: 0.0968\n",
            "21 / 45, train loss: 0.1352\n",
            "22 / 45, train loss: 0.1013\n",
            "23 / 45, train loss: 0.0907\n",
            "24 / 45, train loss: 0.1611\n",
            "25 / 45, train loss: 0.1031\n",
            "26 / 45, train loss: 0.1144\n",
            "27 / 45, train loss: 0.0629\n",
            "28 / 45, train loss: 0.1066\n",
            "29 / 45, train loss: 0.1354\n",
            "30 / 45, train loss: 0.1958\n",
            "31 / 45, train loss: 0.0932\n",
            "32 / 45, train loss: 0.1594\n",
            "33 / 45, train loss: 0.1335\n",
            "34 / 45, train loss: 0.1167\n",
            "35 / 45, train loss: 0.1392\n",
            "36 / 45, train loss: 0.1311\n",
            "37 / 45, train loss: 0.1099\n",
            "38 / 45, train loss: 0.1021\n",
            "39 / 45, train loss: 0.0879\n",
            "40 / 45, train loss: 0.1494\n",
            "41 / 45, train loss: 0.0848\n",
            "42 / 45, train loss: 0.1011\n",
            "43 / 45, train loss: 0.1136\n",
            "44 / 45, train loss: 0.1506\n",
            "45 / 45, train loss: 0.1617\n",
            "epoch 90 loss: 5.1235\n",
            "current learning rate: 0.000219\n",
            "Epoch 92 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.0829\n",
            "2 / 45, train loss: 0.0857\n",
            "3 / 45, train loss: 0.1525\n",
            "4 / 45, train loss: 0.1135\n",
            "5 / 45, train loss: 0.1085\n",
            "6 / 45, train loss: 0.1432\n",
            "7 / 45, train loss: 0.1946\n",
            "8 / 45, train loss: 0.1576\n",
            "9 / 45, train loss: 0.0765\n",
            "10 / 45, train loss: 0.1373\n",
            "11 / 45, train loss: 0.1413\n",
            "12 / 45, train loss: 0.0610\n",
            "13 / 45, train loss: 0.1040\n",
            "14 / 45, train loss: 0.0885\n",
            "15 / 45, train loss: 0.1529\n",
            "16 / 45, train loss: 0.1424\n",
            "17 / 45, train loss: 0.1101\n",
            "18 / 45, train loss: 0.1664\n",
            "19 / 45, train loss: 0.1287\n",
            "20 / 45, train loss: 0.1662\n",
            "21 / 45, train loss: 0.1550\n",
            "22 / 45, train loss: 0.1112\n",
            "23 / 45, train loss: 0.0956\n",
            "24 / 45, train loss: 0.1104\n",
            "25 / 45, train loss: 0.0668\n",
            "26 / 45, train loss: 0.0920\n",
            "27 / 45, train loss: 0.1239\n",
            "28 / 45, train loss: 0.1341\n",
            "29 / 45, train loss: 0.1436\n",
            "30 / 45, train loss: 0.0766\n",
            "31 / 45, train loss: 0.0830\n",
            "32 / 45, train loss: 0.1012\n",
            "33 / 45, train loss: 0.1188\n",
            "34 / 45, train loss: 0.1042\n",
            "35 / 45, train loss: 0.1093\n",
            "36 / 45, train loss: 0.0645\n",
            "37 / 45, train loss: 0.0678\n",
            "38 / 45, train loss: 0.0900\n",
            "39 / 45, train loss: 0.0767\n",
            "40 / 45, train loss: 0.1372\n",
            "41 / 45, train loss: 0.0991\n",
            "42 / 45, train loss: 0.1257\n",
            "43 / 45, train loss: 0.1135\n",
            "44 / 45, train loss: 0.1155\n",
            "45 / 45, train loss: 0.1149\n",
            "epoch 91 loss: 5.1443\n",
            "current learning rate: 0.000218\n",
            "Epoch 93 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1111\n",
            "2 / 45, train loss: 0.1221\n",
            "3 / 45, train loss: 0.1689\n",
            "4 / 45, train loss: 0.1159\n",
            "5 / 45, train loss: 0.1235\n",
            "6 / 45, train loss: 0.0958\n",
            "7 / 45, train loss: 0.1183\n",
            "8 / 45, train loss: 0.1420\n",
            "9 / 45, train loss: 0.1246\n",
            "10 / 45, train loss: 0.1233\n",
            "11 / 45, train loss: 0.1502\n",
            "12 / 45, train loss: 0.0953\n",
            "13 / 45, train loss: 0.0855\n",
            "14 / 45, train loss: 0.1476\n",
            "15 / 45, train loss: 0.0383\n",
            "16 / 45, train loss: 0.0990\n",
            "17 / 45, train loss: 0.1612\n",
            "18 / 45, train loss: 0.0889\n",
            "19 / 45, train loss: 0.1465\n",
            "20 / 45, train loss: 0.0889\n",
            "21 / 45, train loss: 0.1243\n",
            "22 / 45, train loss: 0.1896\n",
            "23 / 45, train loss: 0.1082\n",
            "24 / 45, train loss: 0.0781\n",
            "25 / 45, train loss: 0.1170\n",
            "26 / 45, train loss: 0.1703\n",
            "27 / 45, train loss: 0.1354\n",
            "28 / 45, train loss: 0.1504\n",
            "29 / 45, train loss: 0.0786\n",
            "30 / 45, train loss: 0.0550\n",
            "31 / 45, train loss: 0.0726\n",
            "32 / 45, train loss: 0.0841\n",
            "33 / 45, train loss: 0.1170\n",
            "34 / 45, train loss: 0.0941\n",
            "35 / 45, train loss: 0.1013\n",
            "36 / 45, train loss: 0.0728\n",
            "37 / 45, train loss: 0.0969\n",
            "38 / 45, train loss: 0.1164\n",
            "39 / 45, train loss: 0.0691\n",
            "40 / 45, train loss: 0.1022\n",
            "41 / 45, train loss: 0.1597\n",
            "42 / 45, train loss: 0.0799\n",
            "43 / 45, train loss: 0.1575\n",
            "44 / 45, train loss: 0.1107\n",
            "45 / 45, train loss: 0.1372\n",
            "epoch 92 loss: 5.1254\n",
            "current learning rate: 0.000217\n",
            "Epoch 94 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1145\n",
            "2 / 45, train loss: 0.0704\n",
            "3 / 45, train loss: 0.1160\n",
            "4 / 45, train loss: 0.1278\n",
            "5 / 45, train loss: 0.1414\n",
            "6 / 45, train loss: 0.1360\n",
            "7 / 45, train loss: 0.1426\n",
            "8 / 45, train loss: 0.1004\n",
            "9 / 45, train loss: 0.1982\n",
            "10 / 45, train loss: 0.1065\n",
            "11 / 45, train loss: 0.0967\n",
            "12 / 45, train loss: 0.0741\n",
            "13 / 45, train loss: 0.1911\n",
            "14 / 45, train loss: 0.1075\n",
            "15 / 45, train loss: 0.0925\n",
            "16 / 45, train loss: 0.0858\n",
            "17 / 45, train loss: 0.1392\n",
            "18 / 45, train loss: 0.1624\n",
            "19 / 45, train loss: 0.1452\n",
            "20 / 45, train loss: 0.0814\n",
            "21 / 45, train loss: 0.1269\n",
            "22 / 45, train loss: 0.0714\n",
            "23 / 45, train loss: 0.0761\n",
            "24 / 45, train loss: 0.1048\n",
            "25 / 45, train loss: 0.0948\n",
            "26 / 45, train loss: 0.1170\n",
            "27 / 45, train loss: 0.0781\n",
            "28 / 45, train loss: 0.0734\n",
            "29 / 45, train loss: 0.1367\n",
            "30 / 45, train loss: 0.1140\n",
            "31 / 45, train loss: 0.1015\n",
            "32 / 45, train loss: 0.1105\n",
            "33 / 45, train loss: 0.1307\n",
            "34 / 45, train loss: 0.1740\n",
            "35 / 45, train loss: 0.0785\n",
            "36 / 45, train loss: 0.1718\n",
            "37 / 45, train loss: 0.1024\n",
            "38 / 45, train loss: 0.0753\n",
            "39 / 45, train loss: 0.1002\n",
            "40 / 45, train loss: 0.0652\n",
            "41 / 45, train loss: 0.1419\n",
            "42 / 45, train loss: 0.1197\n",
            "43 / 45, train loss: 0.1174\n",
            "44 / 45, train loss: 0.0646\n",
            "45 / 45, train loss: 0.1551\n",
            "epoch 93 loss: 5.1317\n",
            "current learning rate: 0.000216\n",
            "Epoch 95 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1200\n",
            "2 / 45, train loss: 0.1143\n",
            "3 / 45, train loss: 0.0852\n",
            "4 / 45, train loss: 0.1451\n",
            "5 / 45, train loss: 0.1691\n",
            "6 / 45, train loss: 0.1128\n",
            "7 / 45, train loss: 0.1465\n",
            "8 / 45, train loss: 0.1045\n",
            "9 / 45, train loss: 0.1037\n",
            "10 / 45, train loss: 0.0595\n",
            "11 / 45, train loss: 0.0696\n",
            "12 / 45, train loss: 0.1215\n",
            "13 / 45, train loss: 0.1135\n",
            "14 / 45, train loss: 0.1133\n",
            "15 / 45, train loss: 0.0816\n",
            "16 / 45, train loss: 0.0788\n",
            "17 / 45, train loss: 0.1109\n",
            "18 / 45, train loss: 0.1222\n",
            "19 / 45, train loss: 0.0847\n",
            "20 / 45, train loss: 0.1020\n",
            "21 / 45, train loss: 0.1641\n",
            "22 / 45, train loss: 0.1075\n",
            "23 / 45, train loss: 0.0844\n",
            "24 / 45, train loss: 0.1408\n",
            "25 / 45, train loss: 0.1350\n",
            "26 / 45, train loss: 0.1271\n",
            "27 / 45, train loss: 0.0838\n",
            "28 / 45, train loss: 0.0797\n",
            "29 / 45, train loss: 0.0726\n",
            "30 / 45, train loss: 0.1224\n",
            "31 / 45, train loss: 0.1440\n",
            "32 / 45, train loss: 0.0900\n",
            "33 / 45, train loss: 0.1679\n",
            "34 / 45, train loss: 0.0609\n",
            "35 / 45, train loss: 0.1316\n",
            "36 / 45, train loss: 0.0924\n",
            "37 / 45, train loss: 0.0945\n",
            "38 / 45, train loss: 0.0927\n",
            "39 / 45, train loss: 0.2244\n",
            "40 / 45, train loss: 0.1040\n",
            "41 / 45, train loss: 0.0815\n",
            "42 / 45, train loss: 0.1161\n",
            "43 / 45, train loss: 0.1583\n",
            "44 / 45, train loss: 0.1210\n",
            "45 / 45, train loss: 0.1795\n",
            "epoch 94 loss: 5.1349\n",
            "current learning rate: 0.000215\n",
            "Loss - mean: 0.048791014504703606\tstd: 0.02095718625513841\n",
            "AUC - mean: 0.8578086721475775\tstd: 0.046998288697599123\n",
            "ACC - mean: 0.9191457575017755\tstd: 0.03302389969940429\n",
            "SEN - mean: 0.42101889798971365\tstd: 0.08457115569792145\n",
            "FDR - mean: 0.6181362261890224\tstd: 0.05832337855941427\n",
            "SPE - mean: 0.9529200848273724\tstd: 0.0219575368301401\n",
            "Kappa - mean: 0.3499074246893627\tstd: 0.05747046640075304\n",
            "G-mean - mean: 0.6295675239486266\tstd: 0.06529902789794291\n",
            "IOU - mean: 0.24573164737464764\tstd: 0.04052546489681371\n",
            "Dice - mean: 0.39275483846429177\tstd: 0.05424051147201401\n",
            "Loss - mean: 0.04877326417375694\tstd: 0.020900792121452263\n",
            "AUC - mean: 0.8569390083661854\tstd: 0.04622576020817112\n",
            "ACC - mean: 0.9196203405206854\tstd: 0.033029625038247835\n",
            "SEN - mean: 0.4153532040843121\tstd: 0.08314694639568863\n",
            "FDR - mean: 0.6159830587537563\tstd: 0.058872176385834724\n",
            "SPE - mean: 0.9537383052799786\tstd: 0.021798750075756847\n",
            "Kappa - mean: 0.3486629760871698\tstd: 0.05723082455565666\n",
            "G-mean - mean: 0.6256031576932902\tstd: 0.06453144338893498\n",
            "IOU - mean: 0.2445847090740016\tstd: 0.04039943495457858\n",
            "Dice - mean: 0.39128045356923236\tstd: 0.05420164482318522\n",
            "Loss - mean: 0.048671809025108814\tstd: 0.020836818693242345\n",
            "AUC - mean: 0.8579824696406013\tstd: 0.04661593862290797\n",
            "ACC - mean: 0.9178210171786222\tstd: 0.03363868114717873\n",
            "SEN - mean: 0.4284009193503671\tstd: 0.08500732111932556\n",
            "FDR - mean: 0.6229511286102958\tstd: 0.05790799371227559\n",
            "SPE - mean: 0.9509295034546816\tstd: 0.022989170481489747\n",
            "Kappa - mean: 0.34977806448709625\tstd: 0.0570636813793824\n",
            "G-mean - mean: 0.634461954077273\tstd: 0.06484912244687528\n",
            "IOU - mean: 0.24615356459170679\tstd: 0.040163306048750666\n",
            "Dice - mean: 0.3933284886604222\tstd: 0.05381677332334626\n",
            "best thin: epoch 90\tauc 0.8595\n",
            "best thick: epoch 90\tauc 0.8583\n",
            "best fusion: epoch 90\tauc 0.8593\n",
            "Epoch 96 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.0785\n",
            "2 / 45, train loss: 0.1493\n",
            "3 / 45, train loss: 0.1155\n",
            "4 / 45, train loss: 0.0510\n",
            "5 / 45, train loss: 0.0962\n",
            "6 / 45, train loss: 0.1727\n",
            "7 / 45, train loss: 0.0849\n",
            "8 / 45, train loss: 0.1462\n",
            "9 / 45, train loss: 0.1616\n",
            "10 / 45, train loss: 0.0898\n",
            "11 / 45, train loss: 0.1246\n",
            "12 / 45, train loss: 0.1225\n",
            "13 / 45, train loss: 0.1106\n",
            "14 / 45, train loss: 0.1580\n",
            "15 / 45, train loss: 0.1249\n",
            "16 / 45, train loss: 0.1698\n",
            "17 / 45, train loss: 0.0973\n",
            "18 / 45, train loss: 0.1125\n",
            "19 / 45, train loss: 0.0934\n",
            "20 / 45, train loss: 0.1392\n",
            "21 / 45, train loss: 0.0962\n",
            "22 / 45, train loss: 0.0949\n",
            "23 / 45, train loss: 0.1370\n",
            "24 / 45, train loss: 0.0778\n",
            "25 / 45, train loss: 0.0698\n",
            "26 / 45, train loss: 0.1269\n",
            "27 / 45, train loss: 0.0958\n",
            "28 / 45, train loss: 0.1013\n",
            "29 / 45, train loss: 0.1091\n",
            "30 / 45, train loss: 0.0700\n",
            "31 / 45, train loss: 0.0987\n",
            "32 / 45, train loss: 0.1123\n",
            "33 / 45, train loss: 0.1430\n",
            "34 / 45, train loss: 0.0646\n",
            "35 / 45, train loss: 0.1235\n",
            "36 / 45, train loss: 0.1346\n",
            "37 / 45, train loss: 0.0669\n",
            "38 / 45, train loss: 0.0697\n",
            "39 / 45, train loss: 0.1386\n",
            "40 / 45, train loss: 0.1412\n",
            "41 / 45, train loss: 0.1749\n",
            "42 / 45, train loss: 0.1246\n",
            "43 / 45, train loss: 0.1217\n",
            "44 / 45, train loss: 0.0965\n",
            "45 / 45, train loss: 0.1333\n",
            "epoch 95 loss: 5.1217\n",
            "current learning rate: 0.000214\n",
            "Epoch 97 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1379\n",
            "2 / 45, train loss: 0.0464\n",
            "3 / 45, train loss: 0.1145\n",
            "4 / 45, train loss: 0.1005\n",
            "5 / 45, train loss: 0.1130\n",
            "6 / 45, train loss: 0.0726\n",
            "7 / 45, train loss: 0.1155\n",
            "8 / 45, train loss: 0.1985\n",
            "9 / 45, train loss: 0.0888\n",
            "10 / 45, train loss: 0.1166\n",
            "11 / 45, train loss: 0.0868\n",
            "12 / 45, train loss: 0.1465\n",
            "13 / 45, train loss: 0.1015\n",
            "14 / 45, train loss: 0.1186\n",
            "15 / 45, train loss: 0.0778\n",
            "16 / 45, train loss: 0.1134\n",
            "17 / 45, train loss: 0.1473\n",
            "18 / 45, train loss: 0.1458\n",
            "19 / 45, train loss: 0.1147\n",
            "20 / 45, train loss: 0.1156\n",
            "21 / 45, train loss: 0.0882\n",
            "22 / 45, train loss: 0.1157\n",
            "23 / 45, train loss: 0.1007\n",
            "24 / 45, train loss: 0.1351\n",
            "25 / 45, train loss: 0.1333\n",
            "26 / 45, train loss: 0.1254\n",
            "27 / 45, train loss: 0.1272\n",
            "28 / 45, train loss: 0.1001\n",
            "29 / 45, train loss: 0.0671\n",
            "30 / 45, train loss: 0.0977\n",
            "31 / 45, train loss: 0.0862\n",
            "32 / 45, train loss: 0.1044\n",
            "33 / 45, train loss: 0.0645\n",
            "34 / 45, train loss: 0.0448\n",
            "35 / 45, train loss: 0.1269\n",
            "36 / 45, train loss: 0.1117\n",
            "37 / 45, train loss: 0.1040\n",
            "38 / 45, train loss: 0.1595\n",
            "39 / 45, train loss: 0.1236\n",
            "40 / 45, train loss: 0.1033\n",
            "41 / 45, train loss: 0.1107\n",
            "42 / 45, train loss: 0.1564\n",
            "43 / 45, train loss: 0.1715\n",
            "44 / 45, train loss: 0.1470\n",
            "45 / 45, train loss: 0.1586\n",
            "epoch 96 loss: 5.1359\n",
            "current learning rate: 0.000213\n",
            "Epoch 98 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.0879\n",
            "2 / 45, train loss: 0.0833\n",
            "3 / 45, train loss: 0.1339\n",
            "4 / 45, train loss: 0.0797\n",
            "5 / 45, train loss: 0.0960\n",
            "6 / 45, train loss: 0.0589\n",
            "7 / 45, train loss: 0.0654\n",
            "8 / 45, train loss: 0.1297\n",
            "9 / 45, train loss: 0.0827\n",
            "10 / 45, train loss: 0.1621\n",
            "11 / 45, train loss: 0.1035\n",
            "12 / 45, train loss: 0.1282\n",
            "13 / 45, train loss: 0.1158\n",
            "14 / 45, train loss: 0.0886\n",
            "15 / 45, train loss: 0.1046\n",
            "16 / 45, train loss: 0.1097\n",
            "17 / 45, train loss: 0.0853\n",
            "18 / 45, train loss: 0.0806\n",
            "19 / 45, train loss: 0.0843\n",
            "20 / 45, train loss: 0.1586\n",
            "21 / 45, train loss: 0.0740\n",
            "22 / 45, train loss: 0.1042\n",
            "23 / 45, train loss: 0.1536\n",
            "24 / 45, train loss: 0.1138\n",
            "25 / 45, train loss: 0.1322\n",
            "26 / 45, train loss: 0.1222\n",
            "27 / 45, train loss: 0.0682\n",
            "28 / 45, train loss: 0.2191\n",
            "29 / 45, train loss: 0.1698\n",
            "30 / 45, train loss: 0.0957\n",
            "31 / 45, train loss: 0.0772\n",
            "32 / 45, train loss: 0.1354\n",
            "33 / 45, train loss: 0.0881\n",
            "34 / 45, train loss: 0.0920\n",
            "35 / 45, train loss: 0.1137\n",
            "36 / 45, train loss: 0.1061\n",
            "37 / 45, train loss: 0.1743\n",
            "38 / 45, train loss: 0.1466\n",
            "39 / 45, train loss: 0.1101\n",
            "40 / 45, train loss: 0.2090\n",
            "41 / 45, train loss: 0.0946\n",
            "42 / 45, train loss: 0.1637\n",
            "43 / 45, train loss: 0.1147\n",
            "44 / 45, train loss: 0.0897\n",
            "45 / 45, train loss: 0.1286\n",
            "epoch 97 loss: 5.1354\n",
            "current learning rate: 0.000212\n",
            "Epoch 99 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1050\n",
            "2 / 45, train loss: 0.1590\n",
            "3 / 45, train loss: 0.0892\n",
            "4 / 45, train loss: 0.1809\n",
            "5 / 45, train loss: 0.1630\n",
            "6 / 45, train loss: 0.1073\n",
            "7 / 45, train loss: 0.1181\n",
            "8 / 45, train loss: 0.1237\n",
            "9 / 45, train loss: 0.0832\n",
            "10 / 45, train loss: 0.0910\n",
            "11 / 45, train loss: 0.1049\n",
            "12 / 45, train loss: 0.0817\n",
            "13 / 45, train loss: 0.1102\n",
            "14 / 45, train loss: 0.1013\n",
            "15 / 45, train loss: 0.0865\n",
            "16 / 45, train loss: 0.0861\n",
            "17 / 45, train loss: 0.0647\n",
            "18 / 45, train loss: 0.1074\n",
            "19 / 45, train loss: 0.1142\n",
            "20 / 45, train loss: 0.0930\n",
            "21 / 45, train loss: 0.0820\n",
            "22 / 45, train loss: 0.1177\n",
            "23 / 45, train loss: 0.1131\n",
            "24 / 45, train loss: 0.1508\n",
            "25 / 45, train loss: 0.0761\n",
            "26 / 45, train loss: 0.1706\n",
            "27 / 45, train loss: 0.1182\n",
            "28 / 45, train loss: 0.1368\n",
            "29 / 45, train loss: 0.1566\n",
            "30 / 45, train loss: 0.0772\n",
            "31 / 45, train loss: 0.0887\n",
            "32 / 45, train loss: 0.1266\n",
            "33 / 45, train loss: 0.0785\n",
            "34 / 45, train loss: 0.1324\n",
            "35 / 45, train loss: 0.1110\n",
            "36 / 45, train loss: 0.0678\n",
            "37 / 45, train loss: 0.1428\n",
            "38 / 45, train loss: 0.1279\n",
            "39 / 45, train loss: 0.1775\n",
            "40 / 45, train loss: 0.1074\n",
            "41 / 45, train loss: 0.1159\n",
            "42 / 45, train loss: 0.1339\n",
            "43 / 45, train loss: 0.1205\n",
            "44 / 45, train loss: 0.0797\n",
            "45 / 45, train loss: 0.1339\n",
            "epoch 98 loss: 5.1137\n",
            "current learning rate: 0.000211\n",
            "Epoch 100 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.0703\n",
            "2 / 45, train loss: 0.0794\n",
            "3 / 45, train loss: 0.1201\n",
            "4 / 45, train loss: 0.1588\n",
            "5 / 45, train loss: 0.0919\n",
            "6 / 45, train loss: 0.1245\n",
            "7 / 45, train loss: 0.1023\n",
            "8 / 45, train loss: 0.0881\n",
            "9 / 45, train loss: 0.1377\n",
            "10 / 45, train loss: 0.1416\n",
            "11 / 45, train loss: 0.0913\n",
            "12 / 45, train loss: 0.0684\n",
            "13 / 45, train loss: 0.0807\n",
            "14 / 45, train loss: 0.1475\n",
            "15 / 45, train loss: 0.1287\n",
            "16 / 45, train loss: 0.1195\n",
            "17 / 45, train loss: 0.0884\n",
            "18 / 45, train loss: 0.1070\n",
            "19 / 45, train loss: 0.0889\n",
            "20 / 45, train loss: 0.1090\n",
            "21 / 45, train loss: 0.1655\n",
            "22 / 45, train loss: 0.1439\n",
            "23 / 45, train loss: 0.1286\n",
            "24 / 45, train loss: 0.1104\n",
            "25 / 45, train loss: 0.1184\n",
            "26 / 45, train loss: 0.1204\n",
            "27 / 45, train loss: 0.1658\n",
            "28 / 45, train loss: 0.2251\n",
            "29 / 45, train loss: 0.1228\n",
            "30 / 45, train loss: 0.1074\n",
            "31 / 45, train loss: 0.1442\n",
            "32 / 45, train loss: 0.0769\n",
            "33 / 45, train loss: 0.0657\n",
            "34 / 45, train loss: 0.0901\n",
            "35 / 45, train loss: 0.0841\n",
            "36 / 45, train loss: 0.0734\n",
            "37 / 45, train loss: 0.1025\n",
            "38 / 45, train loss: 0.1078\n",
            "39 / 45, train loss: 0.1020\n",
            "40 / 45, train loss: 0.1211\n",
            "41 / 45, train loss: 0.1817\n",
            "42 / 45, train loss: 0.1258\n",
            "43 / 45, train loss: 0.1091\n",
            "44 / 45, train loss: 0.1626\n",
            "45 / 45, train loss: 0.0480\n",
            "epoch 99 loss: 5.1475\n",
            "current learning rate: 0.000210\n",
            "Loss - mean: 0.04925275640562177\tstd: 0.020459319553058502\n",
            "AUC - mean: 0.8586591936441063\tstd: 0.0456053995949848\n",
            "ACC - mean: 0.9042263031005859\tstd: 0.03443635071521239\n",
            "SEN - mean: 0.5021868939157295\tstd: 0.08128283366051352\n",
            "FDR - mean: 0.6701590274758297\tstd: 0.05287173109349252\n",
            "SPE - mean: 0.9315755932768647\tstd: 0.025115246347672357\n",
            "Kappa - mean: 0.34230585045524076\tstd: 0.04974094240933479\n",
            "G-mean - mean: 0.6813853607273157\tstd: 0.05685130404612192\n",
            "IOU - mean: 0.24479983067272063\tstd: 0.03512226804522771\n",
            "Dice - mean: 0.39195129307264903\tstd: 0.04843285900520028\n",
            "Loss - mean: 0.05004763797941533\tstd: 0.01967740499690126\n",
            "AUC - mean: 0.8419432901360859\tstd: 0.03849628819728166\n",
            "ACC - mean: 0.9022180383855646\tstd: 0.03196105560333887\n",
            "SEN - mean: 0.5069034557063492\tstd: 0.07803814978108287\n",
            "FDR - mean: 0.6790975186471594\tstd: 0.05466987300231189\n",
            "SPE - mean: 0.9295145676927187\tstd: 0.022451523430053456\n",
            "Kappa - mean: 0.33616176652565444\tstd: 0.04956021675895693\n",
            "G-mean - mean: 0.684195767709387\tstd: 0.054972832633862385\n",
            "IOU - mean: 0.24056792549918155\tstd: 0.03587418835862632\n",
            "Dice - mean: 0.3863807995965709\tstd: 0.05036839515760889\n",
            "Loss - mean: 0.050388248044658794\tstd: 0.019763189021598276\n",
            "AUC - mean: 0.844822125716645\tstd: 0.03940832669765275\n",
            "ACC - mean: 0.9012693925337358\tstd: 0.03340444198770091\n",
            "SEN - mean: 0.5140502056311677\tstd: 0.0802691932348658\n",
            "FDR - mean: 0.6793863833886359\tstd: 0.05322744191930583\n",
            "SPE - mean: 0.9278602820969596\tstd: 0.02432136475333036\n",
            "Kappa - mean: 0.3378343038627531\tstd: 0.04978585444665835\n",
            "G-mean - mean: 0.6882634701284995\tstd: 0.05601662967467128\n",
            "IOU - mean: 0.24215267145801447\tstd: 0.03562139116113631\n",
            "Dice - mean: 0.38846378103920465\tstd: 0.049874242740375094\n",
            "best thin: epoch 90\tauc 0.8595\n",
            "best thick: epoch 90\tauc 0.8583\n",
            "best fusion: epoch 90\tauc 0.8593\n",
            "Epoch 101 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1038\n",
            "2 / 45, train loss: 0.1841\n",
            "3 / 45, train loss: 0.0905\n",
            "4 / 45, train loss: 0.0723\n",
            "5 / 45, train loss: 0.0668\n",
            "6 / 45, train loss: 0.0712\n",
            "7 / 45, train loss: 0.1653\n",
            "8 / 45, train loss: 0.0965\n",
            "9 / 45, train loss: 0.0874\n",
            "10 / 45, train loss: 0.1261\n",
            "11 / 45, train loss: 0.0568\n",
            "12 / 45, train loss: 0.0963\n",
            "13 / 45, train loss: 0.1275\n",
            "14 / 45, train loss: 0.0958\n",
            "15 / 45, train loss: 0.1617\n",
            "16 / 45, train loss: 0.1089\n",
            "17 / 45, train loss: 0.0856\n",
            "18 / 45, train loss: 0.1640\n",
            "19 / 45, train loss: 0.1010\n",
            "20 / 45, train loss: 0.0753\n",
            "21 / 45, train loss: 0.1022\n",
            "22 / 45, train loss: 0.0682\n",
            "23 / 45, train loss: 0.0946\n",
            "24 / 45, train loss: 0.0697\n",
            "25 / 45, train loss: 0.1504\n",
            "26 / 45, train loss: 0.1818\n",
            "27 / 45, train loss: 0.0789\n",
            "28 / 45, train loss: 0.0874\n",
            "29 / 45, train loss: 0.1080\n",
            "30 / 45, train loss: 0.1868\n",
            "31 / 45, train loss: 0.0469\n",
            "32 / 45, train loss: 0.0766\n",
            "33 / 45, train loss: 0.1572\n",
            "34 / 45, train loss: 0.1128\n",
            "35 / 45, train loss: 0.1368\n",
            "36 / 45, train loss: 0.1192\n",
            "37 / 45, train loss: 0.1825\n",
            "38 / 45, train loss: 0.1092\n",
            "39 / 45, train loss: 0.1109\n",
            "40 / 45, train loss: 0.1475\n",
            "41 / 45, train loss: 0.1106\n",
            "42 / 45, train loss: 0.1161\n",
            "43 / 45, train loss: 0.1339\n",
            "44 / 45, train loss: 0.1364\n",
            "45 / 45, train loss: 0.1554\n",
            "epoch 100 loss: 5.1170\n",
            "current learning rate: 0.000209\n",
            "Epoch 102 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.0963\n",
            "2 / 45, train loss: 0.0878\n",
            "3 / 45, train loss: 0.1390\n",
            "4 / 45, train loss: 0.1624\n",
            "5 / 45, train loss: 0.0565\n",
            "6 / 45, train loss: 0.1059\n",
            "7 / 45, train loss: 0.1405\n",
            "8 / 45, train loss: 0.0850\n",
            "9 / 45, train loss: 0.1165\n",
            "10 / 45, train loss: 0.1503\n",
            "11 / 45, train loss: 0.1596\n",
            "12 / 45, train loss: 0.0489\n",
            "13 / 45, train loss: 0.0916\n",
            "14 / 45, train loss: 0.0746\n",
            "15 / 45, train loss: 0.0412\n",
            "16 / 45, train loss: 0.0672\n",
            "17 / 45, train loss: 0.1473\n",
            "18 / 45, train loss: 0.1014\n",
            "19 / 45, train loss: 0.1215\n",
            "20 / 45, train loss: 0.0689\n",
            "21 / 45, train loss: 0.0982\n",
            "22 / 45, train loss: 0.0834\n",
            "23 / 45, train loss: 0.1515\n",
            "24 / 45, train loss: 0.1025\n",
            "25 / 45, train loss: 0.1261\n",
            "26 / 45, train loss: 0.1550\n",
            "27 / 45, train loss: 0.0841\n",
            "28 / 45, train loss: 0.1010\n",
            "29 / 45, train loss: 0.0939\n",
            "30 / 45, train loss: 0.1308\n",
            "31 / 45, train loss: 0.1099\n",
            "32 / 45, train loss: 0.1811\n",
            "33 / 45, train loss: 0.1036\n",
            "34 / 45, train loss: 0.1546\n",
            "35 / 45, train loss: 0.1659\n",
            "36 / 45, train loss: 0.1040\n",
            "37 / 45, train loss: 0.1838\n",
            "38 / 45, train loss: 0.1502\n",
            "39 / 45, train loss: 0.0629\n",
            "40 / 45, train loss: 0.1371\n",
            "41 / 45, train loss: 0.1601\n",
            "42 / 45, train loss: 0.0903\n",
            "43 / 45, train loss: 0.1112\n",
            "44 / 45, train loss: 0.0917\n",
            "45 / 45, train loss: 0.1368\n",
            "epoch 101 loss: 5.1317\n",
            "current learning rate: 0.000208\n",
            "Epoch 103 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.0833\n",
            "2 / 45, train loss: 0.1123\n",
            "3 / 45, train loss: 0.1367\n",
            "4 / 45, train loss: 0.1012\n",
            "5 / 45, train loss: 0.0751\n",
            "6 / 45, train loss: 0.1346\n",
            "7 / 45, train loss: 0.1718\n",
            "8 / 45, train loss: 0.1240\n",
            "9 / 45, train loss: 0.1275\n",
            "10 / 45, train loss: 0.1480\n",
            "11 / 45, train loss: 0.1333\n",
            "12 / 45, train loss: 0.1114\n",
            "13 / 45, train loss: 0.0833\n",
            "14 / 45, train loss: 0.1045\n",
            "15 / 45, train loss: 0.1462\n",
            "16 / 45, train loss: 0.0751\n",
            "17 / 45, train loss: 0.1144\n",
            "18 / 45, train loss: 0.1254\n",
            "19 / 45, train loss: 0.1259\n",
            "20 / 45, train loss: 0.0514\n",
            "21 / 45, train loss: 0.0421\n",
            "22 / 45, train loss: 0.1571\n",
            "23 / 45, train loss: 0.0961\n",
            "24 / 45, train loss: 0.1393\n",
            "25 / 45, train loss: 0.1208\n",
            "26 / 45, train loss: 0.1621\n",
            "27 / 45, train loss: 0.0687\n",
            "28 / 45, train loss: 0.0905\n",
            "29 / 45, train loss: 0.1364\n",
            "30 / 45, train loss: 0.0981\n",
            "31 / 45, train loss: 0.1318\n",
            "32 / 45, train loss: 0.1451\n",
            "33 / 45, train loss: 0.1054\n",
            "34 / 45, train loss: 0.1000\n",
            "35 / 45, train loss: 0.1129\n",
            "36 / 45, train loss: 0.1201\n",
            "37 / 45, train loss: 0.1140\n",
            "38 / 45, train loss: 0.1265\n",
            "39 / 45, train loss: 0.1719\n",
            "40 / 45, train loss: 0.0955\n",
            "41 / 45, train loss: 0.0626\n",
            "42 / 45, train loss: 0.0950\n",
            "43 / 45, train loss: 0.1774\n",
            "44 / 45, train loss: 0.1183\n",
            "45 / 45, train loss: 0.0508\n",
            "epoch 102 loss: 5.1239\n",
            "current learning rate: 0.000207\n",
            "Epoch 104 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1115\n",
            "2 / 45, train loss: 0.0875\n",
            "3 / 45, train loss: 0.1200\n",
            "4 / 45, train loss: 0.0769\n",
            "5 / 45, train loss: 0.1405\n",
            "6 / 45, train loss: 0.0478\n",
            "7 / 45, train loss: 0.1070\n",
            "8 / 45, train loss: 0.1353\n",
            "9 / 45, train loss: 0.1290\n",
            "10 / 45, train loss: 0.1249\n",
            "11 / 45, train loss: 0.0720\n",
            "12 / 45, train loss: 0.0900\n",
            "13 / 45, train loss: 0.1813\n",
            "14 / 45, train loss: 0.1441\n",
            "15 / 45, train loss: 0.1437\n",
            "16 / 45, train loss: 0.0845\n",
            "17 / 45, train loss: 0.2002\n",
            "18 / 45, train loss: 0.0646\n",
            "19 / 45, train loss: 0.2093\n",
            "20 / 45, train loss: 0.1144\n",
            "21 / 45, train loss: 0.1128\n",
            "22 / 45, train loss: 0.0774\n",
            "23 / 45, train loss: 0.1447\n",
            "24 / 45, train loss: 0.1072\n",
            "25 / 45, train loss: 0.1422\n",
            "26 / 45, train loss: 0.0569\n",
            "27 / 45, train loss: 0.0505\n",
            "28 / 45, train loss: 0.1055\n",
            "29 / 45, train loss: 0.1156\n",
            "30 / 45, train loss: 0.1188\n",
            "31 / 45, train loss: 0.0917\n",
            "32 / 45, train loss: 0.0993\n",
            "33 / 45, train loss: 0.1532\n",
            "34 / 45, train loss: 0.1849\n",
            "35 / 45, train loss: 0.1192\n",
            "36 / 45, train loss: 0.1234\n",
            "37 / 45, train loss: 0.1272\n",
            "38 / 45, train loss: 0.1129\n",
            "39 / 45, train loss: 0.1054\n",
            "40 / 45, train loss: 0.1006\n",
            "41 / 45, train loss: 0.0921\n",
            "42 / 45, train loss: 0.1005\n",
            "43 / 45, train loss: 0.1220\n",
            "44 / 45, train loss: 0.0792\n",
            "45 / 45, train loss: 0.1121\n",
            "epoch 103 loss: 5.1399\n",
            "current learning rate: 0.000206\n",
            "Epoch 105 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.0785\n",
            "2 / 45, train loss: 0.1136\n",
            "3 / 45, train loss: 0.0885\n",
            "4 / 45, train loss: 0.1313\n",
            "5 / 45, train loss: 0.1168\n",
            "6 / 45, train loss: 0.0896\n",
            "7 / 45, train loss: 0.1593\n",
            "8 / 45, train loss: 0.1282\n",
            "9 / 45, train loss: 0.0630\n",
            "10 / 45, train loss: 0.0984\n",
            "11 / 45, train loss: 0.0816\n",
            "12 / 45, train loss: 0.1428\n",
            "13 / 45, train loss: 0.0847\n",
            "14 / 45, train loss: 0.0763\n",
            "15 / 45, train loss: 0.1258\n",
            "16 / 45, train loss: 0.1434\n",
            "17 / 45, train loss: 0.1285\n",
            "18 / 45, train loss: 0.1148\n",
            "19 / 45, train loss: 0.2047\n",
            "20 / 45, train loss: 0.0908\n",
            "21 / 45, train loss: 0.1005\n",
            "22 / 45, train loss: 0.1308\n",
            "23 / 45, train loss: 0.0619\n",
            "24 / 45, train loss: 0.1316\n",
            "25 / 45, train loss: 0.0627\n",
            "26 / 45, train loss: 0.1279\n",
            "27 / 45, train loss: 0.0859\n",
            "28 / 45, train loss: 0.1082\n",
            "29 / 45, train loss: 0.1299\n",
            "30 / 45, train loss: 0.1094\n",
            "31 / 45, train loss: 0.1179\n",
            "32 / 45, train loss: 0.0999\n",
            "33 / 45, train loss: 0.0954\n",
            "34 / 45, train loss: 0.0582\n",
            "35 / 45, train loss: 0.1344\n",
            "36 / 45, train loss: 0.1300\n",
            "37 / 45, train loss: 0.1501\n",
            "38 / 45, train loss: 0.1682\n",
            "39 / 45, train loss: 0.1032\n",
            "40 / 45, train loss: 0.1542\n",
            "41 / 45, train loss: 0.1717\n",
            "42 / 45, train loss: 0.1183\n",
            "43 / 45, train loss: 0.0969\n",
            "44 / 45, train loss: 0.0886\n",
            "45 / 45, train loss: 0.1297\n",
            "epoch 104 loss: 5.1261\n",
            "current learning rate: 0.000205\n",
            "Loss - mean: 0.04860058858652006\tstd: 0.020575823815836086\n",
            "AUC - mean: 0.8606882219827194\tstd: 0.04580924419619761\n",
            "ACC - mean: 0.9035011638294567\tstd: 0.034684320848026716\n",
            "SEN - mean: 0.51293140153062\tstd: 0.08366705075282861\n",
            "FDR - mean: 0.6720603328188011\tstd: 0.0477254921190993\n",
            "SPE - mean: 0.9301480112030887\tstd: 0.024980999279896283\n",
            "Kappa - mean: 0.34463974828460625\tstd: 0.045161774846425605\n",
            "G-mean - mean: 0.6881373386960367\tstd: 0.057828828250474903\n",
            "IOU - mean: 0.24670646125170836\tstd: 0.032052094872909775\n",
            "Dice - mean: 0.3946575379837713\tstd: 0.04344352553956554\n",
            "Loss - mean: 0.048623987812210216\tstd: 0.020623128416113135\n",
            "AUC - mean: 0.8601044206947425\tstd: 0.04586557400456411\n",
            "ACC - mean: 0.9021136543967507\tstd: 0.035871718023312835\n",
            "SEN - mean: 0.5171619066834505\tstd: 0.08278016555491927\n",
            "FDR - mean: 0.6751183808260273\tstd: 0.04605066520654296\n",
            "SPE - mean: 0.9281607003453516\tstd: 0.02643323566120649\n",
            "Kappa - mean: 0.3434617913758886\tstd: 0.04494650843383543\n",
            "G-mean - mean: 0.6902583511632258\tstd: 0.05711066001533689\n",
            "IOU - mean: 0.24627183818231876\tstd: 0.03193982952396954\n",
            "Dice - mean: 0.3941069547520825\tstd: 0.04323289739994605\n",
            "Loss - mean: 0.04863019537349993\tstd: 0.02050320155582554\n",
            "AUC - mean: 0.8609264737135944\tstd: 0.045902473395739274\n",
            "ACC - mean: 0.9003595872358843\tstd: 0.03586981040307692\n",
            "SEN - mean: 0.525864443603554\tstd: 0.08435178946991188\n",
            "FDR - mean: 0.6791961496442395\tstd: 0.04670054957593695\n",
            "SPE - mean: 0.9257668658326594\tstd: 0.02682111260694418\n",
            "Kappa - mean: 0.3420335678743534\tstd: 0.044664401773624025\n",
            "G-mean - mean: 0.6951434759608818\tstd: 0.057473730089416974\n",
            "IOU - mean: 0.24561923261866522\tstd: 0.03196109857490971\n",
            "Dice - mean: 0.3932618441939862\tstd: 0.04335368477325783\n",
            "best thin: epoch 105\tauc 0.8607\n",
            "best thick: epoch 105\tauc 0.8601\n",
            "best fusion: epoch 105\tauc 0.8609\n",
            "Epoch 106 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.0887\n",
            "2 / 45, train loss: 0.0820\n",
            "3 / 45, train loss: 0.0919\n",
            "4 / 45, train loss: 0.1678\n",
            "5 / 45, train loss: 0.1228\n",
            "6 / 45, train loss: 0.1296\n",
            "7 / 45, train loss: 0.0847\n",
            "8 / 45, train loss: 0.1116\n",
            "9 / 45, train loss: 0.1131\n",
            "10 / 45, train loss: 0.0860\n",
            "11 / 45, train loss: 0.1246\n",
            "12 / 45, train loss: 0.1145\n",
            "13 / 45, train loss: 0.0575\n",
            "14 / 45, train loss: 0.0874\n",
            "15 / 45, train loss: 0.1206\n",
            "16 / 45, train loss: 0.0994\n",
            "17 / 45, train loss: 0.0671\n",
            "18 / 45, train loss: 0.1021\n",
            "19 / 45, train loss: 0.1684\n",
            "20 / 45, train loss: 0.1153\n",
            "21 / 45, train loss: 0.1618\n",
            "22 / 45, train loss: 0.1279\n",
            "23 / 45, train loss: 0.1312\n",
            "24 / 45, train loss: 0.1164\n",
            "25 / 45, train loss: 0.1061\n",
            "26 / 45, train loss: 0.1511\n",
            "27 / 45, train loss: 0.1275\n",
            "28 / 45, train loss: 0.0879\n",
            "29 / 45, train loss: 0.0856\n",
            "30 / 45, train loss: 0.1131\n",
            "31 / 45, train loss: 0.0995\n",
            "32 / 45, train loss: 0.1354\n",
            "33 / 45, train loss: 0.1057\n",
            "34 / 45, train loss: 0.1256\n",
            "35 / 45, train loss: 0.1260\n",
            "36 / 45, train loss: 0.1404\n",
            "37 / 45, train loss: 0.1367\n",
            "38 / 45, train loss: 0.1479\n",
            "39 / 45, train loss: 0.0823\n",
            "40 / 45, train loss: 0.0920\n",
            "41 / 45, train loss: 0.0754\n",
            "42 / 45, train loss: 0.1349\n",
            "43 / 45, train loss: 0.1512\n",
            "44 / 45, train loss: 0.0763\n",
            "45 / 45, train loss: 0.1435\n",
            "epoch 105 loss: 5.1168\n",
            "current learning rate: 0.000205\n",
            "Epoch 107 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.0708\n",
            "2 / 45, train loss: 0.0721\n",
            "3 / 45, train loss: 0.1641\n",
            "4 / 45, train loss: 0.1203\n",
            "5 / 45, train loss: 0.1263\n",
            "6 / 45, train loss: 0.1126\n",
            "7 / 45, train loss: 0.0580\n",
            "8 / 45, train loss: 0.1096\n",
            "9 / 45, train loss: 0.1341\n",
            "10 / 45, train loss: 0.0588\n",
            "11 / 45, train loss: 0.1559\n",
            "12 / 45, train loss: 0.1602\n",
            "13 / 45, train loss: 0.1546\n",
            "14 / 45, train loss: 0.0667\n",
            "15 / 45, train loss: 0.1868\n",
            "16 / 45, train loss: 0.0698\n",
            "17 / 45, train loss: 0.1049\n",
            "18 / 45, train loss: 0.1359\n",
            "19 / 45, train loss: 0.1430\n",
            "20 / 45, train loss: 0.1017\n",
            "21 / 45, train loss: 0.1382\n",
            "22 / 45, train loss: 0.1026\n",
            "23 / 45, train loss: 0.1425\n",
            "24 / 45, train loss: 0.1562\n",
            "25 / 45, train loss: 0.0738\n",
            "26 / 45, train loss: 0.0902\n",
            "27 / 45, train loss: 0.1461\n",
            "28 / 45, train loss: 0.0934\n",
            "29 / 45, train loss: 0.1763\n",
            "30 / 45, train loss: 0.0957\n",
            "31 / 45, train loss: 0.1404\n",
            "32 / 45, train loss: 0.0528\n",
            "33 / 45, train loss: 0.0511\n",
            "34 / 45, train loss: 0.1155\n",
            "35 / 45, train loss: 0.1544\n",
            "36 / 45, train loss: 0.1066\n",
            "37 / 45, train loss: 0.0948\n",
            "38 / 45, train loss: 0.1007\n",
            "39 / 45, train loss: 0.0906\n",
            "40 / 45, train loss: 0.1595\n",
            "41 / 45, train loss: 0.1201\n",
            "42 / 45, train loss: 0.1237\n",
            "43 / 45, train loss: 0.1106\n",
            "44 / 45, train loss: 0.0780\n",
            "45 / 45, train loss: 0.1164\n",
            "epoch 106 loss: 5.1362\n",
            "current learning rate: 0.000204\n",
            "Epoch 108 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.0790\n",
            "2 / 45, train loss: 0.0687\n",
            "3 / 45, train loss: 0.1025\n",
            "4 / 45, train loss: 0.1453\n",
            "5 / 45, train loss: 0.1518\n",
            "6 / 45, train loss: 0.1206\n",
            "7 / 45, train loss: 0.0867\n",
            "8 / 45, train loss: 0.1639\n",
            "9 / 45, train loss: 0.1347\n",
            "10 / 45, train loss: 0.1296\n",
            "11 / 45, train loss: 0.1314\n",
            "12 / 45, train loss: 0.1109\n",
            "13 / 45, train loss: 0.1497\n",
            "14 / 45, train loss: 0.1232\n",
            "15 / 45, train loss: 0.0865\n",
            "16 / 45, train loss: 0.1451\n",
            "17 / 45, train loss: 0.1183\n",
            "18 / 45, train loss: 0.1121\n",
            "19 / 45, train loss: 0.1648\n",
            "20 / 45, train loss: 0.1250\n",
            "21 / 45, train loss: 0.0842\n",
            "22 / 45, train loss: 0.1521\n",
            "23 / 45, train loss: 0.0899\n",
            "24 / 45, train loss: 0.0722\n",
            "25 / 45, train loss: 0.1120\n",
            "26 / 45, train loss: 0.1178\n",
            "27 / 45, train loss: 0.1393\n",
            "28 / 45, train loss: 0.0989\n",
            "29 / 45, train loss: 0.1119\n",
            "30 / 45, train loss: 0.0956\n",
            "31 / 45, train loss: 0.0700\n",
            "32 / 45, train loss: 0.0914\n",
            "33 / 45, train loss: 0.1503\n",
            "34 / 45, train loss: 0.1021\n",
            "35 / 45, train loss: 0.1154\n",
            "36 / 45, train loss: 0.0865\n",
            "37 / 45, train loss: 0.0839\n",
            "38 / 45, train loss: 0.1044\n",
            "39 / 45, train loss: 0.0900\n",
            "40 / 45, train loss: 0.1051\n",
            "41 / 45, train loss: 0.0813\n",
            "42 / 45, train loss: 0.1107\n",
            "43 / 45, train loss: 0.1246\n",
            "44 / 45, train loss: 0.1323\n",
            "45 / 45, train loss: 0.1226\n",
            "epoch 107 loss: 5.0943\n",
            "current learning rate: 0.000203\n",
            "Epoch 109 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.0761\n",
            "2 / 45, train loss: 0.1268\n",
            "3 / 45, train loss: 0.1163\n",
            "4 / 45, train loss: 0.1808\n",
            "5 / 45, train loss: 0.1497\n",
            "6 / 45, train loss: 0.1054\n",
            "7 / 45, train loss: 0.1568\n",
            "8 / 45, train loss: 0.1137\n",
            "9 / 45, train loss: 0.1378\n",
            "10 / 45, train loss: 0.0868\n",
            "11 / 45, train loss: 0.1078\n",
            "12 / 45, train loss: 0.1103\n",
            "13 / 45, train loss: 0.1051\n",
            "14 / 45, train loss: 0.1248\n",
            "15 / 45, train loss: 0.0828\n",
            "16 / 45, train loss: 0.1232\n",
            "17 / 45, train loss: 0.1428\n",
            "18 / 45, train loss: 0.0874\n",
            "19 / 45, train loss: 0.1189\n",
            "20 / 45, train loss: 0.0840\n",
            "21 / 45, train loss: 0.1923\n",
            "22 / 45, train loss: 0.0904\n",
            "23 / 45, train loss: 0.1568\n",
            "24 / 45, train loss: 0.1116\n",
            "25 / 45, train loss: 0.1336\n",
            "26 / 45, train loss: 0.0689\n",
            "27 / 45, train loss: 0.1135\n",
            "28 / 45, train loss: 0.1345\n",
            "29 / 45, train loss: 0.1370\n",
            "30 / 45, train loss: 0.0748\n",
            "31 / 45, train loss: 0.1095\n",
            "32 / 45, train loss: 0.0756\n",
            "33 / 45, train loss: 0.1375\n",
            "34 / 45, train loss: 0.0646\n",
            "35 / 45, train loss: 0.1032\n",
            "36 / 45, train loss: 0.0558\n",
            "37 / 45, train loss: 0.0836\n",
            "38 / 45, train loss: 0.0973\n",
            "39 / 45, train loss: 0.1163\n",
            "40 / 45, train loss: 0.1333\n",
            "41 / 45, train loss: 0.1024\n",
            "42 / 45, train loss: 0.0854\n",
            "43 / 45, train loss: 0.1654\n",
            "44 / 45, train loss: 0.1526\n",
            "45 / 45, train loss: 0.0782\n",
            "epoch 108 loss: 5.1111\n",
            "current learning rate: 0.000202\n",
            "Epoch 110 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1127\n",
            "2 / 45, train loss: 0.1553\n",
            "3 / 45, train loss: 0.1060\n",
            "4 / 45, train loss: 0.0986\n",
            "5 / 45, train loss: 0.0765\n",
            "6 / 45, train loss: 0.0651\n",
            "7 / 45, train loss: 0.0972\n",
            "8 / 45, train loss: 0.1005\n",
            "9 / 45, train loss: 0.1095\n",
            "10 / 45, train loss: 0.1199\n",
            "11 / 45, train loss: 0.1082\n",
            "12 / 45, train loss: 0.1765\n",
            "13 / 45, train loss: 0.1519\n",
            "14 / 45, train loss: 0.1006\n",
            "15 / 45, train loss: 0.1260\n",
            "16 / 45, train loss: 0.1132\n",
            "17 / 45, train loss: 0.0906\n",
            "18 / 45, train loss: 0.1101\n",
            "19 / 45, train loss: 0.1269\n",
            "20 / 45, train loss: 0.1885\n",
            "21 / 45, train loss: 0.0941\n",
            "22 / 45, train loss: 0.0482\n",
            "23 / 45, train loss: 0.1653\n",
            "24 / 45, train loss: 0.1461\n",
            "25 / 45, train loss: 0.0907\n",
            "26 / 45, train loss: 0.1154\n",
            "27 / 45, train loss: 0.1207\n",
            "28 / 45, train loss: 0.1372\n",
            "29 / 45, train loss: 0.0797\n",
            "30 / 45, train loss: 0.1450\n",
            "31 / 45, train loss: 0.1168\n",
            "32 / 45, train loss: 0.0800\n",
            "33 / 45, train loss: 0.0508\n",
            "34 / 45, train loss: 0.1287\n",
            "35 / 45, train loss: 0.1617\n",
            "36 / 45, train loss: 0.1026\n",
            "37 / 45, train loss: 0.1350\n",
            "38 / 45, train loss: 0.1285\n",
            "39 / 45, train loss: 0.0905\n",
            "40 / 45, train loss: 0.0789\n",
            "41 / 45, train loss: 0.1311\n",
            "42 / 45, train loss: 0.1117\n",
            "43 / 45, train loss: 0.1466\n",
            "44 / 45, train loss: 0.1091\n",
            "45 / 45, train loss: 0.0723\n",
            "epoch 109 loss: 5.1208\n",
            "current learning rate: 0.000201\n",
            "Loss - mean: 0.048697606956755575\tstd: 0.020830444549031303\n",
            "AUC - mean: 0.8590168044186999\tstd: 0.0465272955450694\n",
            "ACC - mean: 0.9151420593261719\tstd: 0.0319178774668703\n",
            "SEN - mean: 0.45060967012432834\tstd: 0.08177424197968798\n",
            "FDR - mean: 0.6361660442300191\tstd: 0.05695445213593454\n",
            "SPE - mean: 0.9469971712510801\tstd: 0.0206903543637067\n",
            "Kappa - mean: 0.3503896648776414\tstd: 0.05369956807034734\n",
            "G-mean - mean: 0.6502009261822939\tstd: 0.06075329138215738\n",
            "IOU - mean: 0.24746357744560274\tstd: 0.0374201848000965\n",
            "Dice - mean: 0.3952288010722811\tstd: 0.05066245822095188\n",
            "Loss - mean: 0.0488346268592233\tstd: 0.020703025444708947\n",
            "AUC - mean: 0.8575460896397078\tstd: 0.04585434089124492\n",
            "ACC - mean: 0.9140222722833807\tstd: 0.032219068843121965\n",
            "SEN - mean: 0.454932056168237\tstd: 0.08223783917259928\n",
            "FDR - mean: 0.6407641040703591\tstd: 0.05601315588120887\n",
            "SPE - mean: 0.9455166178153387\tstd: 0.02104980949977304\n",
            "Kappa - mean: 0.34881781160116376\tstd: 0.053089848886328984\n",
            "G-mean - mean: 0.6528213165781614\tstd: 0.06098043200066488\n",
            "IOU - mean: 0.24664247466725978\tstd: 0.036919851970003095\n",
            "Dice - mean: 0.3942121413632959\tstd: 0.04998447709571487\n",
            "Loss - mean: 0.0487288979136131\tstd: 0.02060880270408313\n",
            "AUC - mean: 0.8582891899552737\tstd: 0.04585948535229492\n",
            "ACC - mean: 0.9128339940851385\tstd: 0.03244221601681099\n",
            "SEN - mean: 0.4632890338611968\tstd: 0.0833191617349489\n",
            "FDR - mean: 0.6444759019030356\tstd: 0.05565274170260742\n",
            "SPE - mean: 0.9436550892237492\tstd: 0.02157318159417978\n",
            "Kappa - mean: 0.34918126241625586\tstd: 0.05269224166737822\n",
            "G-mean - mean: 0.6581783379596402\tstd: 0.060995924836131525\n",
            "IOU - mean: 0.24734271045069428\tstd: 0.03677085664184607\n",
            "Dice - mean: 0.39512338779701817\tstd: 0.04985682022738794\n",
            "best thin: epoch 105\tauc 0.8607\n",
            "best thick: epoch 105\tauc 0.8601\n",
            "best fusion: epoch 105\tauc 0.8609\n",
            "Epoch 111 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1236\n",
            "2 / 45, train loss: 0.1463\n",
            "3 / 45, train loss: 0.1211\n",
            "4 / 45, train loss: 0.1157\n",
            "5 / 45, train loss: 0.0904\n",
            "6 / 45, train loss: 0.1186\n",
            "7 / 45, train loss: 0.1425\n",
            "8 / 45, train loss: 0.1291\n",
            "9 / 45, train loss: 0.0786\n",
            "10 / 45, train loss: 0.1144\n",
            "11 / 45, train loss: 0.0919\n",
            "12 / 45, train loss: 0.0873\n",
            "13 / 45, train loss: 0.1496\n",
            "14 / 45, train loss: 0.0821\n",
            "15 / 45, train loss: 0.0892\n",
            "16 / 45, train loss: 0.0881\n",
            "17 / 45, train loss: 0.0983\n",
            "18 / 45, train loss: 0.0938\n",
            "19 / 45, train loss: 0.1520\n",
            "20 / 45, train loss: 0.1268\n",
            "21 / 45, train loss: 0.1049\n",
            "22 / 45, train loss: 0.1165\n",
            "23 / 45, train loss: 0.1044\n",
            "24 / 45, train loss: 0.1261\n",
            "25 / 45, train loss: 0.0885\n",
            "26 / 45, train loss: 0.1636\n",
            "27 / 45, train loss: 0.1770\n",
            "28 / 45, train loss: 0.0665\n",
            "29 / 45, train loss: 0.0746\n",
            "30 / 45, train loss: 0.0935\n",
            "31 / 45, train loss: 0.1332\n",
            "32 / 45, train loss: 0.1763\n",
            "33 / 45, train loss: 0.0892\n",
            "34 / 45, train loss: 0.0603\n",
            "35 / 45, train loss: 0.0879\n",
            "36 / 45, train loss: 0.0896\n",
            "37 / 45, train loss: 0.1292\n",
            "38 / 45, train loss: 0.1038\n",
            "39 / 45, train loss: 0.1582\n",
            "40 / 45, train loss: 0.1284\n",
            "41 / 45, train loss: 0.1831\n",
            "42 / 45, train loss: 0.1378\n",
            "43 / 45, train loss: 0.1004\n",
            "44 / 45, train loss: 0.0794\n",
            "45 / 45, train loss: 0.1047\n",
            "epoch 110 loss: 5.1165\n",
            "current learning rate: 0.000200\n",
            "Epoch 112 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.0823\n",
            "2 / 45, train loss: 0.0864\n",
            "3 / 45, train loss: 0.1141\n",
            "4 / 45, train loss: 0.1545\n",
            "5 / 45, train loss: 0.1506\n",
            "6 / 45, train loss: 0.1320\n",
            "7 / 45, train loss: 0.1679\n",
            "8 / 45, train loss: 0.0610\n",
            "9 / 45, train loss: 0.1351\n",
            "10 / 45, train loss: 0.0801\n",
            "11 / 45, train loss: 0.0796\n",
            "12 / 45, train loss: 0.1137\n",
            "13 / 45, train loss: 0.0790\n",
            "14 / 45, train loss: 0.0892\n",
            "15 / 45, train loss: 0.1120\n",
            "16 / 45, train loss: 0.0787\n",
            "17 / 45, train loss: 0.0879\n",
            "18 / 45, train loss: 0.1337\n",
            "19 / 45, train loss: 0.1331\n",
            "20 / 45, train loss: 0.0894\n",
            "21 / 45, train loss: 0.0991\n",
            "22 / 45, train loss: 0.1347\n",
            "23 / 45, train loss: 0.1061\n",
            "24 / 45, train loss: 0.1329\n",
            "25 / 45, train loss: 0.1374\n",
            "26 / 45, train loss: 0.1371\n",
            "27 / 45, train loss: 0.0793\n",
            "28 / 45, train loss: 0.1399\n",
            "29 / 45, train loss: 0.0935\n",
            "30 / 45, train loss: 0.1589\n",
            "31 / 45, train loss: 0.1127\n",
            "32 / 45, train loss: 0.0817\n",
            "33 / 45, train loss: 0.0958\n",
            "34 / 45, train loss: 0.0758\n",
            "35 / 45, train loss: 0.0904\n",
            "36 / 45, train loss: 0.1275\n",
            "37 / 45, train loss: 0.1947\n",
            "38 / 45, train loss: 0.1240\n",
            "39 / 45, train loss: 0.1357\n",
            "40 / 45, train loss: 0.1283\n",
            "41 / 45, train loss: 0.1417\n",
            "42 / 45, train loss: 0.1353\n",
            "43 / 45, train loss: 0.1235\n",
            "44 / 45, train loss: 0.0875\n",
            "45 / 45, train loss: 0.0947\n",
            "epoch 111 loss: 5.1284\n",
            "current learning rate: 0.000199\n",
            "Epoch 113 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.0955\n",
            "2 / 45, train loss: 0.1453\n",
            "3 / 45, train loss: 0.1236\n",
            "4 / 45, train loss: 0.0799\n",
            "5 / 45, train loss: 0.1509\n",
            "6 / 45, train loss: 0.1367\n",
            "7 / 45, train loss: 0.1758\n",
            "8 / 45, train loss: 0.1206\n",
            "9 / 45, train loss: 0.0855\n",
            "10 / 45, train loss: 0.1037\n",
            "11 / 45, train loss: 0.1438\n",
            "12 / 45, train loss: 0.0703\n",
            "13 / 45, train loss: 0.1676\n",
            "14 / 45, train loss: 0.1070\n",
            "15 / 45, train loss: 0.1481\n",
            "16 / 45, train loss: 0.0893\n",
            "17 / 45, train loss: 0.0376\n",
            "18 / 45, train loss: 0.1066\n",
            "19 / 45, train loss: 0.1010\n",
            "20 / 45, train loss: 0.1608\n",
            "21 / 45, train loss: 0.0908\n",
            "22 / 45, train loss: 0.1412\n",
            "23 / 45, train loss: 0.0733\n",
            "24 / 45, train loss: 0.1325\n",
            "25 / 45, train loss: 0.1436\n",
            "26 / 45, train loss: 0.0893\n",
            "27 / 45, train loss: 0.1283\n",
            "28 / 45, train loss: 0.0815\n",
            "29 / 45, train loss: 0.1023\n",
            "30 / 45, train loss: 0.0997\n",
            "31 / 45, train loss: 0.1101\n",
            "32 / 45, train loss: 0.1331\n",
            "33 / 45, train loss: 0.1491\n",
            "34 / 45, train loss: 0.0946\n",
            "35 / 45, train loss: 0.0924\n",
            "36 / 45, train loss: 0.0717\n",
            "37 / 45, train loss: 0.0754\n",
            "38 / 45, train loss: 0.1156\n",
            "39 / 45, train loss: 0.0972\n",
            "40 / 45, train loss: 0.1463\n",
            "41 / 45, train loss: 0.1372\n",
            "42 / 45, train loss: 0.0694\n",
            "43 / 45, train loss: 0.1576\n",
            "44 / 45, train loss: 0.1050\n",
            "45 / 45, train loss: 0.1376\n",
            "epoch 112 loss: 5.1245\n",
            "current learning rate: 0.000198\n",
            "Epoch 114 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1440\n",
            "2 / 45, train loss: 0.1430\n",
            "3 / 45, train loss: 0.0815\n",
            "4 / 45, train loss: 0.1350\n",
            "5 / 45, train loss: 0.2012\n",
            "6 / 45, train loss: 0.1135\n",
            "7 / 45, train loss: 0.1304\n",
            "8 / 45, train loss: 0.1398\n",
            "9 / 45, train loss: 0.1006\n",
            "10 / 45, train loss: 0.0943\n",
            "11 / 45, train loss: 0.1184\n",
            "12 / 45, train loss: 0.1341\n",
            "13 / 45, train loss: 0.1016\n",
            "14 / 45, train loss: 0.1570\n",
            "15 / 45, train loss: 0.0462\n",
            "16 / 45, train loss: 0.0874\n",
            "17 / 45, train loss: 0.1614\n",
            "18 / 45, train loss: 0.1200\n",
            "19 / 45, train loss: 0.1784\n",
            "20 / 45, train loss: 0.0777\n",
            "21 / 45, train loss: 0.1234\n",
            "22 / 45, train loss: 0.0921\n",
            "23 / 45, train loss: 0.1019\n",
            "24 / 45, train loss: 0.0611\n",
            "25 / 45, train loss: 0.0910\n",
            "26 / 45, train loss: 0.1108\n",
            "27 / 45, train loss: 0.1488\n",
            "28 / 45, train loss: 0.1020\n",
            "29 / 45, train loss: 0.1010\n",
            "30 / 45, train loss: 0.1492\n",
            "31 / 45, train loss: 0.1069\n",
            "32 / 45, train loss: 0.0707\n",
            "33 / 45, train loss: 0.1294\n",
            "34 / 45, train loss: 0.1601\n",
            "35 / 45, train loss: 0.0995\n",
            "36 / 45, train loss: 0.1060\n",
            "37 / 45, train loss: 0.1193\n",
            "38 / 45, train loss: 0.0581\n",
            "39 / 45, train loss: 0.1314\n",
            "40 / 45, train loss: 0.1126\n",
            "41 / 45, train loss: 0.0884\n",
            "42 / 45, train loss: 0.1136\n",
            "43 / 45, train loss: 0.0872\n",
            "44 / 45, train loss: 0.1424\n",
            "45 / 45, train loss: 0.0536\n",
            "epoch 113 loss: 5.1260\n",
            "current learning rate: 0.000197\n",
            "Epoch 115 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1304\n",
            "2 / 45, train loss: 0.1191\n",
            "3 / 45, train loss: 0.0873\n",
            "4 / 45, train loss: 0.0974\n",
            "5 / 45, train loss: 0.1120\n",
            "6 / 45, train loss: 0.1352\n",
            "7 / 45, train loss: 0.1143\n",
            "8 / 45, train loss: 0.0994\n",
            "9 / 45, train loss: 0.0810\n",
            "10 / 45, train loss: 0.1123\n",
            "11 / 45, train loss: 0.0881\n",
            "12 / 45, train loss: 0.1233\n",
            "13 / 45, train loss: 0.1145\n",
            "14 / 45, train loss: 0.0709\n",
            "15 / 45, train loss: 0.1082\n",
            "16 / 45, train loss: 0.1157\n",
            "17 / 45, train loss: 0.1199\n",
            "18 / 45, train loss: 0.0872\n",
            "19 / 45, train loss: 0.1716\n",
            "20 / 45, train loss: 0.1542\n",
            "21 / 45, train loss: 0.1704\n",
            "22 / 45, train loss: 0.1058\n",
            "23 / 45, train loss: 0.1030\n",
            "24 / 45, train loss: 0.0938\n",
            "25 / 45, train loss: 0.0515\n",
            "26 / 45, train loss: 0.1600\n",
            "27 / 45, train loss: 0.0695\n",
            "28 / 45, train loss: 0.2040\n",
            "29 / 45, train loss: 0.1456\n",
            "30 / 45, train loss: 0.0805\n",
            "31 / 45, train loss: 0.1165\n",
            "32 / 45, train loss: 0.0759\n",
            "33 / 45, train loss: 0.1133\n",
            "34 / 45, train loss: 0.1070\n",
            "35 / 45, train loss: 0.1295\n",
            "36 / 45, train loss: 0.0681\n",
            "37 / 45, train loss: 0.0998\n",
            "38 / 45, train loss: 0.0987\n",
            "39 / 45, train loss: 0.1383\n",
            "40 / 45, train loss: 0.1257\n",
            "41 / 45, train loss: 0.1600\n",
            "42 / 45, train loss: 0.0901\n",
            "43 / 45, train loss: 0.1530\n",
            "44 / 45, train loss: 0.1032\n",
            "45 / 45, train loss: 0.0967\n",
            "epoch 114 loss: 5.1019\n",
            "current learning rate: 0.000196\n",
            "Loss - mean: 0.04879929303106936\tstd: 0.02054295795242618\n",
            "AUC - mean: 0.8586686637091941\tstd: 0.04535097044922224\n",
            "ACC - mean: 0.9034671783447266\tstd: 0.0371660846440076\n",
            "SEN - mean: 0.5019743068970738\tstd: 0.08946182028529955\n",
            "FDR - mean: 0.6686155280994643\tstd: 0.05067341666737202\n",
            "SPE - mean: 0.9302511126765456\tstd: 0.02886311231851653\n",
            "Kappa - mean: 0.3421522928168799\tstd: 0.04562650323500607\n",
            "G-mean - mean: 0.6798941063623194\tstd: 0.0613057618441885\n",
            "IOU - mean: 0.24481395367973866\tstd: 0.0326114355026222\n",
            "Dice - mean: 0.3921726222731305\tstd: 0.04438039128635476\n",
            "Loss - mean: 0.04878604788841172\tstd: 0.020536504371535105\n",
            "AUC - mean: 0.8581674748487624\tstd: 0.04532319832978817\n",
            "ACC - mean: 0.9065862135453657\tstd: 0.03596080847472124\n",
            "SEN - mean: 0.48768420053797995\tstd: 0.0874354751766037\n",
            "FDR - mean: 0.6611596594046717\tstd: 0.05089863955235047\n",
            "SPE - mean: 0.9346281936346216\tstd: 0.02697311939963521\n",
            "Kappa - mean: 0.3440535005971181\tstd: 0.04617326076592562\n",
            "G-mean - mean: 0.6717204581885976\tstd: 0.0612848290249436\n",
            "IOU - mean: 0.24535930491522537\tstd: 0.03315037608030382\n",
            "Dice - mean: 0.39284035237808934\tstd: 0.04502389599474695\n",
            "Loss - mean: 0.048894597344439135\tstd: 0.02048871214150267\n",
            "AUC - mean: 0.8590158194916175\tstd: 0.045365269238970836\n",
            "ACC - mean: 0.9024831598455255\tstd: 0.037463224728854584\n",
            "SEN - mean: 0.5071476692427025\tstd: 0.08990287094325028\n",
            "FDR - mean: 0.6714130963567286\tstd: 0.04906183977802525\n",
            "SPE - mean: 0.9288138641948908\tstd: 0.02930069395514079\n",
            "Kappa - mean: 0.34159992508983233\tstd: 0.044644212981867014\n",
            "G-mean - mean: 0.6828892786575239\tstd: 0.06126060565180084\n",
            "IOU - mean: 0.24467005045877704\tstd: 0.03215540524930056\n",
            "Dice - mean: 0.39202010733667725\tstd: 0.04371572640024472\n",
            "best thin: epoch 105\tauc 0.8607\n",
            "best thick: epoch 105\tauc 0.8601\n",
            "best fusion: epoch 105\tauc 0.8609\n",
            "Epoch 116 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1689\n",
            "2 / 45, train loss: 0.1059\n",
            "3 / 45, train loss: 0.0965\n",
            "4 / 45, train loss: 0.0900\n",
            "5 / 45, train loss: 0.0996\n",
            "6 / 45, train loss: 0.1077\n",
            "7 / 45, train loss: 0.1084\n",
            "8 / 45, train loss: 0.1453\n",
            "9 / 45, train loss: 0.1001\n",
            "10 / 45, train loss: 0.0703\n",
            "11 / 45, train loss: 0.1115\n",
            "12 / 45, train loss: 0.1307\n",
            "13 / 45, train loss: 0.1246\n",
            "14 / 45, train loss: 0.2207\n",
            "15 / 45, train loss: 0.1178\n",
            "16 / 45, train loss: 0.0852\n",
            "17 / 45, train loss: 0.1530\n",
            "18 / 45, train loss: 0.1286\n",
            "19 / 45, train loss: 0.1099\n",
            "20 / 45, train loss: 0.1448\n",
            "21 / 45, train loss: 0.1359\n",
            "22 / 45, train loss: 0.0713\n",
            "23 / 45, train loss: 0.0595\n",
            "24 / 45, train loss: 0.0997\n",
            "25 / 45, train loss: 0.1172\n",
            "26 / 45, train loss: 0.0735\n",
            "27 / 45, train loss: 0.0639\n",
            "28 / 45, train loss: 0.1401\n",
            "29 / 45, train loss: 0.1414\n",
            "30 / 45, train loss: 0.1119\n",
            "31 / 45, train loss: 0.1218\n",
            "32 / 45, train loss: 0.1531\n",
            "33 / 45, train loss: 0.1297\n",
            "34 / 45, train loss: 0.1177\n",
            "35 / 45, train loss: 0.0753\n",
            "36 / 45, train loss: 0.1063\n",
            "37 / 45, train loss: 0.1195\n",
            "38 / 45, train loss: 0.1237\n",
            "39 / 45, train loss: 0.0737\n",
            "40 / 45, train loss: 0.1021\n",
            "41 / 45, train loss: 0.0850\n",
            "42 / 45, train loss: 0.1570\n",
            "43 / 45, train loss: 0.1245\n",
            "44 / 45, train loss: 0.1305\n",
            "45 / 45, train loss: 0.0747\n",
            "epoch 115 loss: 5.1287\n",
            "current learning rate: 0.000195\n",
            "Epoch 117 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1337\n",
            "2 / 45, train loss: 0.0663\n",
            "3 / 45, train loss: 0.1008\n",
            "4 / 45, train loss: 0.1069\n",
            "5 / 45, train loss: 0.0862\n",
            "6 / 45, train loss: 0.0737\n",
            "7 / 45, train loss: 0.1318\n",
            "8 / 45, train loss: 0.1086\n",
            "9 / 45, train loss: 0.1551\n",
            "10 / 45, train loss: 0.1572\n",
            "11 / 45, train loss: 0.0678\n",
            "12 / 45, train loss: 0.1047\n",
            "13 / 45, train loss: 0.1004\n",
            "14 / 45, train loss: 0.1339\n",
            "15 / 45, train loss: 0.1040\n",
            "16 / 45, train loss: 0.1528\n",
            "17 / 45, train loss: 0.0725\n",
            "18 / 45, train loss: 0.1231\n",
            "19 / 45, train loss: 0.2057\n",
            "20 / 45, train loss: 0.0707\n",
            "21 / 45, train loss: 0.1132\n",
            "22 / 45, train loss: 0.1057\n",
            "23 / 45, train loss: 0.1551\n",
            "24 / 45, train loss: 0.0908\n",
            "25 / 45, train loss: 0.1522\n",
            "26 / 45, train loss: 0.1151\n",
            "27 / 45, train loss: 0.0973\n",
            "28 / 45, train loss: 0.1033\n",
            "29 / 45, train loss: 0.1300\n",
            "30 / 45, train loss: 0.1448\n",
            "31 / 45, train loss: 0.1033\n",
            "32 / 45, train loss: 0.0666\n",
            "33 / 45, train loss: 0.1831\n",
            "34 / 45, train loss: 0.0764\n",
            "35 / 45, train loss: 0.1018\n",
            "36 / 45, train loss: 0.1408\n",
            "37 / 45, train loss: 0.0892\n",
            "38 / 45, train loss: 0.1238\n",
            "39 / 45, train loss: 0.1380\n",
            "40 / 45, train loss: 0.1357\n",
            "41 / 45, train loss: 0.1189\n",
            "42 / 45, train loss: 0.1020\n",
            "43 / 45, train loss: 0.0861\n",
            "44 / 45, train loss: 0.1112\n",
            "45 / 45, train loss: 0.0858\n",
            "epoch 116 loss: 5.1264\n",
            "current learning rate: 0.000194\n",
            "Epoch 118 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1139\n",
            "2 / 45, train loss: 0.0962\n",
            "3 / 45, train loss: 0.0861\n",
            "4 / 45, train loss: 0.1123\n",
            "5 / 45, train loss: 0.1222\n",
            "6 / 45, train loss: 0.0890\n",
            "7 / 45, train loss: 0.2138\n",
            "8 / 45, train loss: 0.1151\n",
            "9 / 45, train loss: 0.1466\n",
            "10 / 45, train loss: 0.0951\n",
            "11 / 45, train loss: 0.1358\n",
            "12 / 45, train loss: 0.1788\n",
            "13 / 45, train loss: 0.1104\n",
            "14 / 45, train loss: 0.0923\n",
            "15 / 45, train loss: 0.0668\n",
            "16 / 45, train loss: 0.1398\n",
            "17 / 45, train loss: 0.1510\n",
            "18 / 45, train loss: 0.0929\n",
            "19 / 45, train loss: 0.0575\n",
            "20 / 45, train loss: 0.1068\n",
            "21 / 45, train loss: 0.1314\n",
            "22 / 45, train loss: 0.1444\n",
            "23 / 45, train loss: 0.1542\n",
            "24 / 45, train loss: 0.0533\n",
            "25 / 45, train loss: 0.1815\n",
            "26 / 45, train loss: 0.0733\n",
            "27 / 45, train loss: 0.1608\n",
            "28 / 45, train loss: 0.0646\n",
            "29 / 45, train loss: 0.2022\n",
            "30 / 45, train loss: 0.1140\n",
            "31 / 45, train loss: 0.1130\n",
            "32 / 45, train loss: 0.0925\n",
            "33 / 45, train loss: 0.0398\n",
            "34 / 45, train loss: 0.1226\n",
            "35 / 45, train loss: 0.0645\n",
            "36 / 45, train loss: 0.1105\n",
            "37 / 45, train loss: 0.1210\n",
            "38 / 45, train loss: 0.1227\n",
            "39 / 45, train loss: 0.0982\n",
            "40 / 45, train loss: 0.0871\n",
            "41 / 45, train loss: 0.0949\n",
            "42 / 45, train loss: 0.1571\n",
            "43 / 45, train loss: 0.1049\n",
            "44 / 45, train loss: 0.0988\n",
            "45 / 45, train loss: 0.1046\n",
            "epoch 117 loss: 5.1344\n",
            "current learning rate: 0.000193\n",
            "Epoch 119 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1723\n",
            "2 / 45, train loss: 0.0961\n",
            "3 / 45, train loss: 0.1634\n",
            "4 / 45, train loss: 0.0572\n",
            "5 / 45, train loss: 0.1659\n",
            "6 / 45, train loss: 0.1888\n",
            "7 / 45, train loss: 0.1365\n",
            "8 / 45, train loss: 0.0857\n",
            "9 / 45, train loss: 0.1001\n",
            "10 / 45, train loss: 0.1263\n",
            "11 / 45, train loss: 0.0945\n",
            "12 / 45, train loss: 0.1127\n",
            "13 / 45, train loss: 0.0633\n",
            "14 / 45, train loss: 0.0958\n",
            "15 / 45, train loss: 0.0975\n",
            "16 / 45, train loss: 0.1429\n",
            "17 / 45, train loss: 0.1027\n",
            "18 / 45, train loss: 0.0949\n",
            "19 / 45, train loss: 0.0674\n",
            "20 / 45, train loss: 0.1073\n",
            "21 / 45, train loss: 0.1245\n",
            "22 / 45, train loss: 0.1098\n",
            "23 / 45, train loss: 0.1112\n",
            "24 / 45, train loss: 0.1268\n",
            "25 / 45, train loss: 0.1044\n",
            "26 / 45, train loss: 0.1431\n",
            "27 / 45, train loss: 0.1173\n",
            "28 / 45, train loss: 0.1104\n",
            "29 / 45, train loss: 0.0682\n",
            "30 / 45, train loss: 0.1238\n",
            "31 / 45, train loss: 0.1047\n",
            "32 / 45, train loss: 0.1040\n",
            "33 / 45, train loss: 0.1114\n",
            "34 / 45, train loss: 0.1191\n",
            "35 / 45, train loss: 0.1281\n",
            "36 / 45, train loss: 0.1153\n",
            "37 / 45, train loss: 0.1116\n",
            "38 / 45, train loss: 0.1764\n",
            "39 / 45, train loss: 0.0963\n",
            "40 / 45, train loss: 0.1074\n",
            "41 / 45, train loss: 0.0919\n",
            "42 / 45, train loss: 0.1745\n",
            "43 / 45, train loss: 0.0726\n",
            "44 / 45, train loss: 0.0969\n",
            "45 / 45, train loss: 0.0656\n",
            "epoch 118 loss: 5.0868\n",
            "current learning rate: 0.000192\n",
            "Epoch 120 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.0951\n",
            "2 / 45, train loss: 0.0852\n",
            "3 / 45, train loss: 0.1002\n",
            "4 / 45, train loss: 0.1136\n",
            "5 / 45, train loss: 0.0978\n",
            "6 / 45, train loss: 0.1148\n",
            "7 / 45, train loss: 0.1124\n",
            "8 / 45, train loss: 0.1021\n",
            "9 / 45, train loss: 0.1415\n",
            "10 / 45, train loss: 0.0581\n",
            "11 / 45, train loss: 0.1734\n",
            "12 / 45, train loss: 0.0921\n",
            "13 / 45, train loss: 0.0800\n",
            "14 / 45, train loss: 0.1114\n",
            "15 / 45, train loss: 0.0669\n",
            "16 / 45, train loss: 0.1567\n",
            "17 / 45, train loss: 0.0889\n",
            "18 / 45, train loss: 0.0793\n",
            "19 / 45, train loss: 0.1158\n",
            "20 / 45, train loss: 0.1374\n",
            "21 / 45, train loss: 0.0834\n",
            "22 / 45, train loss: 0.1073\n",
            "23 / 45, train loss: 0.2039\n",
            "24 / 45, train loss: 0.1063\n",
            "25 / 45, train loss: 0.1313\n",
            "26 / 45, train loss: 0.1063\n",
            "27 / 45, train loss: 0.0954\n",
            "28 / 45, train loss: 0.1227\n",
            "29 / 45, train loss: 0.1460\n",
            "30 / 45, train loss: 0.1241\n",
            "31 / 45, train loss: 0.1517\n",
            "32 / 45, train loss: 0.0704\n",
            "33 / 45, train loss: 0.1134\n",
            "34 / 45, train loss: 0.1355\n",
            "35 / 45, train loss: 0.1401\n",
            "36 / 45, train loss: 0.1142\n",
            "37 / 45, train loss: 0.0880\n",
            "38 / 45, train loss: 0.1431\n",
            "39 / 45, train loss: 0.1481\n",
            "40 / 45, train loss: 0.1014\n",
            "41 / 45, train loss: 0.0685\n",
            "42 / 45, train loss: 0.0571\n",
            "43 / 45, train loss: 0.1507\n",
            "44 / 45, train loss: 0.1395\n",
            "45 / 45, train loss: 0.1500\n",
            "epoch 119 loss: 5.1213\n",
            "current learning rate: 0.000191\n",
            "Loss - mean: 0.04898396147076379\tstd: 0.02048637114606822\n",
            "AUC - mean: 0.8504082816700645\tstd: 0.04276752701460865\n",
            "ACC - mean: 0.9070850719105114\tstd: 0.03485935212075718\n",
            "SEN - mean: 0.48286845767838055\tstd: 0.08285366562390614\n",
            "FDR - mean: 0.6621284986317953\tstd: 0.05153495938759462\n",
            "SPE - mean: 0.9357729396965339\tstd: 0.025312675474823722\n",
            "Kappa - mean: 0.34268575229554155\tstd: 0.046085302941704306\n",
            "G-mean - mean: 0.6692371849467702\tstd: 0.058282804795982086\n",
            "IOU - mean: 0.24411132537136548\tstd: 0.03247223680575342\n",
            "Dice - mean: 0.39128049735515885\tstd: 0.043965166163563364\n",
            "Loss - mean: 0.04881250384179028\tstd: 0.020530356140520505\n",
            "AUC - mean: 0.8508397530171102\tstd: 0.04252852374481557\n",
            "ACC - mean: 0.9106613505970348\tstd: 0.03413929097641639\n",
            "SEN - mean: 0.46943275828474124\tstd: 0.08062387512216035\n",
            "FDR - mean: 0.6502148850259982\tstd: 0.05349850224874041\n",
            "SPE - mean: 0.9405513194858781\tstd: 0.0239266852093935\n",
            "Kappa - mean: 0.3473592517566977\tstd: 0.04839302562729221\n",
            "G-mean - mean: 0.6615701714240857\tstd: 0.05802536136041944\n",
            "IOU - mean: 0.2466101480982821\tstd: 0.03374176282127439\n",
            "Dice - mean: 0.3944189743019487\tstd: 0.045497078124043806\n",
            "Loss - mean: 0.048996041528880596\tstd: 0.020422631597636267\n",
            "AUC - mean: 0.8513404787084716\tstd: 0.04277719368216432\n",
            "ACC - mean: 0.9058702642267401\tstd: 0.035179260017524014\n",
            "SEN - mean: 0.4911731838104073\tstd: 0.08343781840105094\n",
            "FDR - mean: 0.6648042563489963\tstd: 0.05105972027103118\n",
            "SPE - mean: 0.9338949560358368\tstd: 0.025914030690526984\n",
            "Kappa - mean: 0.34312658518675915\tstd: 0.045856059905257644\n",
            "G-mean - mean: 0.6743311040360629\tstd: 0.05818764243771074\n",
            "IOU - mean: 0.24481510193396774\tstd: 0.03240281936939675\n",
            "Dice - mean: 0.3921960812034097\tstd: 0.04382596968005886\n",
            "best thin: epoch 105\tauc 0.8607\n",
            "best thick: epoch 105\tauc 0.8601\n",
            "best fusion: epoch 105\tauc 0.8609\n",
            "Epoch 121 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1286\n",
            "2 / 45, train loss: 0.1028\n",
            "3 / 45, train loss: 0.1684\n",
            "4 / 45, train loss: 0.1489\n",
            "5 / 45, train loss: 0.1145\n",
            "6 / 45, train loss: 0.1116\n",
            "7 / 45, train loss: 0.0637\n",
            "8 / 45, train loss: 0.1370\n",
            "9 / 45, train loss: 0.0814\n",
            "10 / 45, train loss: 0.0838\n",
            "11 / 45, train loss: 0.1363\n",
            "12 / 45, train loss: 0.0758\n",
            "13 / 45, train loss: 0.1134\n",
            "14 / 45, train loss: 0.1197\n",
            "15 / 45, train loss: 0.1881\n",
            "16 / 45, train loss: 0.1476\n",
            "17 / 45, train loss: 0.1646\n",
            "18 / 45, train loss: 0.1243\n",
            "19 / 45, train loss: 0.1436\n",
            "20 / 45, train loss: 0.0856\n",
            "21 / 45, train loss: 0.1074\n",
            "22 / 45, train loss: 0.0958\n",
            "23 / 45, train loss: 0.1021\n",
            "24 / 45, train loss: 0.0757\n",
            "25 / 45, train loss: 0.0710\n",
            "26 / 45, train loss: 0.1293\n",
            "27 / 45, train loss: 0.1382\n",
            "28 / 45, train loss: 0.1334\n",
            "29 / 45, train loss: 0.0742\n",
            "30 / 45, train loss: 0.0730\n",
            "31 / 45, train loss: 0.0877\n",
            "32 / 45, train loss: 0.1266\n",
            "33 / 45, train loss: 0.0875\n",
            "34 / 45, train loss: 0.1073\n",
            "35 / 45, train loss: 0.0982\n",
            "36 / 45, train loss: 0.1709\n",
            "37 / 45, train loss: 0.0922\n",
            "38 / 45, train loss: 0.1522\n",
            "39 / 45, train loss: 0.0738\n",
            "40 / 45, train loss: 0.1281\n",
            "41 / 45, train loss: 0.1545\n",
            "42 / 45, train loss: 0.0863\n",
            "43 / 45, train loss: 0.0673\n",
            "44 / 45, train loss: 0.1395\n",
            "45 / 45, train loss: 0.1212\n",
            "epoch 120 loss: 5.1331\n",
            "current learning rate: 0.000190\n",
            "Epoch 122 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1676\n",
            "2 / 45, train loss: 0.0740\n",
            "3 / 45, train loss: 0.1205\n",
            "4 / 45, train loss: 0.1063\n",
            "5 / 45, train loss: 0.0994\n",
            "6 / 45, train loss: 0.0875\n",
            "7 / 45, train loss: 0.1206\n",
            "8 / 45, train loss: 0.1553\n",
            "9 / 45, train loss: 0.0890\n",
            "10 / 45, train loss: 0.1707\n",
            "11 / 45, train loss: 0.1515\n",
            "12 / 45, train loss: 0.0963\n",
            "13 / 45, train loss: 0.1746\n",
            "14 / 45, train loss: 0.1193\n",
            "15 / 45, train loss: 0.1403\n",
            "16 / 45, train loss: 0.0716\n",
            "17 / 45, train loss: 0.1288\n",
            "18 / 45, train loss: 0.0973\n",
            "19 / 45, train loss: 0.0570\n",
            "20 / 45, train loss: 0.1271\n",
            "21 / 45, train loss: 0.1327\n",
            "22 / 45, train loss: 0.1037\n",
            "23 / 45, train loss: 0.0750\n",
            "24 / 45, train loss: 0.1058\n",
            "25 / 45, train loss: 0.1000\n",
            "26 / 45, train loss: 0.1076\n",
            "27 / 45, train loss: 0.0660\n",
            "28 / 45, train loss: 0.1418\n",
            "29 / 45, train loss: 0.1433\n",
            "30 / 45, train loss: 0.1742\n",
            "31 / 45, train loss: 0.1556\n",
            "32 / 45, train loss: 0.0736\n",
            "33 / 45, train loss: 0.0726\n",
            "34 / 45, train loss: 0.0646\n",
            "35 / 45, train loss: 0.1187\n",
            "36 / 45, train loss: 0.0868\n",
            "37 / 45, train loss: 0.1345\n",
            "38 / 45, train loss: 0.1410\n",
            "39 / 45, train loss: 0.1618\n",
            "40 / 45, train loss: 0.1630\n",
            "41 / 45, train loss: 0.0718\n",
            "42 / 45, train loss: 0.1262\n",
            "43 / 45, train loss: 0.0907\n",
            "44 / 45, train loss: 0.0790\n",
            "45 / 45, train loss: 0.0796\n",
            "epoch 121 loss: 5.1246\n",
            "current learning rate: 0.000189\n",
            "Epoch 123 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1552\n",
            "2 / 45, train loss: 0.1298\n",
            "3 / 45, train loss: 0.0871\n",
            "4 / 45, train loss: 0.1402\n",
            "5 / 45, train loss: 0.0738\n",
            "6 / 45, train loss: 0.1061\n",
            "7 / 45, train loss: 0.1546\n",
            "8 / 45, train loss: 0.0935\n",
            "9 / 45, train loss: 0.0731\n",
            "10 / 45, train loss: 0.1648\n",
            "11 / 45, train loss: 0.0797\n",
            "12 / 45, train loss: 0.1030\n",
            "13 / 45, train loss: 0.0774\n",
            "14 / 45, train loss: 0.0899\n",
            "15 / 45, train loss: 0.0786\n",
            "16 / 45, train loss: 0.1214\n",
            "17 / 45, train loss: 0.1068\n",
            "18 / 45, train loss: 0.0982\n",
            "19 / 45, train loss: 0.1584\n",
            "20 / 45, train loss: 0.1207\n",
            "21 / 45, train loss: 0.0711\n",
            "22 / 45, train loss: 0.1177\n",
            "23 / 45, train loss: 0.1030\n",
            "24 / 45, train loss: 0.0627\n",
            "25 / 45, train loss: 0.1006\n",
            "26 / 45, train loss: 0.1717\n",
            "27 / 45, train loss: 0.1218\n",
            "28 / 45, train loss: 0.1044\n",
            "29 / 45, train loss: 0.1711\n",
            "30 / 45, train loss: 0.1639\n",
            "31 / 45, train loss: 0.1565\n",
            "32 / 45, train loss: 0.1095\n",
            "33 / 45, train loss: 0.1168\n",
            "34 / 45, train loss: 0.1240\n",
            "35 / 45, train loss: 0.1157\n",
            "36 / 45, train loss: 0.1336\n",
            "37 / 45, train loss: 0.1571\n",
            "38 / 45, train loss: 0.1110\n",
            "39 / 45, train loss: 0.0610\n",
            "40 / 45, train loss: 0.1150\n",
            "41 / 45, train loss: 0.1068\n",
            "42 / 45, train loss: 0.1219\n",
            "43 / 45, train loss: 0.0991\n",
            "44 / 45, train loss: 0.1061\n",
            "45 / 45, train loss: 0.0734\n",
            "epoch 122 loss: 5.1081\n",
            "current learning rate: 0.000188\n",
            "Epoch 124 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.0854\n",
            "2 / 45, train loss: 0.1683\n",
            "3 / 45, train loss: 0.0817\n",
            "4 / 45, train loss: 0.1066\n",
            "5 / 45, train loss: 0.1683\n",
            "6 / 45, train loss: 0.0997\n",
            "7 / 45, train loss: 0.1517\n",
            "8 / 45, train loss: 0.1221\n",
            "9 / 45, train loss: 0.1411\n",
            "10 / 45, train loss: 0.1110\n",
            "11 / 45, train loss: 0.0787\n",
            "12 / 45, train loss: 0.1711\n",
            "13 / 45, train loss: 0.0924\n",
            "14 / 45, train loss: 0.0692\n",
            "15 / 45, train loss: 0.0802\n",
            "16 / 45, train loss: 0.0739\n",
            "17 / 45, train loss: 0.1141\n",
            "18 / 45, train loss: 0.1235\n",
            "19 / 45, train loss: 0.1001\n",
            "20 / 45, train loss: 0.1030\n",
            "21 / 45, train loss: 0.0989\n",
            "22 / 45, train loss: 0.1329\n",
            "23 / 45, train loss: 0.0994\n",
            "24 / 45, train loss: 0.1284\n",
            "25 / 45, train loss: 0.0569\n",
            "26 / 45, train loss: 0.1223\n",
            "27 / 45, train loss: 0.2120\n",
            "28 / 45, train loss: 0.1399\n",
            "29 / 45, train loss: 0.0859\n",
            "30 / 45, train loss: 0.1127\n",
            "31 / 45, train loss: 0.0747\n",
            "32 / 45, train loss: 0.1124\n",
            "33 / 45, train loss: 0.0758\n",
            "34 / 45, train loss: 0.0886\n",
            "35 / 45, train loss: 0.1491\n",
            "36 / 45, train loss: 0.0503\n",
            "37 / 45, train loss: 0.1035\n",
            "38 / 45, train loss: 0.1296\n",
            "39 / 45, train loss: 0.1133\n",
            "40 / 45, train loss: 0.1520\n",
            "41 / 45, train loss: 0.1321\n",
            "42 / 45, train loss: 0.1525\n",
            "43 / 45, train loss: 0.1313\n",
            "44 / 45, train loss: 0.0909\n",
            "45 / 45, train loss: 0.1236\n",
            "epoch 123 loss: 5.1112\n",
            "current learning rate: 0.000188\n",
            "Epoch 125 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1724\n",
            "2 / 45, train loss: 0.1043\n",
            "3 / 45, train loss: 0.1102\n",
            "4 / 45, train loss: 0.1006\n",
            "5 / 45, train loss: 0.0775\n",
            "6 / 45, train loss: 0.1464\n",
            "7 / 45, train loss: 0.1491\n",
            "8 / 45, train loss: 0.1154\n",
            "9 / 45, train loss: 0.0835\n",
            "10 / 45, train loss: 0.0901\n",
            "11 / 45, train loss: 0.0774\n",
            "12 / 45, train loss: 0.1707\n",
            "13 / 45, train loss: 0.1746\n",
            "14 / 45, train loss: 0.0632\n",
            "15 / 45, train loss: 0.1651\n",
            "16 / 45, train loss: 0.0873\n",
            "17 / 45, train loss: 0.1380\n",
            "18 / 45, train loss: 0.1054\n",
            "19 / 45, train loss: 0.1101\n",
            "20 / 45, train loss: 0.1270\n",
            "21 / 45, train loss: 0.1326\n",
            "22 / 45, train loss: 0.1576\n",
            "23 / 45, train loss: 0.1232\n",
            "24 / 45, train loss: 0.1287\n",
            "25 / 45, train loss: 0.1177\n",
            "26 / 45, train loss: 0.0345\n",
            "27 / 45, train loss: 0.0923\n",
            "28 / 45, train loss: 0.1153\n",
            "29 / 45, train loss: 0.0963\n",
            "30 / 45, train loss: 0.1433\n",
            "31 / 45, train loss: 0.0869\n",
            "32 / 45, train loss: 0.0517\n",
            "33 / 45, train loss: 0.0929\n",
            "34 / 45, train loss: 0.1194\n",
            "35 / 45, train loss: 0.1148\n",
            "36 / 45, train loss: 0.0801\n",
            "37 / 45, train loss: 0.1920\n",
            "38 / 45, train loss: 0.1610\n",
            "39 / 45, train loss: 0.0939\n",
            "40 / 45, train loss: 0.0942\n",
            "41 / 45, train loss: 0.1192\n",
            "42 / 45, train loss: 0.0958\n",
            "43 / 45, train loss: 0.1135\n",
            "44 / 45, train loss: 0.0982\n",
            "45 / 45, train loss: 0.0938\n",
            "epoch 124 loss: 5.1172\n",
            "current learning rate: 0.000187\n",
            "Loss - mean: 0.04861229903657328\tstd: 0.020610561046257844\n",
            "AUC - mean: 0.8600913205592774\tstd: 0.045869632603088704\n",
            "ACC - mean: 0.9100771817294034\tstd: 0.03283526715195193\n",
            "SEN - mean: 0.4805112638061042\tstd: 0.08353599010830691\n",
            "FDR - mean: 0.6536424214180468\tstd: 0.05279363218395753\n",
            "SPE - mean: 0.9395159693973656\tstd: 0.022567904111494508\n",
            "Kappa - mean: 0.34868982183260305\tstd: 0.049911985581728886\n",
            "G-mean - mean: 0.6690940518911997\tstd: 0.05904043025617949\n",
            "IOU - mean: 0.24782354996108358\tstd: 0.03502948769581285\n",
            "Dice - mean: 0.39586931622046245\tstd: 0.04779084913657538\n",
            "Loss - mean: 0.04856414885514162\tstd: 0.020659916072794986\n",
            "AUC - mean: 0.8599598307975312\tstd: 0.046129266019339206\n",
            "ACC - mean: 0.9120445251464844\tstd: 0.03320300437607631\n",
            "SEN - mean: 0.4702746430649331\tstd: 0.08263980567480875\n",
            "FDR - mean: 0.6473788563647475\tstd: 0.05093656656391542\n",
            "SPE - mean: 0.9421752611471198\tstd: 0.022620793777485028\n",
            "Kappa - mean: 0.35048903756674793\tstd: 0.04966240383135145\n",
            "G-mean - mean: 0.6627689442197654\tstd: 0.05913294336935646\n",
            "IOU - mean: 0.24861526006300674\tstd: 0.03480236491713658\n",
            "Dice - mean: 0.3969160841379091\tstd: 0.04703245174124112\n",
            "Loss - mean: 0.04856697495349429\tstd: 0.0205128892315065\n",
            "AUC - mean: 0.8605320227828032\tstd: 0.046015820802067266\n",
            "ACC - mean: 0.9088289087468927\tstd: 0.03326895803837251\n",
            "SEN - mean: 0.48770219120078\tstd: 0.08280003363546487\n",
            "FDR - mean: 0.6572561541620655\tstd: 0.0515914884284544\n",
            "SPE - mean: 0.9376472710245143\tstd: 0.023209821325126122\n",
            "Kappa - mean: 0.3485007322734933\tstd: 0.04945122873126817\n",
            "G-mean - mean: 0.6735331906637269\tstd: 0.05820525143505297\n",
            "IOU - mean: 0.2480969218027596\tstd: 0.03476655952209962\n",
            "Dice - mean: 0.3962411103593145\tstd: 0.047417455133076734\n",
            "best thin: epoch 105\tauc 0.8607\n",
            "best thick: epoch 105\tauc 0.8601\n",
            "best fusion: epoch 105\tauc 0.8609\n",
            "Epoch 126 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1175\n",
            "2 / 45, train loss: 0.1527\n",
            "3 / 45, train loss: 0.1018\n",
            "4 / 45, train loss: 0.1477\n",
            "5 / 45, train loss: 0.0545\n",
            "6 / 45, train loss: 0.0979\n",
            "7 / 45, train loss: 0.1292\n",
            "8 / 45, train loss: 0.0908\n",
            "9 / 45, train loss: 0.1019\n",
            "10 / 45, train loss: 0.0770\n",
            "11 / 45, train loss: 0.0894\n",
            "12 / 45, train loss: 0.1157\n",
            "13 / 45, train loss: 0.1573\n",
            "14 / 45, train loss: 0.0833\n",
            "15 / 45, train loss: 0.0368\n",
            "16 / 45, train loss: 0.0887\n",
            "17 / 45, train loss: 0.1385\n",
            "18 / 45, train loss: 0.1045\n",
            "19 / 45, train loss: 0.0961\n",
            "20 / 45, train loss: 0.0986\n",
            "21 / 45, train loss: 0.1474\n",
            "22 / 45, train loss: 0.0736\n",
            "23 / 45, train loss: 0.1262\n",
            "24 / 45, train loss: 0.1307\n",
            "25 / 45, train loss: 0.0997\n",
            "26 / 45, train loss: 0.0954\n",
            "27 / 45, train loss: 0.1035\n",
            "28 / 45, train loss: 0.1695\n",
            "29 / 45, train loss: 0.0681\n",
            "30 / 45, train loss: 0.1335\n",
            "31 / 45, train loss: 0.1720\n",
            "32 / 45, train loss: 0.1572\n",
            "33 / 45, train loss: 0.1456\n",
            "34 / 45, train loss: 0.0871\n",
            "35 / 45, train loss: 0.1488\n",
            "36 / 45, train loss: 0.1153\n",
            "37 / 45, train loss: 0.0911\n",
            "38 / 45, train loss: 0.1403\n",
            "39 / 45, train loss: 0.1246\n",
            "40 / 45, train loss: 0.1175\n",
            "41 / 45, train loss: 0.0813\n",
            "42 / 45, train loss: 0.1246\n",
            "43 / 45, train loss: 0.1159\n",
            "44 / 45, train loss: 0.1506\n",
            "45 / 45, train loss: 0.1163\n",
            "epoch 125 loss: 5.1156\n",
            "current learning rate: 0.000186\n",
            "Epoch 127 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.0671\n",
            "2 / 45, train loss: 0.0739\n",
            "3 / 45, train loss: 0.1405\n",
            "4 / 45, train loss: 0.0910\n",
            "5 / 45, train loss: 0.1308\n",
            "6 / 45, train loss: 0.1078\n",
            "7 / 45, train loss: 0.0768\n",
            "8 / 45, train loss: 0.1296\n",
            "9 / 45, train loss: 0.1414\n",
            "10 / 45, train loss: 0.1579\n",
            "11 / 45, train loss: 0.1373\n",
            "12 / 45, train loss: 0.0794\n",
            "13 / 45, train loss: 0.1362\n",
            "14 / 45, train loss: 0.0672\n",
            "15 / 45, train loss: 0.1542\n",
            "16 / 45, train loss: 0.1941\n",
            "17 / 45, train loss: 0.1392\n",
            "18 / 45, train loss: 0.1491\n",
            "19 / 45, train loss: 0.1081\n",
            "20 / 45, train loss: 0.0766\n",
            "21 / 45, train loss: 0.0839\n",
            "22 / 45, train loss: 0.0714\n",
            "23 / 45, train loss: 0.0450\n",
            "24 / 45, train loss: 0.1189\n",
            "25 / 45, train loss: 0.1222\n",
            "26 / 45, train loss: 0.1003\n",
            "27 / 45, train loss: 0.0928\n",
            "28 / 45, train loss: 0.1587\n",
            "29 / 45, train loss: 0.1245\n",
            "30 / 45, train loss: 0.1472\n",
            "31 / 45, train loss: 0.1017\n",
            "32 / 45, train loss: 0.0877\n",
            "33 / 45, train loss: 0.1146\n",
            "34 / 45, train loss: 0.1385\n",
            "35 / 45, train loss: 0.1188\n",
            "36 / 45, train loss: 0.0840\n",
            "37 / 45, train loss: 0.1258\n",
            "38 / 45, train loss: 0.1627\n",
            "39 / 45, train loss: 0.1235\n",
            "40 / 45, train loss: 0.1061\n",
            "41 / 45, train loss: 0.1208\n",
            "42 / 45, train loss: 0.1601\n",
            "43 / 45, train loss: 0.0711\n",
            "44 / 45, train loss: 0.0683\n",
            "45 / 45, train loss: 0.1159\n",
            "epoch 126 loss: 5.1228\n",
            "current learning rate: 0.000185\n",
            "Epoch 128 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1429\n",
            "2 / 45, train loss: 0.1348\n",
            "3 / 45, train loss: 0.1139\n",
            "4 / 45, train loss: 0.1038\n",
            "5 / 45, train loss: 0.1281\n",
            "6 / 45, train loss: 0.1222\n",
            "7 / 45, train loss: 0.0603\n",
            "8 / 45, train loss: 0.0793\n",
            "9 / 45, train loss: 0.1509\n",
            "10 / 45, train loss: 0.1110\n",
            "11 / 45, train loss: 0.0586\n",
            "12 / 45, train loss: 0.1277\n",
            "13 / 45, train loss: 0.0472\n",
            "14 / 45, train loss: 0.1359\n",
            "15 / 45, train loss: 0.1766\n",
            "16 / 45, train loss: 0.1039\n",
            "17 / 45, train loss: 0.1605\n",
            "18 / 45, train loss: 0.0941\n",
            "19 / 45, train loss: 0.1236\n",
            "20 / 45, train loss: 0.0547\n",
            "21 / 45, train loss: 0.1387\n",
            "22 / 45, train loss: 0.1061\n",
            "23 / 45, train loss: 0.1251\n",
            "24 / 45, train loss: 0.0827\n",
            "25 / 45, train loss: 0.1567\n",
            "26 / 45, train loss: 0.0955\n",
            "27 / 45, train loss: 0.1425\n",
            "28 / 45, train loss: 0.1482\n",
            "29 / 45, train loss: 0.1390\n",
            "30 / 45, train loss: 0.0920\n",
            "31 / 45, train loss: 0.1123\n",
            "32 / 45, train loss: 0.1164\n",
            "33 / 45, train loss: 0.0790\n",
            "34 / 45, train loss: 0.0965\n",
            "35 / 45, train loss: 0.2086\n",
            "36 / 45, train loss: 0.0953\n",
            "37 / 45, train loss: 0.0798\n",
            "38 / 45, train loss: 0.0935\n",
            "39 / 45, train loss: 0.1591\n",
            "40 / 45, train loss: 0.1069\n",
            "41 / 45, train loss: 0.1124\n",
            "42 / 45, train loss: 0.1231\n",
            "43 / 45, train loss: 0.1096\n",
            "44 / 45, train loss: 0.0849\n",
            "45 / 45, train loss: 0.0870\n",
            "epoch 127 loss: 5.1209\n",
            "current learning rate: 0.000184\n",
            "Epoch 129 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.0866\n",
            "2 / 45, train loss: 0.1192\n",
            "3 / 45, train loss: 0.1286\n",
            "4 / 45, train loss: 0.2064\n",
            "5 / 45, train loss: 0.1114\n",
            "6 / 45, train loss: 0.1236\n",
            "7 / 45, train loss: 0.1189\n",
            "8 / 45, train loss: 0.1250\n",
            "9 / 45, train loss: 0.1051\n",
            "10 / 45, train loss: 0.1438\n",
            "11 / 45, train loss: 0.1058\n",
            "12 / 45, train loss: 0.1025\n",
            "13 / 45, train loss: 0.1030\n",
            "14 / 45, train loss: 0.0909\n",
            "15 / 45, train loss: 0.1327\n",
            "16 / 45, train loss: 0.0893\n",
            "17 / 45, train loss: 0.0987\n",
            "18 / 45, train loss: 0.1110\n",
            "19 / 45, train loss: 0.1136\n",
            "20 / 45, train loss: 0.1506\n",
            "21 / 45, train loss: 0.1036\n",
            "22 / 45, train loss: 0.1349\n",
            "23 / 45, train loss: 0.1285\n",
            "24 / 45, train loss: 0.1491\n",
            "25 / 45, train loss: 0.0432\n",
            "26 / 45, train loss: 0.1216\n",
            "27 / 45, train loss: 0.0939\n",
            "28 / 45, train loss: 0.1282\n",
            "29 / 45, train loss: 0.0795\n",
            "30 / 45, train loss: 0.0742\n",
            "31 / 45, train loss: 0.0880\n",
            "32 / 45, train loss: 0.0818\n",
            "33 / 45, train loss: 0.1782\n",
            "34 / 45, train loss: 0.1269\n",
            "35 / 45, train loss: 0.1213\n",
            "36 / 45, train loss: 0.0870\n",
            "37 / 45, train loss: 0.0448\n",
            "38 / 45, train loss: 0.0855\n",
            "39 / 45, train loss: 0.1120\n",
            "40 / 45, train loss: 0.1318\n",
            "41 / 45, train loss: 0.1924\n",
            "42 / 45, train loss: 0.0695\n",
            "43 / 45, train loss: 0.0906\n",
            "44 / 45, train loss: 0.1707\n",
            "45 / 45, train loss: 0.0843\n",
            "epoch 128 loss: 5.0883\n",
            "current learning rate: 0.000183\n",
            "Epoch 130 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1551\n",
            "2 / 45, train loss: 0.0900\n",
            "3 / 45, train loss: 0.0549\n",
            "4 / 45, train loss: 0.0989\n",
            "5 / 45, train loss: 0.0858\n",
            "6 / 45, train loss: 0.0946\n",
            "7 / 45, train loss: 0.0605\n",
            "8 / 45, train loss: 0.0863\n",
            "9 / 45, train loss: 0.2053\n",
            "10 / 45, train loss: 0.1327\n",
            "11 / 45, train loss: 0.1221\n",
            "12 / 45, train loss: 0.0682\n",
            "13 / 45, train loss: 0.0570\n",
            "14 / 45, train loss: 0.1500\n",
            "15 / 45, train loss: 0.1301\n",
            "16 / 45, train loss: 0.0989\n",
            "17 / 45, train loss: 0.1075\n",
            "18 / 45, train loss: 0.2215\n",
            "19 / 45, train loss: 0.0852\n",
            "20 / 45, train loss: 0.0835\n",
            "21 / 45, train loss: 0.0916\n",
            "22 / 45, train loss: 0.1689\n",
            "23 / 45, train loss: 0.0847\n",
            "24 / 45, train loss: 0.1031\n",
            "25 / 45, train loss: 0.1132\n",
            "26 / 45, train loss: 0.1089\n",
            "27 / 45, train loss: 0.0687\n",
            "28 / 45, train loss: 0.1560\n",
            "29 / 45, train loss: 0.0945\n",
            "30 / 45, train loss: 0.1309\n",
            "31 / 45, train loss: 0.1438\n",
            "32 / 45, train loss: 0.1549\n",
            "33 / 45, train loss: 0.1215\n",
            "34 / 45, train loss: 0.1079\n",
            "35 / 45, train loss: 0.1500\n",
            "36 / 45, train loss: 0.0920\n",
            "37 / 45, train loss: 0.1229\n",
            "38 / 45, train loss: 0.1190\n",
            "39 / 45, train loss: 0.0764\n",
            "40 / 45, train loss: 0.0959\n",
            "41 / 45, train loss: 0.1193\n",
            "42 / 45, train loss: 0.1533\n",
            "43 / 45, train loss: 0.1307\n",
            "44 / 45, train loss: 0.0681\n",
            "45 / 45, train loss: 0.1356\n",
            "epoch 129 loss: 5.0998\n",
            "current learning rate: 0.000182\n",
            "Loss - mean: 0.04856096457859332\tstd: 0.02062269749832887\n",
            "AUC - mean: 0.8572172619235268\tstd: 0.04371060554561658\n",
            "ACC - mean: 0.9173987995494496\tstd: 0.03144230238066564\n",
            "SEN - mean: 0.4413197675129174\tstd: 0.07759319920390613\n",
            "FDR - mean: 0.6284654970377582\tstd: 0.05544233100695724\n",
            "SPE - mean: 0.9501010593704753\tstd: 0.019414285807168568\n",
            "Kappa - mean: 0.3529674896675382\tstd: 0.05143694484051941\n",
            "G-mean - mean: 0.6448308024368931\tstd: 0.057886140434655654\n",
            "IOU - mean: 0.24857792248565697\tstd: 0.03543770567940019\n",
            "Dice - mean: 0.39682512297576195\tstd: 0.047705184971504846\n",
            "Loss - mean: 0.04858070726252415\tstd: 0.020622357830695656\n",
            "AUC - mean: 0.8572712005680455\tstd: 0.04416205904957354\n",
            "ACC - mean: 0.9177754142067649\tstd: 0.03181356826783765\n",
            "SEN - mean: 0.4377990755492576\tstd: 0.07893818916976687\n",
            "FDR - mean: 0.6267721311869013\tstd: 0.05466797977523465\n",
            "SPE - mean: 0.9506322727095998\tstd: 0.01983479207225556\n",
            "Kappa - mean: 0.35278415679595365\tstd: 0.05205841777916866\n",
            "G-mean - mean: 0.642269090198525\tstd: 0.05893857343304189\n",
            "IOU - mean: 0.24835550525030897\tstd: 0.03598617679017915\n",
            "Dice - mean: 0.3964994743899768\tstd: 0.048366687294684706\n",
            "Loss - mean: 0.04857823184945367\tstd: 0.020521146401013726\n",
            "AUC - mean: 0.8581931383089135\tstd: 0.04417825945179253\n",
            "ACC - mean: 0.9155464172363281\tstd: 0.03206566008350602\n",
            "SEN - mean: 0.4524186890582767\tstd: 0.07848313754680063\n",
            "FDR - mean: 0.6348043943110073\tstd: 0.0547817719181609\n",
            "SPE - mean: 0.9473047803267497\tstd: 0.020549333179184753\n",
            "Kappa - mean: 0.3528748974680441\tstd: 0.05167763039043565\n",
            "G-mean - mean: 0.6519721959321149\tstd: 0.057822470390235595\n",
            "IOU - mean: 0.24923001406726256\tstd: 0.03563600121935353\n",
            "Dice - mean: 0.39764370878680516\tstd: 0.048083221599795944\n",
            "best thin: epoch 105\tauc 0.8607\n",
            "best thick: epoch 105\tauc 0.8601\n",
            "best fusion: epoch 105\tauc 0.8609\n",
            "Epoch 131 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1027\n",
            "2 / 45, train loss: 0.1038\n",
            "3 / 45, train loss: 0.1417\n",
            "4 / 45, train loss: 0.1012\n",
            "5 / 45, train loss: 0.1279\n",
            "6 / 45, train loss: 0.0958\n",
            "7 / 45, train loss: 0.1398\n",
            "8 / 45, train loss: 0.1439\n",
            "9 / 45, train loss: 0.1242\n",
            "10 / 45, train loss: 0.1319\n",
            "11 / 45, train loss: 0.0813\n",
            "12 / 45, train loss: 0.0365\n",
            "13 / 45, train loss: 0.0457\n",
            "14 / 45, train loss: 0.1108\n",
            "15 / 45, train loss: 0.1001\n",
            "16 / 45, train loss: 0.1599\n",
            "17 / 45, train loss: 0.1291\n",
            "18 / 45, train loss: 0.1113\n",
            "19 / 45, train loss: 0.1247\n",
            "20 / 45, train loss: 0.0723\n",
            "21 / 45, train loss: 0.1259\n",
            "22 / 45, train loss: 0.1372\n",
            "23 / 45, train loss: 0.1062\n",
            "24 / 45, train loss: 0.1254\n",
            "25 / 45, train loss: 0.1553\n",
            "26 / 45, train loss: 0.0864\n",
            "27 / 45, train loss: 0.0949\n",
            "28 / 45, train loss: 0.0592\n",
            "29 / 45, train loss: 0.1259\n",
            "30 / 45, train loss: 0.0868\n",
            "31 / 45, train loss: 0.1266\n",
            "32 / 45, train loss: 0.1245\n",
            "33 / 45, train loss: 0.1488\n",
            "34 / 45, train loss: 0.1067\n",
            "35 / 45, train loss: 0.0845\n",
            "36 / 45, train loss: 0.1225\n",
            "37 / 45, train loss: 0.1084\n",
            "38 / 45, train loss: 0.0537\n",
            "39 / 45, train loss: 0.1126\n",
            "40 / 45, train loss: 0.1774\n",
            "41 / 45, train loss: 0.1128\n",
            "42 / 45, train loss: 0.1591\n",
            "43 / 45, train loss: 0.2151\n",
            "44 / 45, train loss: 0.0906\n",
            "45 / 45, train loss: 0.0884\n",
            "epoch 130 loss: 5.1193\n",
            "current learning rate: 0.000181\n",
            "Epoch 132 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1130\n",
            "2 / 45, train loss: 0.0677\n",
            "3 / 45, train loss: 0.0788\n",
            "4 / 45, train loss: 0.1225\n",
            "5 / 45, train loss: 0.0636\n",
            "6 / 45, train loss: 0.1241\n",
            "7 / 45, train loss: 0.1431\n",
            "8 / 45, train loss: 0.1106\n",
            "9 / 45, train loss: 0.0896\n",
            "10 / 45, train loss: 0.0730\n",
            "11 / 45, train loss: 0.1476\n",
            "12 / 45, train loss: 0.1449\n",
            "13 / 45, train loss: 0.0383\n",
            "14 / 45, train loss: 0.1088\n",
            "15 / 45, train loss: 0.1490\n",
            "16 / 45, train loss: 0.1567\n",
            "17 / 45, train loss: 0.1135\n",
            "18 / 45, train loss: 0.1103\n",
            "19 / 45, train loss: 0.1672\n",
            "20 / 45, train loss: 0.1443\n",
            "21 / 45, train loss: 0.1181\n",
            "22 / 45, train loss: 0.0791\n",
            "23 / 45, train loss: 0.1507\n",
            "24 / 45, train loss: 0.0819\n",
            "25 / 45, train loss: 0.1340\n",
            "26 / 45, train loss: 0.0752\n",
            "27 / 45, train loss: 0.1517\n",
            "28 / 45, train loss: 0.0815\n",
            "29 / 45, train loss: 0.1187\n",
            "30 / 45, train loss: 0.1471\n",
            "31 / 45, train loss: 0.1302\n",
            "32 / 45, train loss: 0.1538\n",
            "33 / 45, train loss: 0.0764\n",
            "34 / 45, train loss: 0.1059\n",
            "35 / 45, train loss: 0.0967\n",
            "36 / 45, train loss: 0.1360\n",
            "37 / 45, train loss: 0.1505\n",
            "38 / 45, train loss: 0.0996\n",
            "39 / 45, train loss: 0.0602\n",
            "40 / 45, train loss: 0.0450\n",
            "41 / 45, train loss: 0.0920\n",
            "42 / 45, train loss: 0.1332\n",
            "43 / 45, train loss: 0.1718\n",
            "44 / 45, train loss: 0.1160\n",
            "45 / 45, train loss: 0.1169\n",
            "epoch 131 loss: 5.0886\n",
            "current learning rate: 0.000180\n",
            "Epoch 133 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1600\n",
            "2 / 45, train loss: 0.1497\n",
            "3 / 45, train loss: 0.1083\n",
            "4 / 45, train loss: 0.1026\n",
            "5 / 45, train loss: 0.1643\n",
            "6 / 45, train loss: 0.0902\n",
            "7 / 45, train loss: 0.0863\n",
            "8 / 45, train loss: 0.1152\n",
            "9 / 45, train loss: 0.0886\n",
            "10 / 45, train loss: 0.0980\n",
            "11 / 45, train loss: 0.1321\n",
            "12 / 45, train loss: 0.0696\n",
            "13 / 45, train loss: 0.1484\n",
            "14 / 45, train loss: 0.1022\n",
            "15 / 45, train loss: 0.0877\n",
            "16 / 45, train loss: 0.0967\n",
            "17 / 45, train loss: 0.1577\n",
            "18 / 45, train loss: 0.1513\n",
            "19 / 45, train loss: 0.0788\n",
            "20 / 45, train loss: 0.0558\n",
            "21 / 45, train loss: 0.1048\n",
            "22 / 45, train loss: 0.1071\n",
            "23 / 45, train loss: 0.1233\n",
            "24 / 45, train loss: 0.0886\n",
            "25 / 45, train loss: 0.0872\n",
            "26 / 45, train loss: 0.0398\n",
            "27 / 45, train loss: 0.1294\n",
            "28 / 45, train loss: 0.1699\n",
            "29 / 45, train loss: 0.1251\n",
            "30 / 45, train loss: 0.0961\n",
            "31 / 45, train loss: 0.1414\n",
            "32 / 45, train loss: 0.0938\n",
            "33 / 45, train loss: 0.1300\n",
            "34 / 45, train loss: 0.1516\n",
            "35 / 45, train loss: 0.1168\n",
            "36 / 45, train loss: 0.1459\n",
            "37 / 45, train loss: 0.0752\n",
            "38 / 45, train loss: 0.1366\n",
            "39 / 45, train loss: 0.1236\n",
            "40 / 45, train loss: 0.0934\n",
            "41 / 45, train loss: 0.1048\n",
            "42 / 45, train loss: 0.1067\n",
            "43 / 45, train loss: 0.0803\n",
            "44 / 45, train loss: 0.1474\n",
            "45 / 45, train loss: 0.1551\n",
            "epoch 132 loss: 5.1174\n",
            "current learning rate: 0.000179\n",
            "Epoch 134 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1090\n",
            "2 / 45, train loss: 0.0816\n",
            "3 / 45, train loss: 0.1579\n",
            "4 / 45, train loss: 0.0684\n",
            "5 / 45, train loss: 0.0884\n",
            "6 / 45, train loss: 0.0979\n",
            "7 / 45, train loss: 0.1065\n",
            "8 / 45, train loss: 0.0962\n",
            "9 / 45, train loss: 0.0842\n",
            "10 / 45, train loss: 0.1164\n",
            "11 / 45, train loss: 0.1221\n",
            "12 / 45, train loss: 0.0887\n",
            "13 / 45, train loss: 0.0409\n",
            "14 / 45, train loss: 0.0406\n",
            "15 / 45, train loss: 0.0990\n",
            "16 / 45, train loss: 0.0890\n",
            "17 / 45, train loss: 0.1407\n",
            "18 / 45, train loss: 0.1004\n",
            "19 / 45, train loss: 0.0988\n",
            "20 / 45, train loss: 0.1126\n",
            "21 / 45, train loss: 0.1489\n",
            "22 / 45, train loss: 0.1260\n",
            "23 / 45, train loss: 0.1835\n",
            "24 / 45, train loss: 0.1465\n",
            "25 / 45, train loss: 0.0761\n",
            "26 / 45, train loss: 0.1059\n",
            "27 / 45, train loss: 0.1341\n",
            "28 / 45, train loss: 0.1345\n",
            "29 / 45, train loss: 0.1717\n",
            "30 / 45, train loss: 0.1487\n",
            "31 / 45, train loss: 0.1046\n",
            "32 / 45, train loss: 0.1261\n",
            "33 / 45, train loss: 0.0627\n",
            "34 / 45, train loss: 0.1438\n",
            "35 / 45, train loss: 0.1168\n",
            "36 / 45, train loss: 0.1652\n",
            "37 / 45, train loss: 0.0620\n",
            "38 / 45, train loss: 0.1421\n",
            "39 / 45, train loss: 0.1045\n",
            "40 / 45, train loss: 0.1468\n",
            "41 / 45, train loss: 0.1271\n",
            "42 / 45, train loss: 0.1527\n",
            "43 / 45, train loss: 0.1310\n",
            "44 / 45, train loss: 0.0610\n",
            "45 / 45, train loss: 0.1328\n",
            "epoch 133 loss: 5.0941\n",
            "current learning rate: 0.000178\n",
            "Epoch 135 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1873\n",
            "2 / 45, train loss: 0.0814\n",
            "3 / 45, train loss: 0.0983\n",
            "4 / 45, train loss: 0.1581\n",
            "5 / 45, train loss: 0.0788\n",
            "6 / 45, train loss: 0.1087\n",
            "7 / 45, train loss: 0.0930\n",
            "8 / 45, train loss: 0.1397\n",
            "9 / 45, train loss: 0.0763\n",
            "10 / 45, train loss: 0.1646\n",
            "11 / 45, train loss: 0.1272\n",
            "12 / 45, train loss: 0.1640\n",
            "13 / 45, train loss: 0.1223\n",
            "14 / 45, train loss: 0.1421\n",
            "15 / 45, train loss: 0.1283\n",
            "16 / 45, train loss: 0.1149\n",
            "17 / 45, train loss: 0.0944\n",
            "18 / 45, train loss: 0.1484\n",
            "19 / 45, train loss: 0.1394\n",
            "20 / 45, train loss: 0.1263\n",
            "21 / 45, train loss: 0.1153\n",
            "22 / 45, train loss: 0.1810\n",
            "23 / 45, train loss: 0.1667\n",
            "24 / 45, train loss: 0.0649\n",
            "25 / 45, train loss: 0.0908\n",
            "26 / 45, train loss: 0.1089\n",
            "27 / 45, train loss: 0.0776\n",
            "28 / 45, train loss: 0.0964\n",
            "29 / 45, train loss: 0.1082\n",
            "30 / 45, train loss: 0.1400\n",
            "31 / 45, train loss: 0.0634\n",
            "32 / 45, train loss: 0.0858\n",
            "33 / 45, train loss: 0.0914\n",
            "34 / 45, train loss: 0.0810\n",
            "35 / 45, train loss: 0.1038\n",
            "36 / 45, train loss: 0.1061\n",
            "37 / 45, train loss: 0.1278\n",
            "38 / 45, train loss: 0.1280\n",
            "39 / 45, train loss: 0.1012\n",
            "40 / 45, train loss: 0.1045\n",
            "41 / 45, train loss: 0.1003\n",
            "42 / 45, train loss: 0.0899\n",
            "43 / 45, train loss: 0.1346\n",
            "44 / 45, train loss: 0.0800\n",
            "45 / 45, train loss: 0.0658\n",
            "epoch 134 loss: 5.1069\n",
            "current learning rate: 0.000177\n",
            "Loss - mean: 0.048765118826519356\tstd: 0.020391351675396314\n",
            "AUC - mean: 0.8585581247730537\tstd: 0.04578992704895617\n",
            "ACC - mean: 0.9091590534556996\tstd: 0.031834070409932344\n",
            "SEN - mean: 0.4837694274982793\tstd: 0.08384742997455058\n",
            "FDR - mean: 0.6578092630630965\tstd: 0.05507931746871114\n",
            "SPE - mean: 0.9384463134794522\tstd: 0.021277335979505232\n",
            "Kappa - mean: 0.34624923496534477\tstd: 0.050005567377142277\n",
            "G-mean - mean: 0.670991122983767\tstd: 0.05998068512064671\n",
            "IOU - mean: 0.2462359533955196\tstd: 0.0355460555822954\n",
            "Dice - mean: 0.39377633975706794\tstd: 0.048837381665493465\n",
            "Loss - mean: 0.048720151228322225\tstd: 0.020398590489334477\n",
            "AUC - mean: 0.8583579527029364\tstd: 0.04587618339913331\n",
            "ACC - mean: 0.9079518751664595\tstd: 0.03270305281100186\n",
            "SEN - mean: 0.48871814638082595\tstd: 0.08527060750735094\n",
            "FDR - mean: 0.660425168782157\tstd: 0.054796351631664346\n",
            "SPE - mean: 0.9366877747292924\tstd: 0.022637658027280804\n",
            "Kappa - mean: 0.34563416829181715\tstd: 0.050070306073808725\n",
            "G-mean - mean: 0.6736784457744724\tstd: 0.06047101340754368\n",
            "IOU - mean: 0.2461689815392435\tstd: 0.03560508432511546\n",
            "Dice - mean: 0.39368592299829736\tstd: 0.04889853938733503\n",
            "Loss - mean: 0.048869994849982584\tstd: 0.020296506224939295\n",
            "AUC - mean: 0.8589716734386786\tstd: 0.04591579588477425\n",
            "ACC - mean: 0.9060982790860262\tstd: 0.03259193904158649\n",
            "SEN - mean: 0.4983947894353306\tstd: 0.08548954454892456\n",
            "FDR - mean: 0.6656994281629104\tstd: 0.0548049022414811\n",
            "SPE - mean: 0.9341219103565542\tstd: 0.022821156901731515\n",
            "Kappa - mean: 0.34426920079677115\tstd: 0.049509240117912336\n",
            "G-mean - mean: 0.6794933113865078\tstd: 0.06007167527589939\n",
            "IOU - mean: 0.2456474514546538\tstd: 0.03542580818291082\n",
            "Dice - mean: 0.3930238307816809\tstd: 0.048781440052132946\n",
            "best thin: epoch 105\tauc 0.8607\n",
            "best thick: epoch 105\tauc 0.8601\n",
            "best fusion: epoch 105\tauc 0.8609\n",
            "Epoch 136 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1148\n",
            "2 / 45, train loss: 0.1171\n",
            "3 / 45, train loss: 0.0962\n",
            "4 / 45, train loss: 0.0873\n",
            "5 / 45, train loss: 0.0627\n",
            "6 / 45, train loss: 0.1567\n",
            "7 / 45, train loss: 0.1044\n",
            "8 / 45, train loss: 0.1559\n",
            "9 / 45, train loss: 0.0867\n",
            "10 / 45, train loss: 0.1374\n",
            "11 / 45, train loss: 0.1007\n",
            "12 / 45, train loss: 0.0884\n",
            "13 / 45, train loss: 0.1475\n",
            "14 / 45, train loss: 0.2081\n",
            "15 / 45, train loss: 0.0751\n",
            "16 / 45, train loss: 0.1065\n",
            "17 / 45, train loss: 0.1097\n",
            "18 / 45, train loss: 0.0588\n",
            "19 / 45, train loss: 0.1478\n",
            "20 / 45, train loss: 0.0647\n",
            "21 / 45, train loss: 0.1779\n",
            "22 / 45, train loss: 0.1503\n",
            "23 / 45, train loss: 0.0986\n",
            "24 / 45, train loss: 0.1069\n",
            "25 / 45, train loss: 0.0828\n",
            "26 / 45, train loss: 0.1108\n",
            "27 / 45, train loss: 0.1083\n",
            "28 / 45, train loss: 0.1212\n",
            "29 / 45, train loss: 0.1218\n",
            "30 / 45, train loss: 0.1320\n",
            "31 / 45, train loss: 0.1046\n",
            "32 / 45, train loss: 0.1142\n",
            "33 / 45, train loss: 0.1317\n",
            "34 / 45, train loss: 0.1517\n",
            "35 / 45, train loss: 0.1015\n",
            "36 / 45, train loss: 0.0955\n",
            "37 / 45, train loss: 0.1362\n",
            "38 / 45, train loss: 0.1587\n",
            "39 / 45, train loss: 0.0713\n",
            "40 / 45, train loss: 0.1089\n",
            "41 / 45, train loss: 0.1112\n",
            "42 / 45, train loss: 0.0852\n",
            "43 / 45, train loss: 0.0823\n",
            "44 / 45, train loss: 0.1311\n",
            "45 / 45, train loss: 0.0716\n",
            "epoch 135 loss: 5.0926\n",
            "current learning rate: 0.000176\n",
            "Epoch 137 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1044\n",
            "2 / 45, train loss: 0.0859\n",
            "3 / 45, train loss: 0.1154\n",
            "4 / 45, train loss: 0.1363\n",
            "5 / 45, train loss: 0.0862\n",
            "6 / 45, train loss: 0.0796\n",
            "7 / 45, train loss: 0.0529\n",
            "8 / 45, train loss: 0.1453\n",
            "9 / 45, train loss: 0.0837\n",
            "10 / 45, train loss: 0.1275\n",
            "11 / 45, train loss: 0.1522\n",
            "12 / 45, train loss: 0.0669\n",
            "13 / 45, train loss: 0.2117\n",
            "14 / 45, train loss: 0.1655\n",
            "15 / 45, train loss: 0.1050\n",
            "16 / 45, train loss: 0.1263\n",
            "17 / 45, train loss: 0.0651\n",
            "18 / 45, train loss: 0.0880\n",
            "19 / 45, train loss: 0.1227\n",
            "20 / 45, train loss: 0.0442\n",
            "21 / 45, train loss: 0.0950\n",
            "22 / 45, train loss: 0.1135\n",
            "23 / 45, train loss: 0.1221\n",
            "24 / 45, train loss: 0.1067\n",
            "25 / 45, train loss: 0.1325\n",
            "26 / 45, train loss: 0.1075\n",
            "27 / 45, train loss: 0.1559\n",
            "28 / 45, train loss: 0.0885\n",
            "29 / 45, train loss: 0.1300\n",
            "30 / 45, train loss: 0.0887\n",
            "31 / 45, train loss: 0.0619\n",
            "32 / 45, train loss: 0.1593\n",
            "33 / 45, train loss: 0.0892\n",
            "34 / 45, train loss: 0.1346\n",
            "35 / 45, train loss: 0.1077\n",
            "36 / 45, train loss: 0.1028\n",
            "37 / 45, train loss: 0.1204\n",
            "38 / 45, train loss: 0.1649\n",
            "39 / 45, train loss: 0.1297\n",
            "40 / 45, train loss: 0.1464\n",
            "41 / 45, train loss: 0.1172\n",
            "42 / 45, train loss: 0.1382\n",
            "43 / 45, train loss: 0.0846\n",
            "44 / 45, train loss: 0.0714\n",
            "45 / 45, train loss: 0.1692\n",
            "epoch 136 loss: 5.1029\n",
            "current learning rate: 0.000175\n",
            "Epoch 138 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1093\n",
            "2 / 45, train loss: 0.0986\n",
            "3 / 45, train loss: 0.0742\n",
            "4 / 45, train loss: 0.0979\n",
            "5 / 45, train loss: 0.1200\n",
            "6 / 45, train loss: 0.0943\n",
            "7 / 45, train loss: 0.1261\n",
            "8 / 45, train loss: 0.0977\n",
            "9 / 45, train loss: 0.0779\n",
            "10 / 45, train loss: 0.1189\n",
            "11 / 45, train loss: 0.1751\n",
            "12 / 45, train loss: 0.0917\n",
            "13 / 45, train loss: 0.1080\n",
            "14 / 45, train loss: 0.1696\n",
            "15 / 45, train loss: 0.1632\n",
            "16 / 45, train loss: 0.1084\n",
            "17 / 45, train loss: 0.1014\n",
            "18 / 45, train loss: 0.1424\n",
            "19 / 45, train loss: 0.1330\n",
            "20 / 45, train loss: 0.0622\n",
            "21 / 45, train loss: 0.0891\n",
            "22 / 45, train loss: 0.0929\n",
            "23 / 45, train loss: 0.0739\n",
            "24 / 45, train loss: 0.1136\n",
            "25 / 45, train loss: 0.1388\n",
            "26 / 45, train loss: 0.0510\n",
            "27 / 45, train loss: 0.1077\n",
            "28 / 45, train loss: 0.1491\n",
            "29 / 45, train loss: 0.0642\n",
            "30 / 45, train loss: 0.0618\n",
            "31 / 45, train loss: 0.1159\n",
            "32 / 45, train loss: 0.0962\n",
            "33 / 45, train loss: 0.1470\n",
            "34 / 45, train loss: 0.1003\n",
            "35 / 45, train loss: 0.1217\n",
            "36 / 45, train loss: 0.1221\n",
            "37 / 45, train loss: 0.1636\n",
            "38 / 45, train loss: 0.1506\n",
            "39 / 45, train loss: 0.0961\n",
            "40 / 45, train loss: 0.0976\n",
            "41 / 45, train loss: 0.0898\n",
            "42 / 45, train loss: 0.1387\n",
            "43 / 45, train loss: 0.1027\n",
            "44 / 45, train loss: 0.1224\n",
            "45 / 45, train loss: 0.2156\n",
            "epoch 137 loss: 5.0922\n",
            "current learning rate: 0.000174\n",
            "Epoch 139 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.0982\n",
            "2 / 45, train loss: 0.1428\n",
            "3 / 45, train loss: 0.0990\n",
            "4 / 45, train loss: 0.0613\n",
            "5 / 45, train loss: 0.0900\n",
            "6 / 45, train loss: 0.1449\n",
            "7 / 45, train loss: 0.0667\n",
            "8 / 45, train loss: 0.1183\n",
            "9 / 45, train loss: 0.0933\n",
            "10 / 45, train loss: 0.0942\n",
            "11 / 45, train loss: 0.0839\n",
            "12 / 45, train loss: 0.0807\n",
            "13 / 45, train loss: 0.1943\n",
            "14 / 45, train loss: 0.1059\n",
            "15 / 45, train loss: 0.0746\n",
            "16 / 45, train loss: 0.1067\n",
            "17 / 45, train loss: 0.1460\n",
            "18 / 45, train loss: 0.1206\n",
            "19 / 45, train loss: 0.0724\n",
            "20 / 45, train loss: 0.1453\n",
            "21 / 45, train loss: 0.1004\n",
            "22 / 45, train loss: 0.0570\n",
            "23 / 45, train loss: 0.1585\n",
            "24 / 45, train loss: 0.0932\n",
            "25 / 45, train loss: 0.1067\n",
            "26 / 45, train loss: 0.1915\n",
            "27 / 45, train loss: 0.1247\n",
            "28 / 45, train loss: 0.1302\n",
            "29 / 45, train loss: 0.0840\n",
            "30 / 45, train loss: 0.1261\n",
            "31 / 45, train loss: 0.1602\n",
            "32 / 45, train loss: 0.0853\n",
            "33 / 45, train loss: 0.1015\n",
            "34 / 45, train loss: 0.1502\n",
            "35 / 45, train loss: 0.0952\n",
            "36 / 45, train loss: 0.1248\n",
            "37 / 45, train loss: 0.1245\n",
            "38 / 45, train loss: 0.1379\n",
            "39 / 45, train loss: 0.0758\n",
            "40 / 45, train loss: 0.0782\n",
            "41 / 45, train loss: 0.1619\n",
            "42 / 45, train loss: 0.1567\n",
            "43 / 45, train loss: 0.1158\n",
            "44 / 45, train loss: 0.1071\n",
            "45 / 45, train loss: 0.1175\n",
            "epoch 138 loss: 5.1040\n",
            "current learning rate: 0.000173\n",
            "Epoch 140 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.0899\n",
            "2 / 45, train loss: 0.1499\n",
            "3 / 45, train loss: 0.1244\n",
            "4 / 45, train loss: 0.1089\n",
            "5 / 45, train loss: 0.0799\n",
            "6 / 45, train loss: 0.1555\n",
            "7 / 45, train loss: 0.0875\n",
            "8 / 45, train loss: 0.0840\n",
            "9 / 45, train loss: 0.0681\n",
            "10 / 45, train loss: 0.0853\n",
            "11 / 45, train loss: 0.1003\n",
            "12 / 45, train loss: 0.1132\n",
            "13 / 45, train loss: 0.0738\n",
            "14 / 45, train loss: 0.0776\n",
            "15 / 45, train loss: 0.0930\n",
            "16 / 45, train loss: 0.1712\n",
            "17 / 45, train loss: 0.1778\n",
            "18 / 45, train loss: 0.1763\n",
            "19 / 45, train loss: 0.1147\n",
            "20 / 45, train loss: 0.0758\n",
            "21 / 45, train loss: 0.1305\n",
            "22 / 45, train loss: 0.1122\n",
            "23 / 45, train loss: 0.0868\n",
            "24 / 45, train loss: 0.1564\n",
            "25 / 45, train loss: 0.1010\n",
            "26 / 45, train loss: 0.1330\n",
            "27 / 45, train loss: 0.1235\n",
            "28 / 45, train loss: 0.1244\n",
            "29 / 45, train loss: 0.1109\n",
            "30 / 45, train loss: 0.0519\n",
            "31 / 45, train loss: 0.1710\n",
            "32 / 45, train loss: 0.0454\n",
            "33 / 45, train loss: 0.1088\n",
            "34 / 45, train loss: 0.1143\n",
            "35 / 45, train loss: 0.1221\n",
            "36 / 45, train loss: 0.1230\n",
            "37 / 45, train loss: 0.1296\n",
            "38 / 45, train loss: 0.1192\n",
            "39 / 45, train loss: 0.0804\n",
            "40 / 45, train loss: 0.1828\n",
            "41 / 45, train loss: 0.1144\n",
            "42 / 45, train loss: 0.1047\n",
            "43 / 45, train loss: 0.1138\n",
            "44 / 45, train loss: 0.1117\n",
            "45 / 45, train loss: 0.1371\n",
            "epoch 139 loss: 5.1160\n",
            "current learning rate: 0.000172\n",
            "Loss - mean: 0.04916115342216058\tstd: 0.020266872503435816\n",
            "AUC - mean: 0.8549163813954684\tstd: 0.04194495798517431\n",
            "ACC - mean: 0.8954745205965909\tstd: 0.036113379824783555\n",
            "SEN - mean: 0.5329359151715224\tstd: 0.07911858569351125\n",
            "FDR - mean: 0.6940109385872801\tstd: 0.04538435124766\n",
            "SPE - mean: 0.9199143505600205\tstd: 0.02771434238875136\n",
            "Kappa - mean: 0.3309069853905223\tstd: 0.038171383533967485\n",
            "G-mean - mean: 0.6979339318352176\tstd: 0.05203802207965591\n",
            "IOU - mean: 0.23834739919008754\tstd: 0.029503293272475\n",
            "Dice - mean: 0.3839850291318349\tstd: 0.04031393148927934\n",
            "Loss - mean: 0.049076679670675236\tstd: 0.020281930716581156\n",
            "AUC - mean: 0.8551169865147787\tstd: 0.04241354340951346\n",
            "ACC - mean: 0.8988142880526456\tstd: 0.035114279870943406\n",
            "SEN - mean: 0.5205523223256111\tstd: 0.08023259097548338\n",
            "FDR - mean: 0.6869987279959994\tstd: 0.04611138408222754\n",
            "SPE - mean: 0.924410597596945\tstd: 0.02625380296009871\n",
            "Kappa - mean: 0.3339281985478166\tstd: 0.03862542929100256\n",
            "G-mean - mean: 0.6912934912261223\tstd: 0.05391588459459145\n",
            "IOU - mean: 0.23973555840978733\tstd: 0.02967957089147331\n",
            "Dice - mean: 0.3857835736495709\tstd: 0.04053021673175063\n",
            "Loss - mean: 0.04932960842482068\tstd: 0.02022857261807987\n",
            "AUC - mean: 0.8556496016277471\tstd: 0.04216639577997296\n",
            "ACC - mean: 0.8941164883700284\tstd: 0.03608943006704539\n",
            "SEN - mean: 0.5392436996957222\tstd: 0.07960392561642086\n",
            "FDR - mean: 0.6967890987482498\tstd: 0.04539323605623776\n",
            "SPE - mean: 0.9180479879143608\tstd: 0.02792595778907351\n",
            "Kappa - mean: 0.32979036115486837\tstd: 0.037778801894508704\n",
            "G-mean - mean: 0.7013474150908349\tstd: 0.05220509074154524\n",
            "IOU - mean: 0.23782759518069005\tstd: 0.029682101140829222\n",
            "Dice - mean: 0.3832941207685135\tstd: 0.04058529390360879\n",
            "best thin: epoch 105\tauc 0.8607\n",
            "best thick: epoch 105\tauc 0.8601\n",
            "best fusion: epoch 105\tauc 0.8609\n",
            "Epoch 141 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1122\n",
            "2 / 45, train loss: 0.1282\n",
            "3 / 45, train loss: 0.1146\n",
            "4 / 45, train loss: 0.1759\n",
            "5 / 45, train loss: 0.1273\n",
            "6 / 45, train loss: 0.1645\n",
            "7 / 45, train loss: 0.0948\n",
            "8 / 45, train loss: 0.1741\n",
            "9 / 45, train loss: 0.0944\n",
            "10 / 45, train loss: 0.0870\n",
            "11 / 45, train loss: 0.0896\n",
            "12 / 45, train loss: 0.0852\n",
            "13 / 45, train loss: 0.1086\n",
            "14 / 45, train loss: 0.0909\n",
            "15 / 45, train loss: 0.1043\n",
            "16 / 45, train loss: 0.0897\n",
            "17 / 45, train loss: 0.1089\n",
            "18 / 45, train loss: 0.1301\n",
            "19 / 45, train loss: 0.0888\n",
            "20 / 45, train loss: 0.1083\n",
            "21 / 45, train loss: 0.1861\n",
            "22 / 45, train loss: 0.1598\n",
            "23 / 45, train loss: 0.0874\n",
            "24 / 45, train loss: 0.1188\n",
            "25 / 45, train loss: 0.1643\n",
            "26 / 45, train loss: 0.0526\n",
            "27 / 45, train loss: 0.0597\n",
            "28 / 45, train loss: 0.0628\n",
            "29 / 45, train loss: 0.1530\n",
            "30 / 45, train loss: 0.1974\n",
            "31 / 45, train loss: 0.0473\n",
            "32 / 45, train loss: 0.1080\n",
            "33 / 45, train loss: 0.0898\n",
            "34 / 45, train loss: 0.1153\n",
            "35 / 45, train loss: 0.1633\n",
            "36 / 45, train loss: 0.1196\n",
            "37 / 45, train loss: 0.1066\n",
            "38 / 45, train loss: 0.1644\n",
            "39 / 45, train loss: 0.1017\n",
            "40 / 45, train loss: 0.0907\n",
            "41 / 45, train loss: 0.0500\n",
            "42 / 45, train loss: 0.0822\n",
            "43 / 45, train loss: 0.1209\n",
            "44 / 45, train loss: 0.0924\n",
            "45 / 45, train loss: 0.1355\n",
            "epoch 140 loss: 5.1070\n",
            "current learning rate: 0.000171\n",
            "Epoch 142 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1435\n",
            "2 / 45, train loss: 0.0936\n",
            "3 / 45, train loss: 0.1680\n",
            "4 / 45, train loss: 0.0831\n",
            "5 / 45, train loss: 0.1698\n",
            "6 / 45, train loss: 0.1178\n",
            "7 / 45, train loss: 0.1039\n",
            "8 / 45, train loss: 0.1294\n",
            "9 / 45, train loss: 0.1369\n",
            "10 / 45, train loss: 0.1260\n",
            "11 / 45, train loss: 0.1163\n",
            "12 / 45, train loss: 0.0845\n",
            "13 / 45, train loss: 0.1692\n",
            "14 / 45, train loss: 0.0994\n",
            "15 / 45, train loss: 0.1230\n",
            "16 / 45, train loss: 0.1039\n",
            "17 / 45, train loss: 0.0509\n",
            "18 / 45, train loss: 0.1563\n",
            "19 / 45, train loss: 0.0900\n",
            "20 / 45, train loss: 0.1581\n",
            "21 / 45, train loss: 0.1478\n",
            "22 / 45, train loss: 0.1803\n",
            "23 / 45, train loss: 0.1414\n",
            "24 / 45, train loss: 0.1445\n",
            "25 / 45, train loss: 0.1119\n",
            "26 / 45, train loss: 0.0917\n",
            "27 / 45, train loss: 0.0995\n",
            "28 / 45, train loss: 0.0986\n",
            "29 / 45, train loss: 0.1267\n",
            "30 / 45, train loss: 0.1299\n",
            "31 / 45, train loss: 0.0899\n",
            "32 / 45, train loss: 0.0662\n",
            "33 / 45, train loss: 0.1060\n",
            "34 / 45, train loss: 0.1190\n",
            "35 / 45, train loss: 0.0760\n",
            "36 / 45, train loss: 0.0866\n",
            "37 / 45, train loss: 0.0707\n",
            "38 / 45, train loss: 0.0942\n",
            "39 / 45, train loss: 0.1588\n",
            "40 / 45, train loss: 0.0902\n",
            "41 / 45, train loss: 0.0540\n",
            "42 / 45, train loss: 0.1033\n",
            "43 / 45, train loss: 0.0756\n",
            "44 / 45, train loss: 0.1158\n",
            "45 / 45, train loss: 0.0977\n",
            "epoch 141 loss: 5.0999\n",
            "current learning rate: 0.000170\n",
            "Epoch 143 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1977\n",
            "2 / 45, train loss: 0.0469\n",
            "3 / 45, train loss: 0.0928\n",
            "4 / 45, train loss: 0.0845\n",
            "5 / 45, train loss: 0.1067\n",
            "6 / 45, train loss: 0.1369\n",
            "7 / 45, train loss: 0.1136\n",
            "8 / 45, train loss: 0.1395\n",
            "9 / 45, train loss: 0.1203\n",
            "10 / 45, train loss: 0.1208\n",
            "11 / 45, train loss: 0.0875\n",
            "12 / 45, train loss: 0.0898\n",
            "13 / 45, train loss: 0.0840\n",
            "14 / 45, train loss: 0.1356\n",
            "15 / 45, train loss: 0.1135\n",
            "16 / 45, train loss: 0.1189\n",
            "17 / 45, train loss: 0.1053\n",
            "18 / 45, train loss: 0.0829\n",
            "19 / 45, train loss: 0.1162\n",
            "20 / 45, train loss: 0.1805\n",
            "21 / 45, train loss: 0.1230\n",
            "22 / 45, train loss: 0.1242\n",
            "23 / 45, train loss: 0.1386\n",
            "24 / 45, train loss: 0.0857\n",
            "25 / 45, train loss: 0.1528\n",
            "26 / 45, train loss: 0.1361\n",
            "27 / 45, train loss: 0.1152\n",
            "28 / 45, train loss: 0.1137\n",
            "29 / 45, train loss: 0.1370\n",
            "30 / 45, train loss: 0.0968\n",
            "31 / 45, train loss: 0.0817\n",
            "32 / 45, train loss: 0.1052\n",
            "33 / 45, train loss: 0.1149\n",
            "34 / 45, train loss: 0.0419\n",
            "35 / 45, train loss: 0.1317\n",
            "36 / 45, train loss: 0.1675\n",
            "37 / 45, train loss: 0.1408\n",
            "38 / 45, train loss: 0.1530\n",
            "39 / 45, train loss: 0.0924\n",
            "40 / 45, train loss: 0.0855\n",
            "41 / 45, train loss: 0.0763\n",
            "42 / 45, train loss: 0.1478\n",
            "43 / 45, train loss: 0.0815\n",
            "44 / 45, train loss: 0.0900\n",
            "45 / 45, train loss: 0.1035\n",
            "epoch 142 loss: 5.1109\n",
            "current learning rate: 0.000169\n",
            "Epoch 144 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.0916\n",
            "2 / 45, train loss: 0.1359\n",
            "3 / 45, train loss: 0.1034\n",
            "4 / 45, train loss: 0.1694\n",
            "5 / 45, train loss: 0.1091\n",
            "6 / 45, train loss: 0.1830\n",
            "7 / 45, train loss: 0.1309\n",
            "8 / 45, train loss: 0.1309\n",
            "9 / 45, train loss: 0.1674\n",
            "10 / 45, train loss: 0.0803\n",
            "11 / 45, train loss: 0.1275\n",
            "12 / 45, train loss: 0.1229\n",
            "13 / 45, train loss: 0.1186\n",
            "14 / 45, train loss: 0.1237\n",
            "15 / 45, train loss: 0.1419\n",
            "16 / 45, train loss: 0.0996\n",
            "17 / 45, train loss: 0.1581\n",
            "18 / 45, train loss: 0.1325\n",
            "19 / 45, train loss: 0.1089\n",
            "20 / 45, train loss: 0.1078\n",
            "21 / 45, train loss: 0.1215\n",
            "22 / 45, train loss: 0.0838\n",
            "23 / 45, train loss: 0.0621\n",
            "24 / 45, train loss: 0.1493\n",
            "25 / 45, train loss: 0.1012\n",
            "26 / 45, train loss: 0.0813\n",
            "27 / 45, train loss: 0.0747\n",
            "28 / 45, train loss: 0.1109\n",
            "29 / 45, train loss: 0.1660\n",
            "30 / 45, train loss: 0.0770\n",
            "31 / 45, train loss: 0.1345\n",
            "32 / 45, train loss: 0.0781\n",
            "33 / 45, train loss: 0.1198\n",
            "34 / 45, train loss: 0.0838\n",
            "35 / 45, train loss: 0.0905\n",
            "36 / 45, train loss: 0.0966\n",
            "37 / 45, train loss: 0.0874\n",
            "38 / 45, train loss: 0.0505\n",
            "39 / 45, train loss: 0.1567\n",
            "40 / 45, train loss: 0.0952\n",
            "41 / 45, train loss: 0.1367\n",
            "42 / 45, train loss: 0.0907\n",
            "43 / 45, train loss: 0.1111\n",
            "44 / 45, train loss: 0.0747\n",
            "45 / 45, train loss: 0.1329\n",
            "epoch 143 loss: 5.1106\n",
            "current learning rate: 0.000168\n",
            "Epoch 145 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.0973\n",
            "2 / 45, train loss: 0.1179\n",
            "3 / 45, train loss: 0.0989\n",
            "4 / 45, train loss: 0.0848\n",
            "5 / 45, train loss: 0.1276\n",
            "6 / 45, train loss: 0.0872\n",
            "7 / 45, train loss: 0.1221\n",
            "8 / 45, train loss: 0.0669\n",
            "9 / 45, train loss: 0.0775\n",
            "10 / 45, train loss: 0.1617\n",
            "11 / 45, train loss: 0.0744\n",
            "12 / 45, train loss: 0.0948\n",
            "13 / 45, train loss: 0.1514\n",
            "14 / 45, train loss: 0.1223\n",
            "15 / 45, train loss: 0.1698\n",
            "16 / 45, train loss: 0.0906\n",
            "17 / 45, train loss: 0.0541\n",
            "18 / 45, train loss: 0.0946\n",
            "19 / 45, train loss: 0.1047\n",
            "20 / 45, train loss: 0.1346\n",
            "21 / 45, train loss: 0.1284\n",
            "22 / 45, train loss: 0.1256\n",
            "23 / 45, train loss: 0.1113\n",
            "24 / 45, train loss: 0.0855\n",
            "25 / 45, train loss: 0.1427\n",
            "26 / 45, train loss: 0.1101\n",
            "27 / 45, train loss: 0.1496\n",
            "28 / 45, train loss: 0.1906\n",
            "29 / 45, train loss: 0.0896\n",
            "30 / 45, train loss: 0.0763\n",
            "31 / 45, train loss: 0.1076\n",
            "32 / 45, train loss: 0.1070\n",
            "33 / 45, train loss: 0.0717\n",
            "34 / 45, train loss: 0.1743\n",
            "35 / 45, train loss: 0.0935\n",
            "36 / 45, train loss: 0.1479\n",
            "37 / 45, train loss: 0.1029\n",
            "38 / 45, train loss: 0.1033\n",
            "39 / 45, train loss: 0.1291\n",
            "40 / 45, train loss: 0.1079\n",
            "41 / 45, train loss: 0.1308\n",
            "42 / 45, train loss: 0.1782\n",
            "43 / 45, train loss: 0.0974\n",
            "44 / 45, train loss: 0.0631\n",
            "45 / 45, train loss: 0.1310\n",
            "epoch 144 loss: 5.0885\n",
            "current learning rate: 0.000168\n",
            "Loss - mean: 0.04856345133686608\tstd: 0.020593463670086187\n",
            "AUC - mean: 0.8589576291921837\tstd: 0.04520220970053692\n",
            "ACC - mean: 0.9121508164839311\tstd: 0.03242884199801287\n",
            "SEN - mean: 0.47078668084729025\tstd: 0.08609765904032368\n",
            "FDR - mean: 0.6476930326249567\tstd: 0.05209273558613543\n",
            "SPE - mean: 0.9424625716050499\tstd: 0.021858180309806137\n",
            "Kappa - mean: 0.3500732044408151\tstd: 0.048390747143768925\n",
            "G-mean - mean: 0.6630670138041809\tstd: 0.060970070977033705\n",
            "IOU - mean: 0.2481440265825416\tstd: 0.033851095550074276\n",
            "Dice - mean: 0.3963810819943344\tstd: 0.04576552998163582\n",
            "Loss - mean: 0.04859854966740717\tstd: 0.020569102934543924\n",
            "AUC - mean: 0.8586218333355624\tstd: 0.04531585614475116\n",
            "ACC - mean: 0.9112443056973544\tstd: 0.03280261350462307\n",
            "SEN - mean: 0.4746040031129152\tstd: 0.08521351982426772\n",
            "FDR - mean: 0.6502867875966649\tstd: 0.051528978428503756\n",
            "SPE - mean: 0.9412089852632022\tstd: 0.022361806901238585\n",
            "Kappa - mean: 0.34940868237340134\tstd: 0.04774908186532999\n",
            "G-mean - mean: 0.6654146294540032\tstd: 0.06001240100060147\n",
            "IOU - mean: 0.24792247633961706\tstd: 0.03327402097676299\n",
            "Dice - mean: 0.39613885474427785\tstd: 0.04496331069214975\n",
            "Loss - mean: 0.048662223260511055\tstd: 0.020493450084505035\n",
            "AUC - mean: 0.8593059260606416\tstd: 0.045325328003661035\n",
            "ACC - mean: 0.9089261835271661\tstd: 0.03336251327878667\n",
            "SEN - mean: 0.4869300708315954\tstd: 0.08623486093343605\n",
            "FDR - mean: 0.6572076197119053\tstd: 0.05054048976747541\n",
            "SPE - mean: 0.9378554839525889\tstd: 0.023472771250038885\n",
            "Kappa - mean: 0.3481943073010744\tstd: 0.04706287773999935\n",
            "G-mean - mean: 0.6728494892842484\tstd: 0.05985572444879631\n",
            "IOU - mean: 0.2477329905015697\tstd: 0.03297379060883647\n",
            "Dice - mean: 0.39591282151446044\tstd: 0.044710314959562555\n",
            "best thin: epoch 105\tauc 0.8607\n",
            "best thick: epoch 105\tauc 0.8601\n",
            "best fusion: epoch 105\tauc 0.8609\n",
            "Epoch 146 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1131\n",
            "2 / 45, train loss: 0.1659\n",
            "3 / 45, train loss: 0.1298\n",
            "4 / 45, train loss: 0.1595\n",
            "5 / 45, train loss: 0.1021\n",
            "6 / 45, train loss: 0.1208\n",
            "7 / 45, train loss: 0.0824\n",
            "8 / 45, train loss: 0.1220\n",
            "9 / 45, train loss: 0.1074\n",
            "10 / 45, train loss: 0.0884\n",
            "11 / 45, train loss: 0.0749\n",
            "12 / 45, train loss: 0.1795\n",
            "13 / 45, train loss: 0.1520\n",
            "14 / 45, train loss: 0.0698\n",
            "15 / 45, train loss: 0.0724\n",
            "16 / 45, train loss: 0.1347\n",
            "17 / 45, train loss: 0.0964\n",
            "18 / 45, train loss: 0.0809\n",
            "19 / 45, train loss: 0.1014\n",
            "20 / 45, train loss: 0.0930\n",
            "21 / 45, train loss: 0.1090\n",
            "22 / 45, train loss: 0.0671\n",
            "23 / 45, train loss: 0.1213\n",
            "24 / 45, train loss: 0.1022\n",
            "25 / 45, train loss: 0.1545\n",
            "26 / 45, train loss: 0.0794\n",
            "27 / 45, train loss: 0.1693\n",
            "28 / 45, train loss: 0.1012\n",
            "29 / 45, train loss: 0.0786\n",
            "30 / 45, train loss: 0.1021\n",
            "31 / 45, train loss: 0.0963\n",
            "32 / 45, train loss: 0.1182\n",
            "33 / 45, train loss: 0.0881\n",
            "34 / 45, train loss: 0.2134\n",
            "35 / 45, train loss: 0.1220\n",
            "36 / 45, train loss: 0.1248\n",
            "37 / 45, train loss: 0.1475\n",
            "38 / 45, train loss: 0.0379\n",
            "39 / 45, train loss: 0.0714\n",
            "40 / 45, train loss: 0.0679\n",
            "41 / 45, train loss: 0.1243\n",
            "42 / 45, train loss: 0.1151\n",
            "43 / 45, train loss: 0.1602\n",
            "44 / 45, train loss: 0.1469\n",
            "45 / 45, train loss: 0.1266\n",
            "epoch 145 loss: 5.0917\n",
            "current learning rate: 0.000167\n",
            "Epoch 147 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.0928\n",
            "2 / 45, train loss: 0.1750\n",
            "3 / 45, train loss: 0.1457\n",
            "4 / 45, train loss: 0.1148\n",
            "5 / 45, train loss: 0.1433\n",
            "6 / 45, train loss: 0.1161\n",
            "7 / 45, train loss: 0.1383\n",
            "8 / 45, train loss: 0.1591\n",
            "9 / 45, train loss: 0.1247\n",
            "10 / 45, train loss: 0.1294\n",
            "11 / 45, train loss: 0.0666\n",
            "12 / 45, train loss: 0.0998\n",
            "13 / 45, train loss: 0.0525\n",
            "14 / 45, train loss: 0.1425\n",
            "15 / 45, train loss: 0.0672\n",
            "16 / 45, train loss: 0.0497\n",
            "17 / 45, train loss: 0.1191\n",
            "18 / 45, train loss: 0.1194\n",
            "19 / 45, train loss: 0.1497\n",
            "20 / 45, train loss: 0.0903\n",
            "21 / 45, train loss: 0.0877\n",
            "22 / 45, train loss: 0.1599\n",
            "23 / 45, train loss: 0.1374\n",
            "24 / 45, train loss: 0.0546\n",
            "25 / 45, train loss: 0.0966\n",
            "26 / 45, train loss: 0.1252\n",
            "27 / 45, train loss: 0.0742\n",
            "28 / 45, train loss: 0.0689\n",
            "29 / 45, train loss: 0.0816\n",
            "30 / 45, train loss: 0.1055\n",
            "31 / 45, train loss: 0.1012\n",
            "32 / 45, train loss: 0.1202\n",
            "33 / 45, train loss: 0.1310\n",
            "34 / 45, train loss: 0.1752\n",
            "35 / 45, train loss: 0.0713\n",
            "36 / 45, train loss: 0.0863\n",
            "37 / 45, train loss: 0.2099\n",
            "38 / 45, train loss: 0.0859\n",
            "39 / 45, train loss: 0.1253\n",
            "40 / 45, train loss: 0.0998\n",
            "41 / 45, train loss: 0.1258\n",
            "42 / 45, train loss: 0.1133\n",
            "43 / 45, train loss: 0.1291\n",
            "44 / 45, train loss: 0.1835\n",
            "45 / 45, train loss: 0.0581\n",
            "epoch 146 loss: 5.1033\n",
            "current learning rate: 0.000166\n",
            "Epoch 148 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1259\n",
            "2 / 45, train loss: 0.1313\n",
            "3 / 45, train loss: 0.1411\n",
            "4 / 45, train loss: 0.1394\n",
            "5 / 45, train loss: 0.1717\n",
            "6 / 45, train loss: 0.0946\n",
            "7 / 45, train loss: 0.0718\n",
            "8 / 45, train loss: 0.1452\n",
            "9 / 45, train loss: 0.1506\n",
            "10 / 45, train loss: 0.1052\n",
            "11 / 45, train loss: 0.1218\n",
            "12 / 45, train loss: 0.1315\n",
            "13 / 45, train loss: 0.0718\n",
            "14 / 45, train loss: 0.1355\n",
            "15 / 45, train loss: 0.0843\n",
            "16 / 45, train loss: 0.1352\n",
            "17 / 45, train loss: 0.1212\n",
            "18 / 45, train loss: 0.1984\n",
            "19 / 45, train loss: 0.0932\n",
            "20 / 45, train loss: 0.0824\n",
            "21 / 45, train loss: 0.0814\n",
            "22 / 45, train loss: 0.1295\n",
            "23 / 45, train loss: 0.1424\n",
            "24 / 45, train loss: 0.1372\n",
            "25 / 45, train loss: 0.0519\n",
            "26 / 45, train loss: 0.0706\n",
            "27 / 45, train loss: 0.0683\n",
            "28 / 45, train loss: 0.1008\n",
            "29 / 45, train loss: 0.1220\n",
            "30 / 45, train loss: 0.0554\n",
            "31 / 45, train loss: 0.1144\n",
            "32 / 45, train loss: 0.0624\n",
            "33 / 45, train loss: 0.1401\n",
            "34 / 45, train loss: 0.0974\n",
            "35 / 45, train loss: 0.1428\n",
            "36 / 45, train loss: 0.0937\n",
            "37 / 45, train loss: 0.1173\n",
            "38 / 45, train loss: 0.1101\n",
            "39 / 45, train loss: 0.1180\n",
            "40 / 45, train loss: 0.0815\n",
            "41 / 45, train loss: 0.1056\n",
            "42 / 45, train loss: 0.1329\n",
            "43 / 45, train loss: 0.1543\n",
            "44 / 45, train loss: 0.1147\n",
            "45 / 45, train loss: 0.1027\n",
            "epoch 147 loss: 5.0995\n",
            "current learning rate: 0.000165\n",
            "Epoch 149 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1015\n",
            "2 / 45, train loss: 0.1022\n",
            "3 / 45, train loss: 0.1275\n",
            "4 / 45, train loss: 0.1030\n",
            "5 / 45, train loss: 0.1489\n",
            "6 / 45, train loss: 0.0901\n",
            "7 / 45, train loss: 0.0695\n",
            "8 / 45, train loss: 0.1492\n",
            "9 / 45, train loss: 0.0887\n",
            "10 / 45, train loss: 0.1098\n",
            "11 / 45, train loss: 0.1086\n",
            "12 / 45, train loss: 0.0387\n",
            "13 / 45, train loss: 0.0623\n",
            "14 / 45, train loss: 0.1549\n",
            "15 / 45, train loss: 0.1627\n",
            "16 / 45, train loss: 0.0869\n",
            "17 / 45, train loss: 0.0926\n",
            "18 / 45, train loss: 0.0803\n",
            "19 / 45, train loss: 0.0992\n",
            "20 / 45, train loss: 0.1428\n",
            "21 / 45, train loss: 0.1609\n",
            "22 / 45, train loss: 0.1305\n",
            "23 / 45, train loss: 0.1035\n",
            "24 / 45, train loss: 0.1083\n",
            "25 / 45, train loss: 0.0980\n",
            "26 / 45, train loss: 0.1728\n",
            "27 / 45, train loss: 0.0909\n",
            "28 / 45, train loss: 0.0666\n",
            "29 / 45, train loss: 0.1658\n",
            "30 / 45, train loss: 0.1078\n",
            "31 / 45, train loss: 0.1029\n",
            "32 / 45, train loss: 0.1418\n",
            "33 / 45, train loss: 0.0493\n",
            "34 / 45, train loss: 0.1285\n",
            "35 / 45, train loss: 0.1447\n",
            "36 / 45, train loss: 0.1181\n",
            "37 / 45, train loss: 0.1534\n",
            "38 / 45, train loss: 0.1241\n",
            "39 / 45, train loss: 0.0642\n",
            "40 / 45, train loss: 0.1022\n",
            "41 / 45, train loss: 0.1154\n",
            "42 / 45, train loss: 0.1283\n",
            "43 / 45, train loss: 0.1295\n",
            "44 / 45, train loss: 0.1558\n",
            "45 / 45, train loss: 0.1093\n",
            "epoch 148 loss: 5.0921\n",
            "current learning rate: 0.000164\n",
            "Epoch 150 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1055\n",
            "2 / 45, train loss: 0.0884\n",
            "3 / 45, train loss: 0.0982\n",
            "4 / 45, train loss: 0.0856\n",
            "5 / 45, train loss: 0.0761\n",
            "6 / 45, train loss: 0.0541\n",
            "7 / 45, train loss: 0.1077\n",
            "8 / 45, train loss: 0.1122\n",
            "9 / 45, train loss: 0.0954\n",
            "10 / 45, train loss: 0.0991\n",
            "11 / 45, train loss: 0.1246\n",
            "12 / 45, train loss: 0.1167\n",
            "13 / 45, train loss: 0.1679\n",
            "14 / 45, train loss: 0.0851\n",
            "15 / 45, train loss: 0.1829\n",
            "16 / 45, train loss: 0.0998\n",
            "17 / 45, train loss: 0.1127\n",
            "18 / 45, train loss: 0.0742\n",
            "19 / 45, train loss: 0.1643\n",
            "20 / 45, train loss: 0.2026\n",
            "21 / 45, train loss: 0.1331\n",
            "22 / 45, train loss: 0.1071\n",
            "23 / 45, train loss: 0.0861\n",
            "24 / 45, train loss: 0.0756\n",
            "25 / 45, train loss: 0.1151\n",
            "26 / 45, train loss: 0.1588\n",
            "27 / 45, train loss: 0.1459\n",
            "28 / 45, train loss: 0.1322\n",
            "29 / 45, train loss: 0.1433\n",
            "30 / 45, train loss: 0.1162\n",
            "31 / 45, train loss: 0.1163\n",
            "32 / 45, train loss: 0.0600\n",
            "33 / 45, train loss: 0.1557\n",
            "34 / 45, train loss: 0.0851\n",
            "35 / 45, train loss: 0.1038\n",
            "36 / 45, train loss: 0.0368\n",
            "37 / 45, train loss: 0.0972\n",
            "38 / 45, train loss: 0.2038\n",
            "39 / 45, train loss: 0.1295\n",
            "40 / 45, train loss: 0.0752\n",
            "41 / 45, train loss: 0.1508\n",
            "42 / 45, train loss: 0.1361\n",
            "43 / 45, train loss: 0.0879\n",
            "44 / 45, train loss: 0.0797\n",
            "45 / 45, train loss: 0.1291\n",
            "epoch 149 loss: 5.1131\n",
            "current learning rate: 0.000163\n",
            "Loss - mean: 0.048527024051343855\tstd: 0.020641570272036548\n",
            "AUC - mean: 0.8581159023746157\tstd: 0.04485999499595828\n",
            "ACC - mean: 0.9176117290150035\tstd: 0.031251571792930956\n",
            "SEN - mean: 0.44108968790327424\tstd: 0.0859395713015823\n",
            "FDR - mean: 0.6283950692160317\tstd: 0.05466574708581434\n",
            "SPE - mean: 0.9502756868875967\tstd: 0.01955401275596039\n",
            "Kappa - mean: 0.3525257034753382\tstd: 0.05059079582252956\n",
            "G-mean - mean: 0.6441083403969731\tstd: 0.06292885884839242\n",
            "IOU - mean: 0.2481580978408312\tstd: 0.03569627640313235\n",
            "Dice - mean: 0.39626605071268595\tstd: 0.048053335184259395\n",
            "Loss - mean: 0.048521745738319376\tstd: 0.02062197700134002\n",
            "AUC - mean: 0.8575854774057302\tstd: 0.0446829490520791\n",
            "ACC - mean: 0.9188737002286044\tstd: 0.03111288313333887\n",
            "SEN - mean: 0.43418031458818335\tstd: 0.08574299982372584\n",
            "FDR - mean: 0.6236430126091298\tstd: 0.05372550520579403\n",
            "SPE - mean: 0.952068968286924\tstd: 0.018980024251662845\n",
            "Kappa - mean: 0.35331678774303327\tstd: 0.052045433034030725\n",
            "G-mean - mean: 0.6395608757078607\tstd: 0.06358975418210888\n",
            "IOU - mean: 0.24836817632317523\tstd: 0.036684850569843185\n",
            "Dice - mean: 0.39645963302010917\tstd: 0.04935563272750787\n",
            "Loss - mean: 0.04853457115082578\tstd: 0.0205304021583592\n",
            "AUC - mean: 0.8583192571165316\tstd: 0.04487031687106036\n",
            "ACC - mean: 0.9162405187433417\tstd: 0.0316891784414371\n",
            "SEN - mean: 0.4498932723074595\tstd: 0.08742033149506931\n",
            "FDR - mean: 0.6334852147407953\tstd: 0.05347190597975194\n",
            "SPE - mean: 0.9481664054487638\tstd: 0.020343763820445598\n",
            "Kappa - mean: 0.3526278943458325\tstd: 0.0506660020136776\n",
            "G-mean - mean: 0.6497749435338009\tstd: 0.06340480844908546\n",
            "IOU - mean: 0.2487872637968918\tstd: 0.035797730517729366\n",
            "Dice - mean: 0.39706372159636827\tstd: 0.048278823986343075\n",
            "best thin: epoch 105\tauc 0.8607\n",
            "best thick: epoch 105\tauc 0.8601\n",
            "best fusion: epoch 105\tauc 0.8609\n",
            "Epoch 151 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1158\n",
            "2 / 45, train loss: 0.1462\n",
            "3 / 45, train loss: 0.1182\n",
            "4 / 45, train loss: 0.1683\n",
            "5 / 45, train loss: 0.1039\n",
            "6 / 45, train loss: 0.0600\n",
            "7 / 45, train loss: 0.0802\n",
            "8 / 45, train loss: 0.1768\n",
            "9 / 45, train loss: 0.1376\n",
            "10 / 45, train loss: 0.0802\n",
            "11 / 45, train loss: 0.1295\n",
            "12 / 45, train loss: 0.0898\n",
            "13 / 45, train loss: 0.0776\n",
            "14 / 45, train loss: 0.0731\n",
            "15 / 45, train loss: 0.1134\n",
            "16 / 45, train loss: 0.1483\n",
            "17 / 45, train loss: 0.1166\n",
            "18 / 45, train loss: 0.1033\n",
            "19 / 45, train loss: 0.1003\n",
            "20 / 45, train loss: 0.2069\n",
            "21 / 45, train loss: 0.1094\n",
            "22 / 45, train loss: 0.1410\n",
            "23 / 45, train loss: 0.0590\n",
            "24 / 45, train loss: 0.1043\n",
            "25 / 45, train loss: 0.0810\n",
            "26 / 45, train loss: 0.1448\n",
            "27 / 45, train loss: 0.0837\n",
            "28 / 45, train loss: 0.1009\n",
            "29 / 45, train loss: 0.0761\n",
            "30 / 45, train loss: 0.1360\n",
            "31 / 45, train loss: 0.1029\n",
            "32 / 45, train loss: 0.1275\n",
            "33 / 45, train loss: 0.0896\n",
            "34 / 45, train loss: 0.0847\n",
            "35 / 45, train loss: 0.2096\n",
            "36 / 45, train loss: 0.0550\n",
            "37 / 45, train loss: 0.1505\n",
            "38 / 45, train loss: 0.0711\n",
            "39 / 45, train loss: 0.1685\n",
            "40 / 45, train loss: 0.1303\n",
            "41 / 45, train loss: 0.1040\n",
            "42 / 45, train loss: 0.0706\n",
            "43 / 45, train loss: 0.0967\n",
            "44 / 45, train loss: 0.1259\n",
            "45 / 45, train loss: 0.1281\n",
            "epoch 150 loss: 5.0970\n",
            "current learning rate: 0.000162\n",
            "Epoch 152 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1553\n",
            "2 / 45, train loss: 0.1343\n",
            "3 / 45, train loss: 0.0588\n",
            "4 / 45, train loss: 0.0912\n",
            "5 / 45, train loss: 0.1377\n",
            "6 / 45, train loss: 0.1071\n",
            "7 / 45, train loss: 0.0955\n",
            "8 / 45, train loss: 0.0762\n",
            "9 / 45, train loss: 0.1160\n",
            "10 / 45, train loss: 0.1101\n",
            "11 / 45, train loss: 0.1339\n",
            "12 / 45, train loss: 0.1114\n",
            "13 / 45, train loss: 0.1191\n",
            "14 / 45, train loss: 0.1582\n",
            "15 / 45, train loss: 0.0808\n",
            "16 / 45, train loss: 0.0828\n",
            "17 / 45, train loss: 0.1068\n",
            "18 / 45, train loss: 0.0934\n",
            "19 / 45, train loss: 0.0949\n",
            "20 / 45, train loss: 0.0812\n",
            "21 / 45, train loss: 0.0599\n",
            "22 / 45, train loss: 0.1214\n",
            "23 / 45, train loss: 0.1431\n",
            "24 / 45, train loss: 0.1711\n",
            "25 / 45, train loss: 0.1177\n",
            "26 / 45, train loss: 0.1521\n",
            "27 / 45, train loss: 0.1324\n",
            "28 / 45, train loss: 0.1320\n",
            "29 / 45, train loss: 0.1359\n",
            "30 / 45, train loss: 0.0791\n",
            "31 / 45, train loss: 0.0775\n",
            "32 / 45, train loss: 0.1451\n",
            "33 / 45, train loss: 0.0612\n",
            "34 / 45, train loss: 0.0991\n",
            "35 / 45, train loss: 0.1446\n",
            "36 / 45, train loss: 0.1227\n",
            "37 / 45, train loss: 0.1138\n",
            "38 / 45, train loss: 0.1501\n",
            "39 / 45, train loss: 0.1184\n",
            "40 / 45, train loss: 0.0684\n",
            "41 / 45, train loss: 0.0843\n",
            "42 / 45, train loss: 0.2098\n",
            "43 / 45, train loss: 0.0797\n",
            "44 / 45, train loss: 0.1010\n",
            "45 / 45, train loss: 0.1283\n",
            "epoch 151 loss: 5.0934\n",
            "current learning rate: 0.000161\n",
            "Epoch 153 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1135\n",
            "2 / 45, train loss: 0.1122\n",
            "3 / 45, train loss: 0.0743\n",
            "4 / 45, train loss: 0.0712\n",
            "5 / 45, train loss: 0.1293\n",
            "6 / 45, train loss: 0.1083\n",
            "7 / 45, train loss: 0.1102\n",
            "8 / 45, train loss: 0.1802\n",
            "9 / 45, train loss: 0.1040\n",
            "10 / 45, train loss: 0.0519\n",
            "11 / 45, train loss: 0.0999\n",
            "12 / 45, train loss: 0.1575\n",
            "13 / 45, train loss: 0.0994\n",
            "14 / 45, train loss: 0.1207\n",
            "15 / 45, train loss: 0.0878\n",
            "16 / 45, train loss: 0.0860\n",
            "17 / 45, train loss: 0.0931\n",
            "18 / 45, train loss: 0.0740\n",
            "19 / 45, train loss: 0.1784\n",
            "20 / 45, train loss: 0.0884\n",
            "21 / 45, train loss: 0.1011\n",
            "22 / 45, train loss: 0.1370\n",
            "23 / 45, train loss: 0.1362\n",
            "24 / 45, train loss: 0.1282\n",
            "25 / 45, train loss: 0.1201\n",
            "26 / 45, train loss: 0.1739\n",
            "27 / 45, train loss: 0.0719\n",
            "28 / 45, train loss: 0.0757\n",
            "29 / 45, train loss: 0.1040\n",
            "30 / 45, train loss: 0.1023\n",
            "31 / 45, train loss: 0.1629\n",
            "32 / 45, train loss: 0.1591\n",
            "33 / 45, train loss: 0.1228\n",
            "34 / 45, train loss: 0.0868\n",
            "35 / 45, train loss: 0.1688\n",
            "36 / 45, train loss: 0.1245\n",
            "37 / 45, train loss: 0.0870\n",
            "38 / 45, train loss: 0.1318\n",
            "39 / 45, train loss: 0.0727\n",
            "40 / 45, train loss: 0.1015\n",
            "41 / 45, train loss: 0.0894\n",
            "42 / 45, train loss: 0.0618\n",
            "43 / 45, train loss: 0.1433\n",
            "44 / 45, train loss: 0.1391\n",
            "45 / 45, train loss: 0.1327\n",
            "epoch 152 loss: 5.0749\n",
            "current learning rate: 0.000160\n",
            "Epoch 154 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.0870\n",
            "2 / 45, train loss: 0.0912\n",
            "3 / 45, train loss: 0.0555\n",
            "4 / 45, train loss: 0.1613\n",
            "5 / 45, train loss: 0.1410\n",
            "6 / 45, train loss: 0.1528\n",
            "7 / 45, train loss: 0.1196\n",
            "8 / 45, train loss: 0.0967\n",
            "9 / 45, train loss: 0.1249\n",
            "10 / 45, train loss: 0.1125\n",
            "11 / 45, train loss: 0.0893\n",
            "12 / 45, train loss: 0.1198\n",
            "13 / 45, train loss: 0.1332\n",
            "14 / 45, train loss: 0.1466\n",
            "15 / 45, train loss: 0.0755\n",
            "16 / 45, train loss: 0.1054\n",
            "17 / 45, train loss: 0.1029\n",
            "18 / 45, train loss: 0.1375\n",
            "19 / 45, train loss: 0.0903\n",
            "20 / 45, train loss: 0.1140\n",
            "21 / 45, train loss: 0.0829\n",
            "22 / 45, train loss: 0.1451\n",
            "23 / 45, train loss: 0.1028\n",
            "24 / 45, train loss: 0.1089\n",
            "25 / 45, train loss: 0.1060\n",
            "26 / 45, train loss: 0.1162\n",
            "27 / 45, train loss: 0.1756\n",
            "28 / 45, train loss: 0.0870\n",
            "29 / 45, train loss: 0.1239\n",
            "30 / 45, train loss: 0.0937\n",
            "31 / 45, train loss: 0.0774\n",
            "32 / 45, train loss: 0.1655\n",
            "33 / 45, train loss: 0.0772\n",
            "34 / 45, train loss: 0.1208\n",
            "35 / 45, train loss: 0.1824\n",
            "36 / 45, train loss: 0.0824\n",
            "37 / 45, train loss: 0.1031\n",
            "38 / 45, train loss: 0.1157\n",
            "39 / 45, train loss: 0.0892\n",
            "40 / 45, train loss: 0.2110\n",
            "41 / 45, train loss: 0.1127\n",
            "42 / 45, train loss: 0.0941\n",
            "43 / 45, train loss: 0.0956\n",
            "44 / 45, train loss: 0.0809\n",
            "45 / 45, train loss: 0.0782\n",
            "epoch 153 loss: 5.0853\n",
            "current learning rate: 0.000159\n",
            "Epoch 155 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.0956\n",
            "2 / 45, train loss: 0.0952\n",
            "3 / 45, train loss: 0.0777\n",
            "4 / 45, train loss: 0.1184\n",
            "5 / 45, train loss: 0.0778\n",
            "6 / 45, train loss: 0.0752\n",
            "7 / 45, train loss: 0.0626\n",
            "8 / 45, train loss: 0.1552\n",
            "9 / 45, train loss: 0.1127\n",
            "10 / 45, train loss: 0.1022\n",
            "11 / 45, train loss: 0.1020\n",
            "12 / 45, train loss: 0.1347\n",
            "13 / 45, train loss: 0.0844\n",
            "14 / 45, train loss: 0.0442\n",
            "15 / 45, train loss: 0.1147\n",
            "16 / 45, train loss: 0.1309\n",
            "17 / 45, train loss: 0.1530\n",
            "18 / 45, train loss: 0.0777\n",
            "19 / 45, train loss: 0.1821\n",
            "20 / 45, train loss: 0.1034\n",
            "21 / 45, train loss: 0.1641\n",
            "22 / 45, train loss: 0.1464\n",
            "23 / 45, train loss: 0.1081\n",
            "24 / 45, train loss: 0.1176\n",
            "25 / 45, train loss: 0.1358\n",
            "26 / 45, train loss: 0.1600\n",
            "27 / 45, train loss: 0.0743\n",
            "28 / 45, train loss: 0.1216\n",
            "29 / 45, train loss: 0.0728\n",
            "30 / 45, train loss: 0.0980\n",
            "31 / 45, train loss: 0.0862\n",
            "32 / 45, train loss: 0.1462\n",
            "33 / 45, train loss: 0.0807\n",
            "34 / 45, train loss: 0.0990\n",
            "35 / 45, train loss: 0.1290\n",
            "36 / 45, train loss: 0.1014\n",
            "37 / 45, train loss: 0.1675\n",
            "38 / 45, train loss: 0.1133\n",
            "39 / 45, train loss: 0.0841\n",
            "40 / 45, train loss: 0.1395\n",
            "41 / 45, train loss: 0.1777\n",
            "42 / 45, train loss: 0.0821\n",
            "43 / 45, train loss: 0.0739\n",
            "44 / 45, train loss: 0.1733\n",
            "45 / 45, train loss: 0.1250\n",
            "epoch 154 loss: 5.0775\n",
            "current learning rate: 0.000158\n",
            "Loss - mean: 0.048459442501718346\tstd: 0.02060671923222128\n",
            "AUC - mean: 0.8587548061428666\tstd: 0.044555788183516826\n",
            "ACC - mean: 0.9116384332830255\tstd: 0.03559178709268582\n",
            "SEN - mean: 0.46769575058130647\tstd: 0.0883774898106423\n",
            "FDR - mean: 0.6420169965253754\tstd: 0.0564102416843691\n",
            "SPE - mean: 0.9413592370481138\tstd: 0.026415888336973777\n",
            "Kappa - mean: 0.35099087997259376\tstd: 0.04992907480735582\n",
            "G-mean - mean: 0.6599698531786847\tstd: 0.061703079675972605\n",
            "IOU - mean: 0.249129763065272\tstd: 0.035134894095785976\n",
            "Dice - mean: 0.3975544721422554\tstd: 0.04736464070087628\n",
            "Loss - mean: 0.048447541130537335\tstd: 0.020572502408133672\n",
            "AUC - mean: 0.8585165222417128\tstd: 0.04442075761357656\n",
            "ACC - mean: 0.9111808430064808\tstd: 0.0353873323452809\n",
            "SEN - mean: 0.4701308204715327\tstd: 0.08872297445670944\n",
            "FDR - mean: 0.643377101705714\tstd: 0.05697048843252231\n",
            "SPE - mean: 0.9407740968436474\tstd: 0.026263576597674386\n",
            "Kappa - mean: 0.35052901539409836\tstd: 0.0497990570884496\n",
            "G-mean - mean: 0.6615006345184052\tstd: 0.06173060968032466\n",
            "IOU - mean: 0.24888471718591987\tstd: 0.035009709848744894\n",
            "Dice - mean: 0.3972472691046071\tstd: 0.04727752387811613\n",
            "Loss - mean: 0.04850819393653761\tstd: 0.02053693197142707\n",
            "AUC - mean: 0.8591359090705123\tstd: 0.04453717256421803\n",
            "ACC - mean: 0.909103046764027\tstd: 0.036375895280078605\n",
            "SEN - mean: 0.48091422505002507\tstd: 0.08914384751819582\n",
            "FDR - mean: 0.6495980289836968\tstd: 0.05567962938176197\n",
            "SPE - mean: 0.9377054918130299\tstd: 0.027748005733504232\n",
            "Kappa - mean: 0.34984390595181725\tstd: 0.049307656999088345\n",
            "G-mean - mean: 0.6680339290024929\tstd: 0.06105602219613342\n",
            "IOU - mean: 0.2490598416648843\tstd: 0.034627287374914203\n",
            "Dice - mean: 0.3974986011947484\tstd: 0.04683903376639588\n",
            "best thin: epoch 105\tauc 0.8607\n",
            "best thick: epoch 105\tauc 0.8601\n",
            "best fusion: epoch 105\tauc 0.8609\n",
            "Epoch 156 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1389\n",
            "2 / 45, train loss: 0.1496\n",
            "3 / 45, train loss: 0.1160\n",
            "4 / 45, train loss: 0.1198\n",
            "5 / 45, train loss: 0.1352\n",
            "6 / 45, train loss: 0.1174\n",
            "7 / 45, train loss: 0.0874\n",
            "8 / 45, train loss: 0.1548\n",
            "9 / 45, train loss: 0.0533\n",
            "10 / 45, train loss: 0.1992\n",
            "11 / 45, train loss: 0.0661\n",
            "12 / 45, train loss: 0.1279\n",
            "13 / 45, train loss: 0.0766\n",
            "14 / 45, train loss: 0.1560\n",
            "15 / 45, train loss: 0.1660\n",
            "16 / 45, train loss: 0.1098\n",
            "17 / 45, train loss: 0.0847\n",
            "18 / 45, train loss: 0.1290\n",
            "19 / 45, train loss: 0.1270\n",
            "20 / 45, train loss: 0.0774\n",
            "21 / 45, train loss: 0.1021\n",
            "22 / 45, train loss: 0.0789\n",
            "23 / 45, train loss: 0.1242\n",
            "24 / 45, train loss: 0.1257\n",
            "25 / 45, train loss: 0.1496\n",
            "26 / 45, train loss: 0.1282\n",
            "27 / 45, train loss: 0.1528\n",
            "28 / 45, train loss: 0.1262\n",
            "29 / 45, train loss: 0.1109\n",
            "30 / 45, train loss: 0.1313\n",
            "31 / 45, train loss: 0.0796\n",
            "32 / 45, train loss: 0.1330\n",
            "33 / 45, train loss: 0.1175\n",
            "34 / 45, train loss: 0.1085\n",
            "35 / 45, train loss: 0.0631\n",
            "36 / 45, train loss: 0.1004\n",
            "37 / 45, train loss: 0.2123\n",
            "38 / 45, train loss: 0.0651\n",
            "39 / 45, train loss: 0.0888\n",
            "40 / 45, train loss: 0.0728\n",
            "41 / 45, train loss: 0.1068\n",
            "42 / 45, train loss: 0.0815\n",
            "43 / 45, train loss: 0.1013\n",
            "44 / 45, train loss: 0.0361\n",
            "45 / 45, train loss: 0.1065\n",
            "epoch 155 loss: 5.0956\n",
            "current learning rate: 0.000157\n",
            "Epoch 157 / 300\n",
            "----------\n",
            "1 / 45, train loss: 0.1148\n",
            "2 / 45, train loss: 0.1284\n",
            "3 / 45, train loss: 0.0982\n",
            "4 / 45, train loss: 0.0809\n",
            "5 / 45, train loss: 0.1221\n",
            "6 / 45, train loss: 0.1074\n",
            "7 / 45, train loss: 0.1261\n",
            "8 / 45, train loss: 0.1120\n",
            "9 / 45, train loss: 0.1317\n",
            "10 / 45, train loss: 0.0884\n",
            "11 / 45, train loss: 0.1049\n",
            "12 / 45, train loss: 0.0977\n",
            "13 / 45, train loss: 0.1372\n",
            "14 / 45, train loss: 0.0680\n",
            "15 / 45, train loss: 0.1386\n",
            "16 / 45, train loss: 0.0992\n",
            "17 / 45, train loss: 0.1308\n",
            "18 / 45, train loss: 0.1036\n",
            "19 / 45, train loss: 0.0867\n",
            "20 / 45, train loss: 0.1610\n",
            "21 / 45, train loss: 0.0801\n",
            "22 / 45, train loss: 0.1488\n",
            "23 / 45, train loss: 0.1100\n",
            "24 / 45, train loss: 0.1229\n",
            "25 / 45, train loss: 0.0893\n",
            "26 / 45, train loss: 0.1415\n",
            "27 / 45, train loss: 0.1066\n",
            "28 / 45, train loss: 0.0908\n",
            "29 / 45, train loss: 0.1319\n",
            "30 / 45, train loss: 0.0867\n",
            "31 / 45, train loss: 0.1533\n",
            "32 / 45, train loss: 0.1125\n",
            "33 / 45, train loss: 0.1470\n",
            "34 / 45, train loss: 0.0529\n",
            "35 / 45, train loss: 0.1690\n",
            "36 / 45, train loss: 0.1212\n",
            "37 / 45, train loss: 0.0814\n",
            "38 / 45, train loss: 0.1308\n",
            "Traceback (most recent call last):\n",
            "  File \"front_main.py\", line 65, in <module>\n",
            "    first_net = train_first_stage(writer, train_dataloader, first_net, first_optim, args.init_lr, thin_criterion, thick_criterion, device, args.power, epoch, args.first_epochs)\n",
            "  File \"/content/drive/MyDrive/can-work/rose/OCTA-Net-OCTA-Vessel-Segmentation-Network-master/code/OCTA-Net/train.py\", line 25, in train_first_stage\n",
            "    loss.backward()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\", line 396, in backward\n",
            "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\", line 175, in backward\n",
            "    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!python front_main.py --mode train --dataset cria --data_dir ../../../../data/ROSE-2 --val_epoch_freq 5 --num_workers 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnKCI-_THwXv",
        "outputId": "c7b1d629-e6c2-46cf-b581-44b24e99b6a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start testing...\n",
            "/content/drive/MyDrive/rose/OCTA-Net-OCTA-Vessel-Segmentation-Network-master/code/OCTA-Net/test.py:75: RuntimeWarning: Mean of empty slice.\n",
            "  print(\"Loss - mean: \" + str(loss_arr.mean()) + \"\\tstd: \" + str(loss_arr.std()))\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:263: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  keepdims=keepdims, where=where)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in true_divide\n",
            "  subok=False)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "Loss - mean: nan\tstd: nan\n",
            "AUC - mean: 0.8606882219827194\tstd: 0.04580924419619761\n",
            "ACC - mean: 0.9035011638294567\tstd: 0.034684320848026716\n",
            "SEN - mean: 0.51293140153062\tstd: 0.08366705075282861\n",
            "FDR - mean: 0.6720603328188011\tstd: 0.0477254921190993\n",
            "SPE - mean: 0.9301480112030887\tstd: 0.024980999279896283\n",
            "Kappa - mean: 0.34463974828460625\tstd: 0.045161774846425605\n",
            "G-mean - mean: 0.6881373386960367\tstd: 0.057828828250474903\n",
            "IOU - mean: 0.24670646125170836\tstd: 0.032052094872909775\n",
            "Dice - mean: 0.3946575379837713\tstd: 0.04344352553956554\n",
            "Loss - mean: nan\tstd: nan\n",
            "AUC - mean: 0.8601044206947425\tstd: 0.04586557400456411\n",
            "ACC - mean: 0.9021136543967507\tstd: 0.035871718023312835\n",
            "SEN - mean: 0.5171619066834505\tstd: 0.08278016555491927\n",
            "FDR - mean: 0.6751183808260273\tstd: 0.04605066520654296\n",
            "SPE - mean: 0.9281607003453516\tstd: 0.02643323566120649\n",
            "Kappa - mean: 0.3434617913758886\tstd: 0.04494650843383543\n",
            "G-mean - mean: 0.6902583511632258\tstd: 0.05711066001533689\n",
            "IOU - mean: 0.24627183818231876\tstd: 0.03193982952396954\n",
            "Dice - mean: 0.3941069547520825\tstd: 0.04323289739994605\n",
            "Loss - mean: nan\tstd: nan\n",
            "AUC - mean: 0.8609264737135944\tstd: 0.045902473395739274\n",
            "ACC - mean: 0.9003595872358843\tstd: 0.03586981040307692\n",
            "SEN - mean: 0.525864443603554\tstd: 0.08435178946991188\n",
            "FDR - mean: 0.6791961496442395\tstd: 0.04670054957593695\n",
            "SPE - mean: 0.9257668658326594\tstd: 0.02682111260694418\n",
            "Kappa - mean: 0.3420335678743534\tstd: 0.044664401773624025\n",
            "G-mean - mean: 0.6951434759608818\tstd: 0.057473730089416974\n",
            "IOU - mean: 0.24561923261866522\tstd: 0.03196109857490971\n",
            "Dice - mean: 0.3932618441939862\tstd: 0.04335368477325783\n",
            "Testing finished.\n"
          ]
        }
      ],
      "source": [
        "!python front_main.py --mode test --dataset cria --data_dir ../../../../data/ROSE-2 --num_workers 2 --first_suffix best_fusion.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def mkdir(path):\n",
        "    path = path.strip()\n",
        "    path = path.rstrip(\"\\\\\")\n",
        "\n",
        "    isExists = os.path.exists(path)\n",
        "\n",
        "    if not isExists:\n",
        "        os.makedirs(path)\n",
        "        return True\n",
        "    else:\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "3mSZ_BqyfxuN"
      },
      "outputs": [],
      "source": [
        "pred_path = 'results/cria/first_stage/fusion/Thresh/'\n",
        "gt_path = '../../../../data/ROSE-2/test/gt/'\n",
        "ori_path = '../../../../data/ROSE-2/test/original/'\n",
        "save_dir = '../../../OctaRoseResults/'\n",
        "imgs = os.listdir(pred_path)\n",
        "mkdir(folder_path + '/OctaRoseResults')\n",
        "for img_path in imgs:\n",
        "    if not img_path.endswith('.png'):\n",
        "        continue\n",
        "    img = cv2.imread(pred_path + img_path)\n",
        "    pink = (255,0,255)\n",
        "    white_pixels = np.where(\n",
        "        (img[:, :, 0] == 255) & \n",
        "        (img[:, :, 1] == 255) & \n",
        "        (img[:, :, 2] == 255)\n",
        "    )\n",
        "    img[white_pixels] = pink\n",
        "\n",
        "    gt = cv2.imread(gt_path + img_path)\n",
        "    ori = cv2.imread(ori_path + img_path)\n",
        "\n",
        "    res = np.zeros((512, 512*3, 3))\n",
        "    res[:,0:512,:] = gt\n",
        "    res[:,512:2*512, :] = ori\n",
        "    res[:,2*512:, :] = img\n",
        "    cv2.imwrite(save_dir + img_path, res.astype(int))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zeCfqSVJinhF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device('cuda')\n",
        "net = torch.load(\"models/cria/first_stage/front_model-best_fusion.pth\").to(device)\n",
        "net.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "uO9fTp7Kz75q"
      },
      "outputs": [],
      "source": [
        "ori_path = '../../../../A. Segmentation/1. Original Images/a. Training Set/'\n",
        "save_dir = '../../../OctaDracResults/'\n",
        "imgs = os.listdir(ori_path)\n",
        "mkdir(folder_path + '/OctaDracResults')\n",
        "for img_path in imgs:\n",
        "    if not img_path.endswith('.png'):\n",
        "        continue\n",
        "\n",
        "    simple_transform = transforms.ToTensor()\n",
        "    \n",
        "    ori = Image.open(ori_path + img_path).resize((512,512))\n",
        "    ori = ori.convert(\"RGB\")\n",
        "    ori = simple_transform(ori).unsqueeze(0)\n",
        "\n",
        "    thick_pred, thin_pred, pred = net(ori.to(device))\n",
        "    pred_arr = pred.squeeze().detach().cpu().numpy()\n",
        "    pred_img = np.array(pred_arr * 255, np.uint8)\n",
        "    _, img = cv2.threshold(pred_img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "    pink = (255,0,255)\n",
        "    img = np.expand_dims(img, 2)\n",
        "    img = np.repeat(img, 3, 2)\n",
        "    white_pixels = np.where(\n",
        "        (img[:, :, 0] == 255) & \n",
        "        (img[:, :, 1] == 255) & \n",
        "        (img[:, :, 2] == 255)\n",
        "    )\n",
        "    img[white_pixels] = pink\n",
        "\n",
        "\n",
        "    res = np.zeros((512, 512*2, 3))\n",
        "    res[:,:512, :] = cv2.resize(cv2.imread(ori_path + img_path), (512,512))\n",
        "    res[:, 512:, :] = img\n",
        "    cv2.imwrite(save_dir + img_path, res.astype(int))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Octa_Rose_DRAC.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
