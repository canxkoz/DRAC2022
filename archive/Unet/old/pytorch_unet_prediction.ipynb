{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23711,"status":"ok","timestamp":1661495120090,"user":{"displayName":"Hakan Sivuk","userId":"08930197213953409035"},"user_tz":-180},"id":"tIFJRBtK_5lA","outputId":"7c8c4bc8-c7ac-4a27-cb3c-6d028f115699"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":2731,"status":"ok","timestamp":1661495122816,"user":{"displayName":"Hakan Sivuk","userId":"08930197213953409035"},"user_tz":-180},"id":"CsUd68S66upe"},"outputs":[],"source":["import os,sys\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch\n","import cv2 as cv\n","import glob\n","from PIL import Image\n","from os import listdir\n","\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, datasets, models\n","\n","import random"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dbtX8K1z_1ah"},"outputs":[],"source":["%cd /content/drive/MyDrive/DRAC2022/Unet"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2077746,"status":"ok","timestamp":1661464866681,"user":{"displayName":"Hakan Sivuk","userId":"08930197213953409035"},"user_tz":-180},"id":"T5_9lR50AnT8","outputId":"1d4df5b4-b81f-4272-ecf9-88f6f50877ba"},"outputs":[{"name":"stdout","output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 512, 512]             640\n","              ReLU-2         [-1, 64, 512, 512]               0\n","            Conv2d-3         [-1, 64, 512, 512]          36,928\n","              ReLU-4         [-1, 64, 512, 512]               0\n","         MaxPool2d-5         [-1, 64, 256, 256]               0\n","            Conv2d-6        [-1, 128, 256, 256]          73,856\n","              ReLU-7        [-1, 128, 256, 256]               0\n","            Conv2d-8        [-1, 128, 256, 256]         147,584\n","              ReLU-9        [-1, 128, 256, 256]               0\n","        MaxPool2d-10        [-1, 128, 128, 128]               0\n","           Conv2d-11        [-1, 256, 128, 128]         295,168\n","             ReLU-12        [-1, 256, 128, 128]               0\n","           Conv2d-13        [-1, 256, 128, 128]         590,080\n","             ReLU-14        [-1, 256, 128, 128]               0\n","        MaxPool2d-15          [-1, 256, 64, 64]               0\n","           Conv2d-16          [-1, 512, 64, 64]       1,180,160\n","             ReLU-17          [-1, 512, 64, 64]               0\n","           Conv2d-18          [-1, 512, 64, 64]       2,359,808\n","             ReLU-19          [-1, 512, 64, 64]               0\n","         Upsample-20        [-1, 512, 128, 128]               0\n","           Conv2d-21        [-1, 256, 128, 128]       1,769,728\n","             ReLU-22        [-1, 256, 128, 128]               0\n","           Conv2d-23        [-1, 256, 128, 128]         590,080\n","             ReLU-24        [-1, 256, 128, 128]               0\n","         Upsample-25        [-1, 256, 256, 256]               0\n","           Conv2d-26        [-1, 128, 256, 256]         442,496\n","             ReLU-27        [-1, 128, 256, 256]               0\n","           Conv2d-28        [-1, 128, 256, 256]         147,584\n","             ReLU-29        [-1, 128, 256, 256]               0\n","         Upsample-30        [-1, 128, 512, 512]               0\n","           Conv2d-31         [-1, 64, 512, 512]         110,656\n","             ReLU-32         [-1, 64, 512, 512]               0\n","           Conv2d-33         [-1, 64, 512, 512]          36,928\n","             ReLU-34         [-1, 64, 512, 512]               0\n","           Conv2d-35          [-1, 1, 512, 512]              65\n","================================================================\n","Total params: 7,781,761\n","Trainable params: 7,781,761\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 1.00\n","Forward/backward pass size (MB): 2362.00\n","Params size (MB): 29.69\n","Estimated Total Size (MB): 2392.69\n","----------------------------------------------------------------\n","Epoch 1/100\n","----------\n","LR 0.0001\n","train: loss: 0.434833\n","val: loss: 0.249935\n","saving best model\n","1m 38s\n","\n","Epoch 2/100\n","----------\n","LR 0.0001\n","train: loss: 0.266567\n","val: loss: 0.232574\n","saving best model\n","0m 18s\n","\n","Epoch 3/100\n","----------\n","LR 0.0001\n","train: loss: 0.260834\n","val: loss: 0.228967\n","saving best model\n","0m 19s\n","\n","Epoch 4/100\n","----------\n","LR 0.0001\n","train: loss: 0.253739\n","val: loss: 0.223924\n","saving best model\n","0m 19s\n","\n","Epoch 5/100\n","----------\n","LR 0.0001\n","train: loss: 0.246774\n","val: loss: 0.224741\n","0m 19s\n","\n","Epoch 6/100\n","----------\n","LR 0.0001\n","train: loss: 0.239057\n","val: loss: 0.210123\n","saving best model\n","0m 19s\n","\n","Epoch 7/100\n","----------\n","LR 0.0001\n","train: loss: 0.235523\n","val: loss: 0.206860\n","saving best model\n","0m 19s\n","\n","Epoch 8/100\n","----------\n","LR 0.0001\n","train: loss: 0.232409\n","val: loss: 0.204740\n","saving best model\n","0m 19s\n","\n","Epoch 9/100\n","----------\n","LR 0.0001\n","train: loss: 0.228502\n","val: loss: 0.202356\n","saving best model\n","0m 19s\n","\n","Epoch 10/100\n","----------\n","LR 0.0001\n","train: loss: 0.226848\n","val: loss: 0.207280\n","0m 20s\n","\n","Epoch 11/100\n","----------\n","LR 0.0001\n","train: loss: 0.228402\n","val: loss: 0.201083\n","saving best model\n","0m 20s\n","\n","Epoch 12/100\n","----------\n","LR 0.0001\n","train: loss: 0.226335\n","val: loss: 0.207672\n","0m 20s\n","\n","Epoch 13/100\n","----------\n","LR 0.0001\n","train: loss: 0.225780\n","val: loss: 0.200613\n","saving best model\n","0m 20s\n","\n","Epoch 14/100\n","----------\n","LR 0.0001\n","train: loss: 0.226130\n","val: loss: 0.200555\n","saving best model\n","0m 20s\n","\n","Epoch 15/100\n","----------\n","LR 0.0001\n","train: loss: 0.225938\n","val: loss: 0.201948\n","0m 20s\n","\n","Epoch 16/100\n","----------\n","LR 0.0001\n","train: loss: 0.226413\n","val: loss: 0.201474\n","0m 20s\n","\n","Epoch 17/100\n","----------\n","LR 0.0001\n","train: loss: 0.223958\n","val: loss: 0.204035\n","0m 20s\n","\n","Epoch 18/100\n","----------\n","LR 0.0001\n","train: loss: 0.225979\n","val: loss: 0.199937\n","saving best model\n","0m 20s\n","\n","Epoch 19/100\n","----------\n","LR 0.0001\n","train: loss: 0.226196\n","val: loss: 0.198655\n","saving best model\n","0m 20s\n","\n","Epoch 20/100\n","----------\n","LR 0.0001\n","train: loss: 0.223244\n","val: loss: 0.197644\n","saving best model\n","0m 20s\n","\n","Epoch 21/100\n","----------\n","LR 0.0001\n","train: loss: 0.223251\n","val: loss: 0.197819\n","0m 20s\n","\n","Epoch 22/100\n","----------\n","LR 0.0001\n","train: loss: 0.223377\n","val: loss: 0.197560\n","saving best model\n","0m 20s\n","\n","Epoch 23/100\n","----------\n","LR 0.0001\n","train: loss: 0.222708\n","val: loss: 0.196236\n","saving best model\n","0m 20s\n","\n","Epoch 24/100\n","----------\n","LR 0.0001\n","train: loss: 0.221336\n","val: loss: 0.196077\n","saving best model\n","0m 20s\n","\n","Epoch 25/100\n","----------\n","LR 0.0001\n","train: loss: 0.222231\n","val: loss: 0.195712\n","saving best model\n","0m 20s\n","\n","Epoch 26/100\n","----------\n","LR 0.0001\n","train: loss: 0.222969\n","val: loss: 0.196194\n","0m 20s\n","\n","Epoch 27/100\n","----------\n","LR 0.0001\n","train: loss: 0.224606\n","val: loss: 0.196550\n","0m 20s\n","\n","Epoch 28/100\n","----------\n","LR 0.0001\n","train: loss: 0.222224\n","val: loss: 0.195045\n","saving best model\n","0m 20s\n","\n","Epoch 29/100\n","----------\n","LR 0.0001\n","train: loss: 0.222021\n","val: loss: 0.195917\n","0m 20s\n","\n","Epoch 30/100\n","----------\n","LR 0.0001\n","train: loss: 0.221630\n","val: loss: 0.194274\n","saving best model\n","0m 20s\n","\n","Epoch 31/100\n","----------\n","LR 0.0001\n","train: loss: 0.219805\n","val: loss: 0.194267\n","saving best model\n","0m 20s\n","\n","Epoch 32/100\n","----------\n","LR 0.0001\n","train: loss: 0.220426\n","val: loss: 0.196196\n","0m 20s\n","\n","Epoch 33/100\n","----------\n","LR 0.0001\n","train: loss: 0.221316\n","val: loss: 0.194509\n","0m 20s\n","\n","Epoch 34/100\n","----------\n","LR 0.0001\n","train: loss: 0.218797\n","val: loss: 0.193319\n","saving best model\n","0m 20s\n","\n","Epoch 35/100\n","----------\n","LR 0.0001\n","train: loss: 0.219835\n","val: loss: 0.192758\n","saving best model\n","0m 20s\n","\n","Epoch 36/100\n","----------\n","LR 0.0001\n","train: loss: 0.218766\n","val: loss: 0.192464\n","saving best model\n","0m 20s\n","\n","Epoch 37/100\n","----------\n","LR 0.0001\n","train: loss: 0.219159\n","val: loss: 0.191288\n","saving best model\n","0m 20s\n","\n","Epoch 38/100\n","----------\n","LR 0.0001\n","train: loss: 0.219707\n","val: loss: 0.191502\n","0m 20s\n","\n","Epoch 39/100\n","----------\n","LR 0.0001\n","train: loss: 0.219523\n","val: loss: 0.193991\n","0m 20s\n","\n","Epoch 40/100\n","----------\n","LR 0.0001\n","train: loss: 0.218055\n","val: loss: 0.195311\n","0m 20s\n","\n","Epoch 41/100\n","----------\n","LR 0.0001\n","train: loss: 0.216976\n","val: loss: 0.190760\n","saving best model\n","0m 20s\n","\n","Epoch 42/100\n","----------\n","LR 0.0001\n","train: loss: 0.218305\n","val: loss: 0.192692\n","0m 20s\n","\n","Epoch 43/100\n","----------\n","LR 0.0001\n","train: loss: 0.217147\n","val: loss: 0.191461\n","0m 20s\n","\n","Epoch 44/100\n","----------\n","LR 0.0001\n","train: loss: 0.216758\n","val: loss: 0.189312\n","saving best model\n","0m 20s\n","\n","Epoch 45/100\n","----------\n","LR 0.0001\n","train: loss: 0.217956\n","val: loss: 0.189744\n","0m 20s\n","\n","Epoch 46/100\n","----------\n","LR 0.0001\n","train: loss: 0.216953\n","val: loss: 0.191151\n","0m 20s\n","\n","Epoch 47/100\n","----------\n","LR 0.0001\n","train: loss: 0.216385\n","val: loss: 0.188468\n","saving best model\n","0m 20s\n","\n","Epoch 48/100\n","----------\n","LR 0.0001\n","train: loss: 0.217252\n","val: loss: 0.192479\n","0m 20s\n","\n","Epoch 49/100\n","----------\n","LR 0.0001\n","train: loss: 0.216472\n","val: loss: 0.193382\n","0m 20s\n","\n","Epoch 50/100\n","----------\n","LR 0.0001\n","train: loss: 0.216372\n","val: loss: 0.187647\n","saving best model\n","0m 20s\n","\n","Epoch 51/100\n","----------\n","LR 0.0001\n","train: loss: 0.215725\n","val: loss: 0.189369\n","0m 20s\n","\n","Epoch 52/100\n","----------\n","LR 0.0001\n","train: loss: 0.216036\n","val: loss: 0.187800\n","0m 20s\n","\n","Epoch 53/100\n","----------\n","LR 0.0001\n","train: loss: 0.215683\n","val: loss: 0.187722\n","0m 20s\n","\n","Epoch 54/100\n","----------\n","LR 0.0001\n","train: loss: 0.214853\n","val: loss: 0.188176\n","0m 20s\n","\n","Epoch 55/100\n","----------\n","LR 0.0001\n","train: loss: 0.216155\n","val: loss: 0.187143\n","saving best model\n","0m 20s\n","\n","Epoch 56/100\n","----------\n","LR 0.0001\n","train: loss: 0.214506\n","val: loss: 0.188803\n","0m 20s\n","\n","Epoch 57/100\n","----------\n","LR 0.0001\n","train: loss: 0.214483\n","val: loss: 0.186808\n","saving best model\n","0m 20s\n","\n","Epoch 58/100\n","----------\n","LR 0.0001\n","train: loss: 0.215428\n","val: loss: 0.186668\n","saving best model\n","0m 20s\n","\n","Epoch 59/100\n","----------\n","LR 0.0001\n","train: loss: 0.215297\n","val: loss: 0.187415\n","0m 20s\n","\n","Epoch 60/100\n","----------\n","LR 0.0001\n","train: loss: 0.214493\n","val: loss: 0.187057\n","0m 20s\n","\n","Epoch 61/100\n","----------\n","LR 0.0001\n","train: loss: 0.214852\n","val: loss: 0.190994\n","0m 20s\n","\n","Epoch 62/100\n","----------\n","LR 0.0001\n","train: loss: 0.215123\n","val: loss: 0.186687\n","0m 20s\n","\n","Epoch 63/100\n","----------\n","LR 0.0001\n","train: loss: 0.216112\n","val: loss: 0.186943\n","0m 20s\n","\n","Epoch 64/100\n","----------\n","LR 0.0001\n","train: loss: 0.212676\n","val: loss: 0.185899\n","saving best model\n","0m 20s\n","\n","Epoch 65/100\n","----------\n","LR 0.0001\n","train: loss: 0.214708\n","val: loss: 0.185553\n","saving best model\n","0m 20s\n","\n","Epoch 66/100\n","----------\n","LR 0.0001\n","train: loss: 0.214258\n","val: loss: 0.185893\n","0m 20s\n","\n","Epoch 67/100\n","----------\n","LR 0.0001\n","train: loss: 0.213991\n","val: loss: 0.185643\n","0m 20s\n","\n","Epoch 68/100\n","----------\n","LR 0.0001\n","train: loss: 0.214841\n","val: loss: 0.189578\n","0m 20s\n","\n","Epoch 69/100\n","----------\n","LR 0.0001\n","train: loss: 0.215276\n","val: loss: 0.189032\n","0m 20s\n","\n","Epoch 70/100\n","----------\n","LR 0.0001\n","train: loss: 0.214595\n","val: loss: 0.185371\n","saving best model\n","0m 20s\n","\n","Epoch 71/100\n","----------\n","LR 0.0001\n","train: loss: 0.211931\n","val: loss: 0.184454\n","saving best model\n","0m 20s\n","\n","Epoch 72/100\n","----------\n","LR 0.0001\n","train: loss: 0.213024\n","val: loss: 0.184334\n","saving best model\n","0m 20s\n","\n","Epoch 73/100\n","----------\n","LR 0.0001\n","train: loss: 0.213139\n","val: loss: 0.184848\n","0m 20s\n","\n","Epoch 74/100\n","----------\n","LR 0.0001\n","train: loss: 0.212390\n","val: loss: 0.187180\n","0m 20s\n","\n","Epoch 75/100\n","----------\n","LR 0.0001\n","train: loss: 0.212135\n","val: loss: 0.186681\n","0m 20s\n","\n","Epoch 76/100\n","----------\n","LR 0.0001\n","train: loss: 0.213096\n","val: loss: 0.185087\n","0m 20s\n","\n","Epoch 77/100\n","----------\n","LR 0.0001\n","train: loss: 0.211942\n","val: loss: 0.184498\n","0m 20s\n","\n","Epoch 78/100\n","----------\n","LR 0.0001\n","train: loss: 0.212731\n","val: loss: 0.183879\n","saving best model\n","0m 20s\n","\n","Epoch 79/100\n","----------\n","LR 0.0001\n","train: loss: 0.213092\n","val: loss: 0.185134\n","0m 20s\n","\n","Epoch 80/100\n","----------\n","LR 0.0001\n","train: loss: 0.212292\n","val: loss: 0.184357\n","0m 20s\n","\n","Epoch 81/100\n","----------\n","LR 0.0001\n","train: loss: 0.210944\n","val: loss: 0.184684\n","0m 20s\n","\n","Epoch 82/100\n","----------\n","LR 0.0001\n","train: loss: 0.211669\n","val: loss: 0.183578\n","saving best model\n","0m 20s\n","\n","Epoch 83/100\n","----------\n","LR 0.0001\n","train: loss: 0.212653\n","val: loss: 0.183758\n","0m 20s\n","\n","Epoch 84/100\n","----------\n","LR 0.0001\n","train: loss: 0.210496\n","val: loss: 0.183710\n","0m 20s\n","\n","Epoch 85/100\n","----------\n","LR 0.0001\n","train: loss: 0.211747\n","val: loss: 0.184880\n","0m 20s\n","\n","Epoch 86/100\n","----------\n","LR 0.0001\n","train: loss: 0.212383\n","val: loss: 0.183977\n","0m 20s\n","\n","Epoch 87/100\n","----------\n","LR 0.0001\n","train: loss: 0.211783\n","val: loss: 0.183404\n","saving best model\n","0m 20s\n","\n","Epoch 88/100\n","----------\n","LR 0.0001\n","train: loss: 0.210990\n","val: loss: 0.185813\n","0m 20s\n","\n","Epoch 89/100\n","----------\n","LR 0.0001\n","train: loss: 0.210834\n","val: loss: 0.183904\n","0m 20s\n","\n","Epoch 90/100\n","----------\n","LR 0.0001\n","train: loss: 0.210212\n","val: loss: 0.185858\n","0m 20s\n","\n","Epoch 91/100\n","----------\n","LR 0.0001\n","train: loss: 0.210889\n","val: loss: 0.182254\n","saving best model\n","0m 20s\n","\n","Epoch 92/100\n","----------\n","LR 0.0001\n","train: loss: 0.210062\n","val: loss: 0.186290\n","0m 20s\n","\n","Epoch 93/100\n","----------\n","LR 0.0001\n","train: loss: 0.213668\n","val: loss: 0.183630\n","0m 20s\n","\n","Epoch 94/100\n","----------\n","LR 0.0001\n","train: loss: 0.211220\n","val: loss: 0.185602\n","0m 20s\n","\n","Epoch 95/100\n","----------\n","LR 0.0001\n","train: loss: 0.210969\n","val: loss: 0.182910\n","0m 20s\n","\n","Epoch 96/100\n","----------\n","LR 0.0001\n","train: loss: 0.210658\n","val: loss: 0.182971\n","0m 20s\n","\n","Epoch 97/100\n","----------\n","LR 0.0001\n","train: loss: 0.212120\n","val: loss: 0.182506\n","0m 20s\n","\n","Epoch 98/100\n","----------\n","LR 0.0001\n","train: loss: 0.211427\n","val: loss: 0.182155\n","saving best model\n","0m 20s\n","\n","Epoch 99/100\n","----------\n","LR 0.0001\n","train: loss: 0.211135\n","val: loss: 0.182309\n","0m 20s\n","\n","Epoch 100/100\n","----------\n","LR 0.0001\n","train: loss: 0.210008\n","val: loss: 0.185269\n","0m 20s\n","\n","Best val loss: 0.182155\n"]}],"source":["!python unet.py"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":860,"status":"ok","timestamp":1661495183249,"user":{"displayName":"Hakan Sivuk","userId":"08930197213953409035"},"user_tz":-180},"id":"G5KZewgs6upx","outputId":"0372baeb-6aaa-4318-83b1-679c09c62b08"},"outputs":[{"data":{"text/plain":["UNet(\n","  (dconv_down1): Sequential(\n","    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","  )\n","  (dconv_down2): Sequential(\n","    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","  )\n","  (dconv_down3): Sequential(\n","    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","  )\n","  (dconv_down4): Sequential(\n","    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","  )\n","  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (upsample): Upsample(scale_factor=2.0, mode=bilinear)\n","  (dconv_up3): Sequential(\n","    (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","  )\n","  (dconv_up2): Sequential(\n","    (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","  )\n","  (dconv_up1): Sequential(\n","    (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","  )\n","  (conv_last): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",")"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["#### prediction\n","import torch\n","import math\n","import pytorch_unet\n","from torchvision.utils import save_image\n","import torch.nn.functional as F\n","import cv2\n","\n","fold = 2\n","run = 1\n","model_name = 'UNet_fold{}_run{}'.format(fold, run)\n","\n","device = torch.device('cuda')\n","dtype = torch.cuda.FloatTensor\n","model = pytorch_unet.UNet(1).to(device)\n","model.load_state_dict(torch.load('./models/' + model_name))\n","model.eval()   # Set model to evaluate mode"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def mkdir(path):\n","    path = path.strip()\n","    path = path.rstrip(\"\\\\\")\n","\n","    isExists = os.path.exists(path)\n","\n","    if not isExists:\n","        os.makedirs(path)\n","        return True\n","    else:\n","        return False"]},{"cell_type":"code","execution_count":73,"metadata":{"executionInfo":{"elapsed":20253,"status":"ok","timestamp":1661498458168,"user":{"displayName":"Hakan Sivuk","userId":"08930197213953409035"},"user_tz":-180},"id":"k9B1qhPITCYD"},"outputs":[],"source":["ori_path = '../data/ROSE-2/test/original/'\n","gt_path = '../data/ROSE-2/test/gt/'\n","save_dir = 'UnetRoseResults/'\n","mkdir('UnetRoseResults')\n","imgs = os.listdir(ori_path)\n","for img_path in imgs:\n","    if not img_path.endswith('.png'):\n","        continue\n","\n","    simple_transform = transforms.ToTensor()\n","    \n","    ori = Image.open(ori_path + img_path).resize((512,512))\n","    ori = ori.convert(\"L\")\n","    ori = simple_transform(ori).unsqueeze(0)\n","    pred = model(ori.to(device))\n","    pred = torch.sigmoid(pred)\n","    # pred = F.softmax(pred, dim = 1)\n","    pred = pred.data.cpu().numpy()\n","    pred = pred[0,0]\n","    pred_img = np.array(pred * 255, np.uint8)\n","    _, img = cv2.threshold(pred_img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n","\n","    pink = (255,0,255)\n","    img = np.expand_dims(img, 2)\n","    img = np.repeat(img, 3, 2)\n","    white_pixels = np.where(\n","        (img[:, :, 0] == 255) & \n","        (img[:, :, 1] == 255) & \n","        (img[:, :, 2] == 255)\n","    )\n","    img[white_pixels] = pink\n","\n","    gt = cv2.imread(gt_path + img_path)\n","\n","    res = np.zeros((512, 512*3, 3))\n","    res[:,:512,:] = gt\n","    res[:,512:2*512, :] = cv2.resize(cv2.imread(ori_path + img_path), (512,512))\n","    res[:, 2*512:, :] = img\n","\n","    cv2.imwrite(save_dir + img_path, res.astype(int))"]},{"cell_type":"code","execution_count":74,"metadata":{"executionInfo":{"elapsed":15976,"status":"ok","timestamp":1661498483045,"user":{"displayName":"Hakan Sivuk","userId":"08930197213953409035"},"user_tz":-180},"id":"YGhhCuWkAOkK"},"outputs":[],"source":["ori_path = '../A. Segmentation/1. Original Images/a. Training Set/'\n","save_dir = 'UnetDracResults/'\n","mkdir('UnetDracResults')\n","\n","imgs = os.listdir(ori_path)\n","for img_path in imgs:\n","    if not img_path.endswith('.png'):\n","        continue\n","\n","    simple_transform = transforms.ToTensor()\n","    \n","    ori = Image.open(ori_path + img_path).resize((512,512))\n","    ori = ori.convert(\"L\")\n","    ori = simple_transform(ori).unsqueeze(0)\n","    pred = model(ori.to(device))\n","    pred = torch.sigmoid(pred)\n","    # pred = F.softmax(pred, dim = 1)\n","    pred = pred.data.cpu().numpy()\n","    pred = pred[0,0]\n","    pred_img = np.array(pred * 255, np.uint8)\n","    _, img = cv2.threshold(pred_img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n","\n","    pink = (255,0,255)\n","    img = np.expand_dims(img, 2)\n","    img = np.repeat(img, 3, 2)\n","    white_pixels = np.where(\n","        (img[:, :, 0] == 255) & \n","        (img[:, :, 1] == 255) & \n","        (img[:, :, 2] == 255)\n","    )\n","    img[white_pixels] = pink\n","\n","\n","    res = np.zeros((512, 512*2, 3))\n","    res[:,:512, :] = cv2.resize(cv2.imread(ori_path + img_path), (512,512))\n","    res[:, 512:, :] = img\n","\n","    cv2.imwrite(save_dir + img_path, res.astype(int))"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"pytorch_unet_prediction.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
